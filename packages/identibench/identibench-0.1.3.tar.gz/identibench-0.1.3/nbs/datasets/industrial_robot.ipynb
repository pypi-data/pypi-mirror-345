{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Industrial Robot Dataset\n",
    "\n",
    "> Fill in a module description here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp datasets.industrial_robot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from identibench.utils import write_dataset,write_array\n",
    "import identibench.benchmark as idb\n",
    "import identibench.metrics\n",
    "from nonlinear_benchmarks.utilities import cashed_download\n",
    "from pathlib import Path\n",
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "\n",
    "def robot_mat2hdf(\n",
    "        save_path: Path, #directory the files are written to, created if it does not exist\n",
    "        mat_path: Path, #path of mat file to extract\n",
    ") -> None:         \n",
    "    'converts .mat file of industrial robot to hdf5 file, used for forward and inverse'\n",
    "\n",
    "\n",
    "    fs = 10  # Hz\n",
    "    train_valid_split = 0.8\n",
    "    os.makedirs(save_path / 'test', exist_ok=True)\n",
    "    os.makedirs(save_path / 'train', exist_ok=True)\n",
    "    os.makedirs(save_path / 'valid', exist_ok=True)\n",
    "\n",
    "    mf = sio.loadmat(mat_path)\n",
    "    for mode in ['train', 'test']:\n",
    "        if mode == 'test':\n",
    "            with h5py.File(save_path / 'test' / 'test.hdf5', 'w') as f:\n",
    "                write_dataset(f, 'dt', np.ones_like(mf[f'time_{mode}'][0]) / fs)\n",
    "                write_array(f, 'u', mf[f'u_{mode}'].T)\n",
    "                write_array(f, 'y', mf[f'y_{mode}'].T)\n",
    "                f.attrs['fs'] = fs\n",
    "\n",
    "        else:\n",
    "            with h5py.File(save_path / 'train' / 'train.hdf5', 'w') as train_f, \\\n",
    "                h5py.File(save_path / 'valid' / 'valid.hdf5', 'w') as valid_f:\n",
    "                    dt = np.ones_like(mf[f'time_{mode}'][0]) / fs\n",
    "                    total_entries = len(dt)\n",
    "                    split_index = int(total_entries * train_valid_split)\n",
    "\n",
    "                    write_dataset(train_f, 'dt', dt[:split_index])\n",
    "                    write_array(train_f, 'u', mf[f'u_{mode}'][:,:split_index].T)\n",
    "                    write_array(train_f, 'y', mf[f'y_{mode}'][:,:split_index].T)\n",
    "                    train_f.attrs['fs'] = fs  \n",
    "                    \n",
    "                    write_dataset(valid_f, 'dt', dt[split_index:])\n",
    "                    write_array(valid_f, 'u', mf[f'u_{mode}'][:,split_index:].T)\n",
    "                    write_array(valid_f, 'y', mf[f'y_{mode}'][:,split_index:].T)\n",
    "                    valid_f.attrs['fs'] = fs  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def dl_robot_forward(\n",
    "        save_path: Path, #directory the files are written to, created if it does not exist\n",
    "        force_download: bool = False # force download the dataset\n",
    ") -> None:\n",
    "    save_path = Path(save_path)\n",
    "    url_robot = \"https://fdm-fallback.uni-kl.de/TUK/FB/MV/WSKL/0001/Robot_Identification_Benchmark_Without_Raw_Data.rar\"\n",
    "    # unrar_download(url_robot,tmp_dir)\n",
    "\n",
    "    tmp_dir = cashed_download(url_robot,'Industrial_robot',force_download=force_download)\n",
    "    tmp_dir = Path(tmp_dir)\n",
    "\n",
    "    path_forward = tmp_dir / \"forward_identification_without_raw_data.mat\"\n",
    "\n",
    "    robot_mat2hdf(save_path,path_forward)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dir = idb.get_default_data_root()\n",
    "dl_robot_forward(tmp_dir / 'robot_forward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "u_forward = [ f'u{i}' for i in range(0,6) ]\n",
    "y_forward = [ f'y{i}' for i in range(0,6) ]\n",
    "\n",
    "BenchmarkRobotForward_Simulation = idb.BenchmarkSpecSimulation(\n",
    "    name='BenchmarkRobotForward_Simulation', dataset_id='robot_forward',\n",
    "    u_cols=u_forward, y_cols=y_forward, metric_func=identibench.metrics.rmse, \n",
    "    download_func=dl_robot_forward,\n",
    "    init_window=100\n",
    ")\n",
    "BenchmarkRobotForward_Prediction = idb.BenchmarkSpecPrediction(\n",
    "    name='BenchmarkRobotForward_Prediction', dataset_id='robot_forward',\n",
    "    u_cols=u_forward, y_cols=y_forward, metric_func=identibench.metrics.rmse, \n",
    "    download_func=dl_robot_forward,\n",
    "    init_window=100, pred_horizon=100,pred_step=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model with spec: BenchmarkRobotForward_Simulation, seed: 760661688\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'benchmark_name': 'BenchmarkRobotForward_Simulation',\n",
       " 'dataset_id': 'robot_forward',\n",
       " 'hyperparameters': {},\n",
       " 'seed': 760661688,\n",
       " 'training_time_seconds': 2.2000021999701858e-05,\n",
       " 'test_time_seconds': 0.0015273329918272793,\n",
       " 'benchmark_type': 'BenchmarkSpecSimulation',\n",
       " 'model_predictions': [(array([[0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0.]]),\n",
       "   array([[ 3.1585358e+01,  2.1944978e+00, -5.5836140e+01, -1.4837356e+01,\n",
       "           -8.9203796e+00, -4.8761210e+00],\n",
       "          [ 3.2038864e+01,  2.0360527e+00, -5.6426006e+01, -1.4673362e+01,\n",
       "           -9.9500036e+00, -5.6239290e+00],\n",
       "          [ 3.2423717e+01,  1.8637525e+00, -5.6897465e+01, -1.4411838e+01,\n",
       "           -1.1025160e+01, -6.3868413e+00],\n",
       "          ...,\n",
       "          [ 8.6335334e-05,  7.6897955e-03,  1.8853325e-03,  6.9732600e-06,\n",
       "            5.7662483e-06,  5.2318801e-06],\n",
       "          [ 7.8283243e-05,  7.4523911e-03,  1.8687517e-03,  1.0425742e-05,\n",
       "            6.7272158e-06,  3.8295721e-06],\n",
       "          [ 7.7276098e-05,  7.3412801e-03,  1.8494413e-03,  1.1828348e-05,\n",
       "            6.5456975e-06,  1.9779534e-06]], dtype=float32))],\n",
       " 'metric_scores': {'metric_score': 25.958381135555868}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = idb.run_benchmark(\n",
    "    spec=BenchmarkRobotForward_Simulation, \n",
    "    build_model=idb._dummy_build_model\n",
    ")\n",
    "results['metric_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model with spec: BenchmarkRobotForward_Prediction, seed: 914560277\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43midb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_benchmark\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBenchmarkRobotForward_Prediction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbuild_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43midb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dummy_build_model\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Development/identibench/identibench/benchmark.py:297\u001b[0m, in \u001b[0;36mrun_benchmark\u001b[0;34m(spec, build_model, hyperparameters, seed)\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbuild_model for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspec\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m did not return a model.\u001b[39m\u001b[38;5;124m\"\u001b[39m) \n\u001b[1;32m    296\u001b[0m test_start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 297\u001b[0m test_results \u001b[38;5;241m=\u001b[39m \u001b[43mspec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_model_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# get list of (y_pred,y_test) tuples\u001b[39;00m\n\u001b[1;32m    298\u001b[0m test_end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[1;32m    299\u001b[0m results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_time_seconds\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m test_end_time \u001b[38;5;241m-\u001b[39m test_start_time\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "results = idb.run_benchmark(\n",
    "    spec=BenchmarkRobotForward_Prediction, \n",
    "    build_model=idb._dummy_build_model\n",
    ")\n",
    "results['metric_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def dl_robot_inverse(\n",
    "        save_path: Path, #directory the files are written to, created if it does not exist\n",
    "        force_download: bool = False # force download the dataset\n",
    ") -> None:\n",
    "    save_path = Path(save_path)\n",
    "    url_robot = \"https://fdm-fallback.uni-kl.de/TUK/FB/MV/WSKL/0001/Robot_Identification_Benchmark_Without_Raw_Data.rar\"\n",
    "    # unrar_download(url_robot,tmp_dir)\n",
    "\n",
    "    tmp_dir = cashed_download(url_robot,'Industrial_robot',force_download=force_download)\n",
    "    tmp_dir = Path(tmp_dir)\n",
    "\n",
    "    path_inverse = tmp_dir / \"inverse_identification_without_raw_data.mat\"\n",
    "\n",
    "    robot_mat2hdf(save_path,path_inverse)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dir = idb.get_default_data_root()\n",
    "dl_robot_inverse(tmp_dir / 'robot_inverse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "u_inverse = [ f'u{i}' for i in range(0,12) ]\n",
    "y_inverse = [ f'y{i}' for i in range(0,6) ]\n",
    "\n",
    "BenchmarkRobotInverse_Simulation = idb.BenchmarkSpecSimulation(\n",
    "    name='BenchmarkRobotInverse_Simulation', dataset_id='robot_inverse',\n",
    "    u_cols=u_inverse, y_cols=y_inverse, metric_func=identibench.metrics.rmse, \n",
    "    download_func=dl_robot_inverse,\n",
    "    init_window=100\n",
    ")\n",
    "BenchmarkRobotInverse_Prediction = idb.BenchmarkSpecPrediction(\n",
    "    name='BenchmarkRobotInverse_Prediction', dataset_id='robot_inverse',\n",
    "    u_cols=u_inverse, y_cols=y_inverse, metric_func=identibench.metrics.rmse, \n",
    "    download_func=dl_robot_inverse,\n",
    "    init_window=100, pred_horizon=100,pred_step=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model with spec: BenchmarkRobotInverse_Simulation, seed: 3124363609\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'benchmark_name': 'BenchmarkRobotInverse_Simulation',\n",
       " 'dataset_id': 'robot_inverse',\n",
       " 'hyperparameters': {},\n",
       " 'seed': 3124363609,\n",
       " 'training_time_seconds': 0.00020908399892505258,\n",
       " 'test_time_seconds': 0.0013573749893112108,\n",
       " 'benchmark_type': 'BenchmarkSpecSimulation',\n",
       " 'metric_score': 3.952129646947972}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = idb.run_benchmark(\n",
    "    spec=BenchmarkRobotInverse_Simulation, \n",
    "    build_model=idb._dummy_build_model\n",
    ")\n",
    "results['metric_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model with spec: BenchmarkRobotInverse_Prediction, seed: 3738251874\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'benchmark_name': 'BenchmarkRobotInverse_Prediction',\n",
       " 'dataset_id': 'robot_inverse',\n",
       " 'hyperparameters': {},\n",
       " 'seed': 3738251874,\n",
       " 'training_time_seconds': 1.6375008272007108e-05,\n",
       " 'test_time_seconds': 0.0017839999927673489,\n",
       " 'benchmark_type': 'BenchmarkSpecPrediction',\n",
       " 'metric_score': 3.952129646947972}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = idb.run_benchmark(\n",
    "    spec=BenchmarkRobotInverse_Prediction, \n",
    "    build_model=idb._dummy_build_model\n",
    ")\n",
    "results['metric_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
