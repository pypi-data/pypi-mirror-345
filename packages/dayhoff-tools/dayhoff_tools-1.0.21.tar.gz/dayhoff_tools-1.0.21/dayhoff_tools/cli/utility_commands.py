"""CLI commands common to all repos."""

import os
import re
import shutil
import subprocess
import sys
from pathlib import Path

import toml
import typer
import yaml


def test_github_actions_locally():
    """Run the script test_pytest_in_github_actions_container.sh.sh."""
    script_path = ".devcontainer/scripts/test_pytest_in_github_actions_container.sh"

    try:
        subprocess.check_call(["bash", script_path])
        print("Script ran successfully!")
    except subprocess.CalledProcessError as e:
        print(f"Error occurred while running the script: {e}")


def rebuild_devcontainer_file():
    """Run the script prepare_for_build.py."""
    script_path = ".devcontainer/scripts/prepare_for_build.py"

    try:
        subprocess.check_call([sys.executable, script_path])
        print("Script ran successfully!")
    except subprocess.CalledProcessError as e:
        print(f"Error occurred while running the script: {e}")


def get_ancestry(filepath: str) -> None:
    """Take a .dvc file created from import, and generate an ancestry entry
    that can be manually copied into other .dvc files."""
    with open(filepath, "r") as file:
        assert filepath.endswith(".dvc"), "ERROR: Not a .dvc file"
        ancestor_content = yaml.safe_load(file)

        error_msg = "Unexpected file structure. Are you sure this is a .dvc file generated from `dvc import`?"
        assert "deps" in ancestor_content, error_msg

        error_msg = "Please only reference data imported from main branches."
        assert "rev" not in ancestor_content["deps"][0]["repo"], error_msg

        ancestor_info = {
            "name": os.path.basename(ancestor_content["outs"][0]["path"]),
            "file_md5_hash": ancestor_content["outs"][0]["md5"],
            "size": ancestor_content["outs"][0]["size"],
            "repo_url": ancestor_content["deps"][0]["repo"]["url"],
            "repo_path": ancestor_content["deps"][0]["path"],
            "commit_hash": ancestor_content["deps"][0]["repo"]["rev_lock"],
        }
        print()
        yaml.safe_dump(
            [ancestor_info], sys.stdout, default_flow_style=False, sort_keys=False
        )


def import_from_warehouse_typer() -> None:
    """Import a file from warehouse.
    This is a thin wrapper around `cli.utils.import_from_warehouse`,
    with interactive prompts using questionary.
    """
    # Import only when the function is called
    import questionary
    from dayhoff_tools.warehouse import import_from_warehouse

    # Ensure execution from root
    cwd = Path(os.getcwd())
    if cwd.parent.name != "workspaces" or str(cwd.parent.parent) != cwd.root:
        raise Exception(
            f"This command must be executed from the repo's root directory (/workspaces/reponame). Current directory: {cwd}"
        )

    # Use questionary for prompts instead of typer
    warehouse_path = questionary.text("Warehouse path:").ask()

    # Provide multiple-choice options for output folder
    output_folder_choice = questionary.select(
        "Output folder:",
        choices=["data/imports", "same_as_warehouse", "Custom path..."],
    ).ask()

    # If custom path is selected, ask for the path
    if output_folder_choice == "Custom path...":
        output_folder = questionary.text("Enter custom output folder:").ask()
    else:
        output_folder = output_folder_choice

    branch = questionary.text("Branch (default: main):", default="main").ask()

    final_path = import_from_warehouse(
        warehouse_path=warehouse_path,
        output_folder=output_folder,
        branch=branch,
    )


def add_to_warehouse_typer() -> None:
    """Add a new data file to warehouse, and expand its .dvc file with
    metadata, including ancestor files."""
    # Import only when the function is called
    import questionary
    from dayhoff_tools.warehouse import add_to_warehouse

    # Ensure execution from root
    cwd = Path(os.getcwd())
    if cwd.parent.name != "workspaces" or str(cwd.parent.parent) != cwd.root:
        raise Exception(
            f"This command must be executed from the repo's root directory (/workspaces/reponame). Current directory: {cwd}"
        )

    # Prompt for the data file path
    warehouse_path = questionary.text("Data file to be registered:").ask()

    # Prompt for the ancestor .dvc file paths
    ancestor_dvc_paths = []
    print("\nEnter the path of all ancestor .dvc files (or hit Enter to finish).")
    print("These files must be generated by `dvc import` or `dh wimport`.")
    while True:
        ancestor_path = questionary.text("Ancestor path: ").ask()
        if ancestor_path:
            ancestor_dvc_paths.append(ancestor_path)
        else:
            print()
            break

    dvc_path = add_to_warehouse(
        warehouse_path=warehouse_path,
        ancestor_dvc_paths=ancestor_dvc_paths,
    )


def delete_local_branch(branch_name: str, folder_path: str):
    """Delete a local Git branch after fetching with pruning.

    Args:
        branch_name: Name of the branch to delete
        folder_path: Path to the git repository folder
    """
    try:
        # Store current working directory
        original_dir = os.getcwd()

        # Change to the specified directory
        os.chdir(folder_path)
        print(f"Changed to directory: {folder_path}")

        # Delete the specified branch
        delete_branch_cmd = ["git", "branch", "-D", branch_name]
        subprocess.run(delete_branch_cmd, check=True)
        print(f"Deleted branch: {branch_name}")

        # Fetch changes from the remote repository and prune obsolete branches
        fetch_prune_cmd = ["git", "fetch", "-p"]
        subprocess.run(fetch_prune_cmd, check=True)
        print("Fetched changes and pruned obsolete branches")

    except subprocess.CalledProcessError as e:
        print(f"Error occurred while running Git commands: {e}")
    finally:
        # Always return to the original directory
        os.chdir(original_dir)


def get_current_version_from_toml(file_path="pyproject.toml"):
    """Reads the version from a pyproject.toml file."""
    try:
        with open(file_path, "r") as f:
            content = f.read()
        version_match = re.search(r'^version\s*=\s*"([^"]+)"', content, re.MULTILINE)
        if version_match:
            return version_match.group(1)
        else:
            raise ValueError(f"Could not find version string in {file_path}")
    except FileNotFoundError:
        raise FileNotFoundError(f"{file_path} not found.")
    except Exception as e:
        raise e


def build_and_upload_wheel(bump_part: str = "patch"):
    """Build a Python wheel and upload to PyPI using UV.

    Automatically increments the version number in pyproject.toml before building
    based on the bump_part argument ('major', 'minor', 'patch').

    Expects PyPI authentication to be configured via the environment variable:
    - UV_PUBLISH_TOKEN

    Args:
        bump_part (str): The part of the version to bump. Defaults to 'patch'.
    """
    if bump_part not in ["major", "minor", "patch"]:
        print(
            f"Error: Invalid bump_part '{bump_part}'. Must be 'major', 'minor', or 'patch'."
        )
        return

    # ANSI color codes
    BLUE = "\033[94m"
    RESET = "\033[0m"

    # --- Authentication Setup ---
    token = os.environ.get("UV_PUBLISH_TOKEN")

    if not token:
        print("Error: PyPI authentication not configured.")
        print(
            "Please set the UV_PUBLISH_TOKEN environment variable with your PyPI API token."
        )
        return

    # Build the command with token authentication
    # IMPORTANT: Mask token for printing
    publish_cmd_safe_print = ["uv", "publish", "--token", "*****"]
    publish_cmd = ["uv", "publish", "--token", token]
    print("Using UV_PUBLISH_TOKEN for authentication.")

    pyproject_path = "pyproject.toml"
    current_version = None  # Initialize in case the first try block fails

    try:
        # --- Clean dist directory ---
        dist_dir = Path("dist")
        if dist_dir.exists():
            print(f"Removing existing build directory: {dist_dir}")
            shutil.rmtree(dist_dir)
        # --- End Clean dist directory ---

        # --- Version Bumping Logic ---
        current_version = get_current_version_from_toml(pyproject_path)
        print(f"Current version: {current_version}")

        try:
            major, minor, patch = map(int, current_version.split("."))
        except ValueError:
            print(
                f"Error: Could not parse version '{current_version}'. Expected format X.Y.Z"
            )
            return

        if bump_part == "major":
            major += 1
            minor = 0
            patch = 0
        elif bump_part == "minor":
            minor += 1
            patch = 0
        else:  # patch
            patch += 1

        new_version = f"{major}.{minor}.{patch}"
        print(f"Bumping {bump_part} version to: {new_version}")

        # Read pyproject.toml
        with open(pyproject_path, "r") as f:
            content = f.read()

        # Replace the version string
        pattern = re.compile(
            f'^version\s*=\s*"{re.escape(current_version)}"', re.MULTILINE
        )
        new_content, num_replacements = pattern.subn(
            f'version = "{new_version}"', content
        )

        if num_replacements == 0:
            print(
                f"Error: Could not find 'version = \"{current_version}\"' in {pyproject_path}"
            )
            return  # Exit before build/publish if version wasn't updated
        if num_replacements > 1:
            print(
                f"Warning: Found multiple version lines for '{current_version}'. Only the first was updated."
            )

        # Write the updated content back
        with open(pyproject_path, "w") as f:
            f.write(new_content)
        print(f"Updated {pyproject_path} with version {new_version}")
        # --- End Version Bumping Logic ---

        # Build wheel and sdist
        build_cmd = ["uv", "build"]
        # Print command in blue
        print(f"Running command: {BLUE}{' '.join(build_cmd)}{RESET}")
        subprocess.run(build_cmd, check=True)

        # Upload using uv publish with explicit arguments
        # Print masked command in blue
        print(f"Running command: {BLUE}{' '.join(publish_cmd_safe_print)}{RESET}")
        subprocess.run(
            publish_cmd,  # Use the actual command with token
            check=True,
        )

        print(f"Successfully built and uploaded version {new_version} to PyPI")

    except FileNotFoundError:
        print(f"Error: {pyproject_path} not found.")
        # No version change happened, so no rollback needed
    except subprocess.CalledProcessError as e:
        print(f"Error during build/upload: {e}")
        # Attempt to roll back version change only if it was bumped successfully
        if current_version and new_version:
            try:
                print(
                    f"Attempting to revert version in {pyproject_path} back to {current_version}..."
                )
                with open(pyproject_path, "r") as f:
                    content_revert = f.read()
                # Use new_version in pattern for reverting
                pattern_revert = re.compile(
                    f'^version\s*=\s*"{re.escape(new_version)}"', re.MULTILINE
                )
                reverted_content, num_revert = pattern_revert.subn(
                    f'version = "{current_version}"', content_revert
                )
                if num_revert > 0:
                    with open(pyproject_path, "w") as f:
                        f.write(reverted_content)
                    print(f"Successfully reverted version in {pyproject_path}.")
                else:
                    print(
                        f"Warning: Could not find version {new_version} to revert in {pyproject_path}."
                    )
            except Exception as revert_e:
                print(
                    f"Warning: Failed to revert version change in {pyproject_path}: {revert_e}"
                )
    except Exception as e:
        print(f"An unexpected error occurred: {e}")
        # Also attempt rollback here if version was bumped
        if current_version and "new_version" in locals() and new_version:
            try:
                print(
                    f"Attempting to revert version in {pyproject_path} back to {current_version} due to unexpected error..."
                )
                # (Same revert logic as above)
                with open(pyproject_path, "r") as f:
                    content_revert = f.read()
                pattern_revert = re.compile(
                    f'^version\s*=\s*"{re.escape(new_version)}"', re.MULTILINE
                )
                reverted_content, num_revert = pattern_revert.subn(
                    f'version = "{current_version}"', content_revert
                )
                if num_revert > 0:
                    with open(pyproject_path, "w") as f:
                        f.write(reverted_content)
                    print(f"Successfully reverted version in {pyproject_path}.")
                else:
                    print(
                        f"Warning: Could not find version {new_version} to revert in {pyproject_path}."
                    )
            except Exception as revert_e:
                print(
                    f"Warning: Failed to revert version change in {pyproject_path}: {revert_e}"
                )


def update_dayhoff_tools():
    """Update dayhoff-tools to latest, update pyproject.toml, and sync.

    1. Runs `uv lock --upgrade-package dayhoff-tools`
    2. Parses uv.lock to find the new version.
    3. Updates the version constraint in pyproject.toml to `>=<new_version>`.
    4. Runs `uv sync --no-install-project`.
    """
    # ANSI color codes
    BLUE = "\033[94m"
    RESET = "\033[0m"

    lock_file_path = Path("uv.lock")
    pyproject_path = Path("pyproject.toml")

    try:
        print("Updating dayhoff-tools lock...")

        # Step 1: Update lock file for dayhoff-tools
        lock_cmd = ["uv", "lock", "--upgrade-package", "dayhoff-tools"]
        print(f"Running command: {BLUE}{' '.join(lock_cmd)}{RESET}")
        subprocess.run(lock_cmd, check=True)

        # Step 2: Parse uv.lock to find the new version
        print(f"Reading {lock_file_path} to find new version...")
        if not lock_file_path.exists():
            print(f"Error: {lock_file_path} not found after lock command.")
            return

        locked_version = None
        try:
            lock_data = toml.load(lock_file_path)
            # Find dayhoff-tools in the lock file packages
            for package in lock_data.get("package", []):
                if package.get("name") == "dayhoff-tools":
                    locked_version = package.get("version")
                    break
        except toml.TomlDecodeError as e:
            print(f"Error parsing {lock_file_path}: {e}")
            return
        except Exception as e:
            print(f"Error reading lock file: {e}")
            return

        if not locked_version:
            print(f"Error: Could not find dayhoff-tools version in {lock_file_path}.")
            return

        print(f"Found dayhoff-tools version {locked_version} in lock file.")

        # Step 3: Update pyproject.toml
        print(f"Updating {pyproject_path} version constraint...")
        try:
            content = pyproject_path.read_text()
            # Simplified Regex: Capture quoted package name "dayhoff-tools" (group 1),
            # match operators, then match non-quote/comma chars for version.
            pattern = re.compile(
                # Capture group 1: Start, whitespace, quote, "dayhoff-tools", quote, whitespace
                r"(^\\s*[\'\"](dayhoff-tools)[\'\"]\\s*)" +
                # Match version specifiers: operators followed by non-quote/comma chars
                r"[><=~^]*[^\'\",]*",
                re.MULTILINE,
            )
            new_constraint = f">= {locked_version}"
            new_content, num_replacements = pattern.subn(
                # Replace the whole match with group 1 + new constraint
                rf"\\1{new_constraint}",
                content,
            )

            if num_replacements > 0:
                pyproject_path.write_text(new_content)
                print(
                    f"Updated dayhoff-tools constraint in {pyproject_path} to '{new_constraint}'"
                )
            else:
                print(
                    f"Warning: Could not find dayhoff-tools dependency line in {pyproject_path} to update constraint."
                )

        except FileNotFoundError:
            print(f"Error: {pyproject_path} not found.")
            return
        except Exception as e:
            print(f"Error updating {pyproject_path}: {e}")
            # Continue to sync step even if pyproject update fails?
            # For now, let's proceed to sync.
            print("Proceeding with sync despite pyproject.toml update error.")

        # Step 4: Sync environment based on updated lock file
        print("Syncing environment...")
        # Adding --all-groups to ensure dev dependencies are synced too
        sync_cmd = ["uv", "sync", "--all-groups", "--no-install-project"]
        print(f"Running command: {BLUE}{' '.join(sync_cmd)}{RESET}")
        subprocess.run(sync_cmd, check=True)

        print(
            "dayhoff-tools updated, pyproject.toml modified, and environment synced successfully."
        )

    except subprocess.CalledProcessError as e:
        print(f"Error occurred during update/sync process: {e}")
    except FileNotFoundError:
        # This catches if uv command itself is not found
        print("Error: 'uv' command not found. Is uv installed and in PATH?")
        sys.exit(1)
    except Exception as e:
        # Catch any other unexpected errors
        print(f"An unexpected error occurred: {e}")


def sync_dependencies(
    install_project: bool = typer.Option(
        False,
        "--install-project",
        help="Install the local project package itself into the environment.",
    )
):
    """Update uv.lock and sync dependencies based on pyproject.toml.

    By default, installs all declared dependencies without building/installing
    the local project itself (--no-install-project). Use --install-project to
    include the local project.
    """
    # ANSI color codes
    BLUE = "\033[94m"
    RESET = "\033[0m"

    try:
        lock_cmd = ["uv", "lock"]
        # Print command in blue
        print(f"Running command: {BLUE}{' '.join(lock_cmd)}{RESET}")
        subprocess.run(lock_cmd, check=True)

        sync_cmd = ["uv", "sync", "--all-groups"]
        if not install_project:
            sync_cmd.append("--no-install-project")

        # Print command in blue
        print(f"Running command: {BLUE}{' '.join(sync_cmd)}{RESET}")
        subprocess.run(sync_cmd, check=True)

        print("Dependencies synced successfully.")
    except subprocess.CalledProcessError as e:
        print(f"Error occurred during dependency sync: {e}")
        sys.exit(1)
    except FileNotFoundError:
        print("Error: 'uv' command not found. Is uv installed and in PATH?")
        sys.exit(1)
