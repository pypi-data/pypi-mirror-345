"""CLI commands common to all repos."""

import os
import re
import subprocess
import sys
from pathlib import Path

import yaml


def test_github_actions_locally():
    """Run the script test_pytest_in_github_actions_container.sh.sh."""
    script_path = ".devcontainer/scripts/test_pytest_in_github_actions_container.sh"

    try:
        subprocess.check_call(["bash", script_path])
        print("Script ran successfully!")
    except subprocess.CalledProcessError as e:
        print(f"Error occurred while running the script: {e}")


def rebuild_devcontainer_file():
    """Run the script prepare_for_build.py."""
    script_path = ".devcontainer/scripts/prepare_for_build.py"

    try:
        subprocess.check_call([sys.executable, script_path])
        print("Script ran successfully!")
    except subprocess.CalledProcessError as e:
        print(f"Error occurred while running the script: {e}")


def get_ancestry(filepath: str) -> None:
    """Take a .dvc file created from import, and generate an ancestry entry
    that can be manually copied into other .dvc files."""
    with open(filepath, "r") as file:
        assert filepath.endswith(".dvc"), "ERROR: Not a .dvc file"
        ancestor_content = yaml.safe_load(file)

        error_msg = "Unexpected file structure. Are you sure this is a .dvc file generated from `dvc import`?"
        assert "deps" in ancestor_content, error_msg

        error_msg = "Please only reference data imported from main branches."
        assert "rev" not in ancestor_content["deps"][0]["repo"], error_msg

        ancestor_info = {
            "name": os.path.basename(ancestor_content["outs"][0]["path"]),
            "file_md5_hash": ancestor_content["outs"][0]["md5"],
            "size": ancestor_content["outs"][0]["size"],
            "repo_url": ancestor_content["deps"][0]["repo"]["url"],
            "repo_path": ancestor_content["deps"][0]["path"],
            "commit_hash": ancestor_content["deps"][0]["repo"]["rev_lock"],
        }
        print()
        yaml.safe_dump(
            [ancestor_info], sys.stdout, default_flow_style=False, sort_keys=False
        )


def import_from_warehouse_typer() -> None:
    """Import a file from warehouse.
    This is a thin wrapper around `cli.utils.import_from_warehouse`,
    with interactive prompts using questionary.
    """
    # Import only when the function is called
    import questionary
    from dayhoff_tools.warehouse import import_from_warehouse

    # Ensure execution from root
    cwd = Path(os.getcwd())
    if cwd.parent.name != "workspaces" or str(cwd.parent.parent) != cwd.root:
        raise Exception(
            f"This command must be executed from the repo's root directory (/workspaces/reponame). Current directory: {cwd}"
        )

    # Use questionary for prompts instead of typer
    warehouse_path = questionary.text("Warehouse path:").ask()

    # Provide multiple-choice options for output folder
    output_folder_choice = questionary.select(
        "Output folder:",
        choices=["data/imports", "same_as_warehouse", "Custom path..."],
    ).ask()

    # If custom path is selected, ask for the path
    if output_folder_choice == "Custom path...":
        output_folder = questionary.text("Enter custom output folder:").ask()
    else:
        output_folder = output_folder_choice

    branch = questionary.text("Branch (default: main):", default="main").ask()

    final_path = import_from_warehouse(
        warehouse_path=warehouse_path,
        output_folder=output_folder,
        branch=branch,
    )


def add_to_warehouse_typer() -> None:
    """Add a new data file to warehouse, and expand its .dvc file with
    metadata, including ancestor files."""
    # Import only when the function is called
    import questionary
    from dayhoff_tools.warehouse import add_to_warehouse

    # Ensure execution from root
    cwd = Path(os.getcwd())
    if cwd.parent.name != "workspaces" or str(cwd.parent.parent) != cwd.root:
        raise Exception(
            f"This command must be executed from the repo's root directory (/workspaces/reponame). Current directory: {cwd}"
        )

    # Prompt for the data file path
    warehouse_path = questionary.text("Data file to be registered:").ask()

    # Prompt for the ancestor .dvc file paths
    ancestor_dvc_paths = []
    print("\nEnter the path of all ancestor .dvc files (or hit Enter to finish).")
    print("These files must be generated by `dvc import` or `dh wimport`.")
    while True:
        ancestor_path = questionary.text("Ancestor path: ").ask()
        if ancestor_path:
            ancestor_dvc_paths.append(ancestor_path)
        else:
            print()
            break

    dvc_path = add_to_warehouse(
        warehouse_path=warehouse_path,
        ancestor_dvc_paths=ancestor_dvc_paths,
    )


def delete_local_branch(branch_name: str, folder_path: str):
    """Delete a local Git branch after fetching with pruning.

    Args:
        branch_name: Name of the branch to delete
        folder_path: Path to the git repository folder
    """
    try:
        # Store current working directory
        original_dir = os.getcwd()

        # Change to the specified directory
        os.chdir(folder_path)
        print(f"Changed to directory: {folder_path}")

        # Delete the specified branch
        delete_branch_cmd = ["git", "branch", "-D", branch_name]
        subprocess.run(delete_branch_cmd, check=True)
        print(f"Deleted branch: {branch_name}")

        # Fetch changes from the remote repository and prune obsolete branches
        fetch_prune_cmd = ["git", "fetch", "-p"]
        subprocess.run(fetch_prune_cmd, check=True)
        print("Fetched changes and pruned obsolete branches")

    except subprocess.CalledProcessError as e:
        print(f"Error occurred while running Git commands: {e}")
    finally:
        # Always return to the original directory
        os.chdir(original_dir)


def get_current_version_from_toml(file_path="pyproject.toml"):
    """Reads the version from a pyproject.toml file."""
    try:
        with open(file_path, "r") as f:
            content = f.read()
        version_match = re.search(r'^version\s*=\s*"([^"]+)"', content, re.MULTILINE)
        if version_match:
            return version_match.group(1)
        else:
            raise ValueError(f"Could not find version string in {file_path}")
    except FileNotFoundError:
        raise FileNotFoundError(f"{file_path} not found.")
    except Exception as e:
        raise e


def build_and_upload_wheel(bump_part: str = "patch"):
    """Build a Python wheel and upload to PyPI.

    Automatically increments the version number in pyproject.toml before building.
    Use the bump_part argument to specify major, minor, or patch increment.
    For example: 1.2.3 -> 1.2.4 (patch), 1.3.0 (minor), 2.0.0 (major)

    Expects the PyPI API token to be available in the PYPI_API_TOKEN environment variable.

    Args:
        bump_part (str): The part of the version to bump: 'major', 'minor', or 'patch'. Defaults to 'patch'.
    """
    if bump_part not in ["major", "minor", "patch"]:
        print(
            f"Error: Invalid bump_part '{bump_part}'. Must be 'major', 'minor', or 'patch'."
        )
        return

    pypi_token = os.environ.get("PYPI_API_TOKEN")
    if not pypi_token:
        print("Error: PYPI_API_TOKEN environment variable not set.")
        print("Please set it with your PyPI API token before running this command.")
        return

    try:
        # Get the current version before bumping
        current_version = get_current_version_from_toml()
        print(f"Current version: {current_version}")

        # Use poetry to bump the version in pyproject.toml
        print(f"Bumping {bump_part} version using poetry...")
        subprocess.run(["poetry", "version", bump_part], check=True)

        # Get the new version after bumping
        new_version = get_current_version_from_toml()
        print(f"New version: {new_version}")

        # Disable keyring to avoid issues in containers/CI
        print("Disabling Poetry keyring...")
        subprocess.run(
            ["poetry", "config", "keyring.enabled", "false"],
            check=True,
            capture_output=True,
        )

        # Configure Poetry with the API token
        print("Configuring Poetry with PyPI token...")
        subprocess.run(
            ["poetry", "config", "pypi-token.pypi", pypi_token],
            check=True,
            capture_output=True,  # Hide token from output
        )

        # Build and upload
        print("Building and uploading wheel to PyPI...")
        subprocess.run(
            [
                "poetry",
                "publish",
                "--build",
            ],
            check=True,
        )

        print(f"Successfully built and uploaded version {new_version} to PyPI")

    except subprocess.CalledProcessError as e:
        print(f"Error during build/upload: {e}")
    except Exception as e:
        print(f"An unexpected error occurred: {e}")


def update_dayhoff_tools():
    """Update the dayhoff-tools package to the latest version using poetry."""
    try:
        print("Updating dayhoff-tools to the latest version...")
        subprocess.run(["poetry", "update", "dayhoff-tools"], check=True)
        print("Update complete!")
    except subprocess.CalledProcessError as e:
        print(f"Error occurred while updating: {e}")
        sys.exit(1)
    except FileNotFoundError:
        print("Error: 'poetry' command not found. Make sure Poetry is installed.")
        sys.exit(1)
