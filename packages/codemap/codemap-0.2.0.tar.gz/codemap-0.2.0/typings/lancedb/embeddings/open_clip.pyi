"""
This type stub file was generated by pyright.
"""

import numpy as np
import PIL
from typing import List, TYPE_CHECKING, Union
from .base import EmbeddingFunction
from .registry import register
from .utils import IMAGES

if TYPE_CHECKING:
    ...
@register("open-clip")
class OpenClipEmbeddings(EmbeddingFunction):
    """
    An embedding function that uses the OpenClip API
    For multi-modal text-to-image search

    https://github.com/mlfoundations/open_clip
    """
    name: str = ...
    pretrained: str = ...
    device: str = ...
    batch_size: int = ...
    normalize: bool = ...
    _model = ...
    _preprocess = ...
    _tokenizer = ...
    def __init__(self, *args, **kwargs) -> None:
        ...
    
    def ndims(self): # -> int:
        ...
    
    def compute_query_embeddings(self, query: Union[str, PIL.Image.Image], *args, **kwargs) -> List[np.ndarray]:
        """
        Compute the embeddings for a given user query

        Parameters
        ----------
        query : Union[str, PIL.Image.Image]
            The query to embed. A query can be either text or an image.
        """
        ...
    
    def generate_text_embeddings(self, text: str) -> np.ndarray:
        ...
    
    def sanitize_input(self, images: IMAGES) -> Union[List[bytes], np.ndarray]:
        """
        Sanitize the input to the embedding function.
        """
        ...
    
    def compute_source_embeddings(self, images: IMAGES, *args, **kwargs) -> List[np.array]:
        """
        Get the embeddings for the given images
        """
        ...
    
    def generate_image_embedding(self, image: Union[str, bytes, PIL.Image.Image]) -> np.ndarray:
        """
        Generate the embedding for a single image

        Parameters
        ----------
        image : Union[str, bytes, PIL.Image.Image]
            The image to embed. If the image is a str, it is treated as a uri.
            If the image is bytes, it is treated as the raw image bytes.
        """
        ...
    


