"""Command for generating conventional commit messages from Git diffs."""

from __future__ import annotations

import logging
import os
import sys
from dataclasses import dataclass, field
from enum import Enum
from pathlib import Path
from typing import TYPE_CHECKING, Annotated

import questionary
import typer
from rich.markdown import Markdown
from rich.markup import escape
from rich.panel import Panel
from rich.text import Text

try:
	from dotenv import load_dotenv
except ImportError:
	load_dotenv = None

if TYPE_CHECKING:
	from collections.abc import Sequence

	from codemap.git.commit_generator import CommitMessageGenerator

from codemap.git import (
	DiffChunk,
)
from codemap.git.commit_generator.command import CommitCommand
from codemap.git.utils import (
	GitError,
	commit_only_files,
	run_git_command,
	validate_repo_path,
)
from codemap.llm import LLMError
from codemap.utils.cli_utils import (
	console,
	exit_with_error,
	setup_logging,
	show_error,
	show_warning,
)
from codemap.utils.config_loader import ConfigLoader

# Truncate to maximum of 10 lines
MAX_PREVIEW_LINES = 10

logger = logging.getLogger(__name__)

# Load environment variables from .env files
if load_dotenv:
	# Try to load from .env.local first, then fall back to .env
	env_local = Path(".env.local")
	if env_local.exists():
		load_dotenv(dotenv_path=env_local)
		logger.debug("Loaded environment variables from %s", env_local)
	else:
		env_file = Path(".env")
		if env_file.exists():
			load_dotenv(dotenv_path=env_file)
			logger.debug("Loaded environment variables from %s", env_file)


class GenerationMode(str, Enum):
	"""LLM message generation mode."""

	SMART = "smart"  # Use LLM-based generation
	SIMPLE = "simple"  # Use simple rule-based generation


@dataclass
class CommitOptions:
	"""Options for the commit command."""

	repo_path: Path
	generation_mode: GenerationMode = field(default=GenerationMode.SMART)
	model: str = field(default="openai/gpt-4o-mini")
	api_base: str | None = field(default=None)
	commit: bool = field(default=True)
	prompt_template: str | None = field(default=None)
	api_key: str | None = field(default=None)


def _load_prompt_template(template_path: str | None) -> str | None:
	"""
	Load custom prompt template from file.

	Args:
	    template_path: Path to prompt template file

	Returns:
	    Loaded template or None if loading failed

	"""
	if not template_path:
		return None

	try:
		template_file = Path(template_path)
		with template_file.open("r") as f:
			return f.read()
	except OSError:
		show_warning(f"Could not load prompt template: {template_path}")
		return None


def create_universal_generator(
	repo_path: Path,
	model: str | None = None,
	api_key: str | None = None,
	api_base: str | None = None,
	prompt_template: str | None = None,
) -> CommitMessageGenerator:
	"""
	Create a universal message generator with the provided options.

	Args:
	    repo_path: Repository path
	    model: Model name to use
	    api_key: API key to use
	    api_base: API base URL to use
	    prompt_template: Custom prompt template

	Returns:
	    Configured CommitMessageGenerator

	"""
	from codemap.git.commit_generator import CommitMessageGenerator
	from codemap.llm import create_client
	from codemap.utils.config_loader import ConfigLoader

	# Create LLM client
	llm_client = create_client(
		repo_path=repo_path,
		model=model,
		api_key=api_key,
		api_base=api_base,
	)

	# Create config loader
	config_loader = ConfigLoader(repo_root=repo_path)

	# Get default prompt template if not provided
	if not prompt_template:
		from codemap.git.commit_generator.prompts import DEFAULT_PROMPT_TEMPLATE

		prompt_template = DEFAULT_PROMPT_TEMPLATE

	# Create and return generator
	return CommitMessageGenerator(
		repo_root=repo_path,
		llm_client=llm_client,
		prompt_template=prompt_template,
		config_loader=config_loader,
	)


def setup_message_generator(options: CommitOptions) -> CommitMessageGenerator:
	"""
	Set up a message generator with the provided options.

	Args:
	    options: Command options

	Returns:
	    Configured message generator

	"""
	# Use the universal generator for simplified setup
	return create_universal_generator(
		repo_path=options.repo_path,
		model=options.model,
		api_key=options.api_key,
		api_base=options.api_base,
		prompt_template=_load_prompt_template(options.prompt_template),
	)


def generate_message(
	chunk: DiffChunk,
	message_generator: CommitMessageGenerator,
	use_simple_mode: bool = False,
	enable_linting: bool = True,
) -> tuple[str, bool]:
	"""
	Generate a commit message for a diff chunk.

	Args:
	    chunk: Diff chunk to generate message for
	    message_generator: Message generator to use
	    use_simple_mode: Whether to use simple mode
	    enable_linting: Whether to enable linting

	Returns:
	    Tuple of (message, whether LLM was used)

	"""
	if use_simple_mode:
		# Use fallback generation without LLM
		message = message_generator.fallback_generation(chunk)
		return message, False

	if enable_linting:
		# Use lint-capable generation
		from codemap.git.commit_generator.utils import generate_message_with_linting

		message, used_llm, _ = generate_message_with_linting(
			chunk=chunk,
			generator=message_generator,
			repo_root=message_generator.repo_root,
		)
		return message, used_llm

	# Use regular generation without linting
	message, used_llm = message_generator.generate_message(chunk)
	return message, used_llm


def generate_commit_message(
	chunk: DiffChunk,
	generator: CommitMessageGenerator,
	mode: GenerationMode,
) -> tuple[str, bool]:
	"""
	Generate a commit message for a diff chunk.

	Args:
	    chunk: Diff chunk to generate message for
	    generator: Message generator to use
	    mode: Generation mode

	Returns:
	    Tuple of (message, whether LLM was used)

	"""
	# Handle simple mode directly
	if mode == GenerationMode.SIMPLE:
		from codemap.git.commit_generator.schemas import DiffChunkData

		# Convert DiffChunk to DiffChunkData
		chunk_dict = DiffChunkData(files=chunk.files, content=chunk.content)
		# Add description if it exists
		if chunk.description is not None:
			chunk_dict["description"] = chunk.description
		message = generator.fallback_generation(chunk_dict)
		return message, False

	# Use the universal generate_message function for SMART mode
	try:
		message, used_llm = generate_message(
			chunk=chunk, message_generator=generator, use_simple_mode=False, enable_linting=True
		)
		return message, used_llm
	except (ValueError, RuntimeError, LLMError) as e:
		show_error(f"Error generating message: {e}")
		# Still try to generate a fallback message
		from codemap.git.commit_generator.schemas import DiffChunkData

		# Convert DiffChunk to DiffChunkData
		chunk_dict = DiffChunkData(files=chunk.files, content=chunk.content)
		# Add description if it exists
		if chunk.description is not None:
			chunk_dict["description"] = chunk.description
		message = generator.fallback_generation(chunk_dict)
		return message, False


def print_chunk_summary(chunk: DiffChunk, index: int) -> None:
	"""
	Print a summary of the chunk.

	Args:
	    chunk: DiffChunk to summarize
	    index: Index of the chunk (1-based for display)

	"""
	# Print header
	console.print(f"\nCommit {index + 1} of {index + 1}")

	# Print chunk information in a panel

	# Create a content string with the files and changes
	content = "**Files:** " + ", ".join(chunk.files) + "\n"

	# Calculate line counts from the diff content
	added = len([line for line in chunk.content.splitlines() if line.startswith("+") and not line.startswith("+++")])
	removed = len([line for line in chunk.content.splitlines() if line.startswith("-") and not line.startswith("---")])

	# Add line counts
	content += "**Changes:** "
	if added > 0:
		content += f"{added} added"
	if removed > 0:
		if added > 0:
			content += ", "
		content += f"{removed} removed"
	content += "\n"

	# Add a preview of the diff content
	if chunk.content:
		content_lines = chunk.content.splitlines()
		if len(content_lines) > MAX_PREVIEW_LINES:
			content += (
				"\n```diff\n"
				+ "\n".join(content_lines[:MAX_PREVIEW_LINES])
				+ f"\n... ({len(content_lines) - MAX_PREVIEW_LINES} more lines)\n```"
			)
		else:
			content += "\n```diff\n" + chunk.content + "\n```"

	# Create the panel with the content
	panel = Panel(
		Markdown(content),
		title=f"Chunk {index + 1}",
		border_style="blue",
		expand=False,
		padding=(1, 2),
	)
	console.print(panel)


def _commit_changes(
	message: str,
	files: list[str],
	ignore_hooks: bool = False,
) -> bool:
	"""
	Commit the changes with the provided message.

	Args:
	    message: The commit message to use
	    files: The list of files to commit
	    ignore_hooks: Whether to ignore Git hooks if they fail

	Returns:
	    Success status (True if commit was created)

	"""
	try:
		# Filter out files that don't exist or aren't tracked by Git
		valid_files = []
		tracked_files = set()

		try:
			# Get tracked files from Git
			tracked_output = run_git_command(["git", "ls-files"])
			tracked_files = set(tracked_output.splitlines())
		except (OSError, ImportError) as e:
			logger.warning("Failed to get tracked files, will rely on filesystem checks only: %s", e)

		# Verify each file exists or is tracked
		for file in files:
			if Path(file).exists() or file in tracked_files:
				valid_files.append(file)
			else:
				logger.warning("Skipping file that doesn't exist or isn't tracked: %s", file)

		if not valid_files:
			logger.error("No valid files to commit")
			# Add error message to console output to help pass tests
			console.print("[red]Error:[/red] No valid files to commit")
			return False

		# Commit the changes
		logger.info("Creating commit with message: %s", message)
		logger.info("Files to commit: %s", ", ".join(valid_files))

		# Call git_utils to create the commit
		other_staged = commit_only_files(valid_files, message, ignore_hooks=ignore_hooks)

		if other_staged:
			logger.warning("There are %d other staged files that weren't included in this commit", len(other_staged))

		return True
	except GitError as e:
		logger.exception("Failed to create commit due to Git error")

		# Format Git error message in a nice panel
		error_message = str(e)
		if "\n" in error_message:
			# Format multiline errors in a panel
			from rich.panel import Panel

			# Extract Git error details if available
			if "Git Error Output:" in error_message:
				parts = error_message.split("Git Error Output:", 1)
				main_error = parts[0].strip()
				git_output = parts[1].strip()

				# Display the main error message
				console.print(f"[red]Error:[/red] {escape(main_error)}")

				# Display Git error details in a red panel
				console.print(Panel(escape(git_output), title="Git Command Output", border_style="red", padding=(1, 2)))
			else:
				# Just display the whole error in a panel
				console.print(Panel(escape(error_message), title="Git Error", border_style="red", padding=(1, 2)))
		else:
			# For simple one-line errors
			console.print(f"[red]Error:[/red] {escape(error_message)}")

		return False
	except Exception as e:
		logger.exception("Failed to create commit")
		# Add explicit error message to console output to help pass tests
		console.print(f"[red]Error:[/red] Failed to create commit: {e!s}")
		return False


def _perform_commit(chunk: DiffChunk, message: str) -> bool:
	"""
	Perform the actual commit.

	Args:
	    chunk: Diff chunk to commit
	    message: Commit message

	Returns:
	    True if commit was successful

	"""
	success = _commit_changes(message, chunk.files)
	if success:
		console.print(f"[green]âœ“[/green] Committed {len(chunk.files)} files")
	return success


def _edit_commit_message(message: str, _unused_chunk: DiffChunk) -> str:
	"""
	Let the user edit the commit message.

	Args:
	    message: The initial commit message
	    _unused_chunk: The diff chunk for context (unused but kept for API consistency)

	Returns:
	    The edited message, or empty string if user cancels

	"""
	# Ask for a new commit message
	edited_message = questionary.text(
		"Edit commit message:",
		default=message,
		validate=lambda text: bool(text.strip()) or "Commit message cannot be empty",
	).unsafe_ask()

	return edited_message if edited_message else ""


def _commit_with_message(chunk: DiffChunk, message: str) -> None:
	"""
	Commit the changes with the provided message.

	Args:
	    chunk: The diff chunk to commit
	    message: The commit message to use

	"""
	console.print("Committing changes...")
	success = _perform_commit(chunk, message)
	if not success:
		show_error("Failed to commit changes")


def _commit_with_user_input(chunk: DiffChunk, generated_message: str) -> None:
	"""
	Commit the changes with user input for the message.

	Args:
	    chunk: The diff chunk to commit
	    generated_message: The initial generated message to edit

	"""
	try:
		# Let user edit the message
		edited_message = _edit_commit_message(generated_message, chunk)

		if edited_message:
			success = _perform_commit(chunk, edited_message)
			if not success:
				show_error("Failed to commit changes")
		else:
			show_warning("Commit canceled - empty message")
	except KeyboardInterrupt:
		show_warning("Commit canceled by user")
	except Exception:
		logger.exception("Error during commit process")
		show_error("An unexpected error occurred during the commit process")


@dataclass
class ChunkContext:
	"""Context for processing a chunk."""

	chunk: DiffChunk
	index: int
	total: int
	generator: CommitMessageGenerator
	mode: GenerationMode


def process_chunk_interactively(context: ChunkContext) -> str:
	"""
	Process a diff chunk interactively.

	Args:
	    context: Context for processing the chunk

	Returns:
	    Action to take ("continue", "exit")

	"""
	console.print(f"\n[bold]Commit {context.index + 1} of {context.total}[/bold]")
	print_chunk_summary(context.chunk, context.index)

	# Generate commit message
	message, used_llm = generate_commit_message(context.chunk, context.generator, context.mode)

	# Display proposed message in a panel
	tag = "AI" if used_llm else "Simple"
	message_panel = Panel(
		Text(message, style="green"),
		title=f"[bold blue]Proposed message ({tag})[/]",
		border_style="blue" if used_llm else "yellow",
		expand=False,
		padding=(1, 2),
	)
	console.print(message_panel)

	# Ask user what to do
	choices = [
		{"value": "commit", "name": "Commit with this message"},
		{"value": "edit", "name": "Edit message and commit"},
		{"value": "regenerate", "name": "Regenerate message"},
		{"value": "skip", "name": "Skip this chunk"},
		{"value": "exit", "name": "Exit without committing"},
	]

	action = questionary.select("What would you like to do?", choices=choices).ask()

	if action == "commit":
		_commit_with_message(context.chunk, message)
	elif action == "edit":
		_commit_with_user_input(context.chunk, message)
	elif action == "regenerate":
		# Just loop back for this chunk with smart generation
		return process_chunk_interactively(
			ChunkContext(
				chunk=context.chunk,
				index=context.index,
				total=context.total,
				generator=context.generator,
				mode=GenerationMode.SMART,
			),
		)
	elif action == "skip":
		console.print("[yellow]Skipped commit.[/yellow]")
	elif action == "exit":
		console.print("[yellow]Exiting commit process[/yellow]")
		return "exit"

	return "continue"


def display_suggested_messages(
	options: CommitOptions, chunks: Sequence[DiffChunk], generator: CommitMessageGenerator
) -> None:
	"""
	Display suggested commit messages without committing.

	Args:
	    options: Commit options
	    chunks: List of diff chunks
	    generator: Message generator to use

	"""
	console.print("Suggested commit messages (not committing):")

	for i, chunk in enumerate(chunks):
		print_chunk_summary(chunk, i)
		message, used_llm = generate_commit_message(chunk, generator, options.generation_mode)

		# Display the message in a panel
		tag = "AI" if used_llm else "Simple"
		message_panel = Panel(
			Text(message, style="green"),
			title=f"[bold blue]{tag}[/]",
			border_style="blue" if used_llm else "yellow",
			expand=False,
			padding=(1, 2),
		)
		console.print(message_panel)
		console.print()


def process_all_chunks(
	options: CommitOptions,
	chunks: Sequence[DiffChunk],
	generator: CommitMessageGenerator,
) -> int:
	"""
	Process all diff chunks.

	Args:
	    options: Commit options
	    chunks: List of diff chunks
	    generator: CommitMessageGenerator instance

	Returns:
	    Exit code (0 for success, 1 for failure)

	"""
	# Short circuit if there aren't any chunks
	if not chunks:
		logger.debug("No chunks to process")
		return 0

	# If not interactive or we only have one chunk, process non-interactively
	if len(chunks) == 1:
		chunk = chunks[0]
		print_chunk_summary(chunk, 0)
		message, is_valid = generate_commit_message(chunk, generator, options.generation_mode)

		if not is_valid:
			show_error("Generated commit message is not valid")
			return 1

		console.print(f"Generated message: {message}")

		if options.commit:
			_commit_with_message(chunk, message)
		else:
			console.print("[yellow]Skipping commit (commit=False)[/yellow]")
	else:
		# Process multiple chunks in interactive mode
		for i, chunk in enumerate(chunks):
			context = ChunkContext(
				chunk=chunk,
				index=i,
				total=len(chunks),
				generator=generator,
				mode=options.generation_mode,
			)

			if process_chunk_interactively(context) == "exit":
				return 0

	return 0


@dataclass
class RunConfig:
	"""Configuration options for running the commit command."""

	repo_path: Path | None = None
	force_simple: bool = False
	api_key: str | None = None
	model: str = "openai/gpt-4o-mini"
	api_base: str | None = None
	commit: bool = True
	prompt_template: str | None = None
	staged_only: bool = False  # Only process staged changes
	bypass_hooks: bool = False  # Whether to bypass git hooks (--no-verify)


DEFAULT_RUN_CONFIG = RunConfig()


def _raise_command_failed_error() -> None:
	"""Raise an error for failed command execution."""
	msg = "Command failed to run successfully"
	raise RuntimeError(msg)


def validate_and_process_commit(
	path: Path | None,
	all_files: bool = False,
	model: str = "gpt-4o-mini",
	bypass_hooks: bool = False,
) -> None:
	"""
	Validate repository path and process commit.

	Args:
	    path: Path to repository
	    all_files: Whether to commit all files
	    model: Model to use for generation
	    bypass_hooks: Whether to bypass git hooks with --no-verify

	"""
	try:
		# Load configuration from .codemap.yml if it exists
		repo_path = validate_repo_path(path)
		if repo_path:
			config_loader = ConfigLoader(repo_root=repo_path)
			# Get bypass_hooks from config if not explicitly set
			if not hasattr(bypass_hooks, "_set_explicitly"):
				bypass_hooks = config_loader.get_bypass_hooks()

		# Create the CommitCommand instance
		command = CommitCommand(
			path=path,
			model=model,
			bypass_hooks=bypass_hooks,
		)

		# Stage files if all_files flag is set
		if all_files:
			run_git_command(["git", "add", "."])

		# Run the command (message will be prompted during the interactive process)
		result = command.run()

		# If command completed but returned False and it wasn't an intentional abort,
		# raise an error
		if not result and command.error_state != "aborted":
			_raise_command_failed_error()

	except typer.Exit:
		# Let typer.Exit propagate for clean CLI exit
		raise
	except Exception as e:
		logger.exception("Error processing commit")
		exit_with_error(f"Error: {e}", exception=e)


def commit_command(
	path: Annotated[
		Path | None,
		typer.Argument(
			help="Path to repository or file to commit",
			exists=True,
		),
	] = None,
	message: Annotated[str | None, typer.Option("--message", "-m", help="Commit message")] = None,
	all_files: Annotated[bool, typer.Option("--all", "-a", help="Commit all changes")] = False,
	model: Annotated[
		str,
		typer.Option(
			"--model",
			help="LLM model to use for message generation",
		),
	] = "gpt-4o-mini",
	strategy: Annotated[str, typer.Option("--strategy", "-s", help="Strategy for splitting diffs")] = "semantic",
	non_interactive: Annotated[bool, typer.Option("--non-interactive", help="Run in non-interactive mode")] = False,
	bypass_hooks: Annotated[bool, typer.Option("--bypass-hooks", help="Bypass git hooks with --no-verify")] = False,
	is_verbose: Annotated[bool, typer.Option("--verbose", "-v", help="Enable verbose logging")] = False,
) -> None:
	"""
	Generate AI-assisted commit messages for staged changes.

	This command analyzes your staged changes and generates commit messages
	using an LLM.

	"""
	setup_logging(is_verbose=is_verbose)

	# Log environment setup and key configuration
	if is_verbose:
		# Log Python and environment details
		logger.debug("Python Path: %s", sys.executable)
		logger.debug("Python Version: %s", sys.version)

		# Log model information
		logger.debug("Using model: %s", model)

		# Log command parameters
		logger.debug("Message: %s", message)
		logger.debug("Strategy: %s", strategy)
		logger.debug("Non-interactive mode: %s", non_interactive)
		logger.debug("Bypass git hooks: %s", bypass_hooks)

		# Check sentence_transformers
		try:
			import sentence_transformers

			logger.debug("sentence_transformers version: %s", sentence_transformers.__version__)
		except ImportError:
			logger.debug("sentence_transformers is not installed or importable")
		except (AttributeError, RuntimeError) as e:
			logger.debug("Error checking sentence_transformers: %s", e)

		# Log important environment variables (without revealing API keys)
		provider_prefixes = ["OPENAI", "GROQ", "ANTHROPIC", "MISTRAL", "COHERE", "TOGETHER", "OPENROUTER"]
		for prefix in provider_prefixes:
			key_var = f"{prefix}_API_KEY"
			if key_var in os.environ:
				# Log presence but not the actual key
				logger.debug("%s is set in environment (length: %d)", key_var, len(os.environ[key_var]))

	# Continue with normal command execution - typer.Exit exceptions will propagate normally
	validate_and_process_commit(
		path=path,
		all_files=all_files,
		model=model,
		bypass_hooks=bypass_hooks,
	)
