{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enderim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# Definer datamappen\n",
    "DATADIR = Path(\"/home/ingeridd/prosjekter/dikt-utforskning/data\")\n",
    "\n",
    "DATADIR.exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annoter enderim for tekst og transkripsjoner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Det første vi gjør er å lese inn diktene og annotere enderimene, og laste resultatene inn i en dataramme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lister med diktfilene\n",
    "poem_txt_files = list(DATADIR.glob(\"**/*.txt\"))\n",
    "poem_json_files = list(DATADIR.glob(\"**/*østnorsk.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from poetry_analysis import rhyme_detection as rd\n",
    "\n",
    "\n",
    "def load_rhyme_df(filepath: Path) -> pd.DataFrame:\n",
    "    filename = filepath.stem\n",
    "    pronfile = filepath.parent / f\"{filename}_østnorsk.json\"\n",
    "\n",
    "    if not pronfile.exists():\n",
    "        raise FileNotFoundError(f\"Pronunciation file {pronfile} does not exist.\")\n",
    "\n",
    "    df_pron = (\n",
    "        pd.DataFrame(rd.tag_poem_file(pronfile))\n",
    "        .explode(\"verses\")\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    df_text = (\n",
    "        pd.DataFrame(rd.tag_poem_file(filepath))\n",
    "        .explode(\"verses\")\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    text_verses = df_text.verses.apply(pd.Series)\n",
    "    transcribed_verses = df_pron.verses.apply(pd.Series)\n",
    "\n",
    "    verses = transcribed_verses.drop(columns=[\"text\", \"tokens\"]).merge(\n",
    "        text_verses[\n",
    "            [\"text\", \"tokens\", \"last_token\", \"rhyme_tag\", \"rhymes_with\", \"rhyme_score\"]\n",
    "        ],\n",
    "        left_index=True,\n",
    "        right_index=True,\n",
    "        suffixes=(\"_syll\", \"_text\"),\n",
    "    )\n",
    "\n",
    "    df = df_pron[[\"stanza_id\", \"rhyme_scheme\"]].merge(\n",
    "        verses, left_index=True, right_index=True\n",
    "    )\n",
    "    df = df.rename(\n",
    "        columns={\"stanza_id\": \"stanza\", \"rhyme_scheme\": \"rhyme\", \"verse_id\": \"verse\"}\n",
    "    )\n",
    "\n",
    "    df[\"filename\"] = filename\n",
    "    df[\"poem\"] = filename.split(\"_\")[0]\n",
    "    ordered_columns = [\n",
    "        \"filename\",\n",
    "        \"poem\",\n",
    "        \"stanza\",\n",
    "        \"rhyme\",\n",
    "        \"verse\",\n",
    "        \"rhymes_with_text\",\n",
    "        \"rhymes_with_syll\",\n",
    "        \"rhyme_score_text\",\n",
    "        \"rhyme_score_syll\",\n",
    "        \"rhyme_tag_text\",\n",
    "        \"rhyme_tag_syll\",\n",
    "        \"last_token_text\",\n",
    "        \"last_token_syll\",\n",
    "        \"text\",\n",
    "        \"transcription\",\n",
    "        \"tokens\",\n",
    "        \"syllables\",\n",
    "    ]\n",
    "    return df[ordered_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [load_rhyme_df(textfile) for textfile in poem_txt_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_44350/69934419.py:1: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat(dfs, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['dag', 'os', 'slag', ..., 'vek', 'smelter', 'fagnaljo'],\n",
       "      shape=(4818,), dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.last_token_text.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Hent ut de mest brukte rimmønstrene for alle strofene\n",
    "scheme_counter = Counter(\n",
    "    [pattern for schemes in rhymepatterns.values() for pattern in schemes]\n",
    ")\n",
    "\n",
    "scheme_counter.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se nærmere på antall dikt som har et bestemt rimmønster\n",
    "most_common_schemes = [\n",
    "    poem_id for poem_id, schemes in rhymepatterns.items() if \"abcd\" in schemes\n",
    "]\n",
    "len(most_common_schemes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hent ut rimmønsteret som forekommer hyppigst i hvert dikt, og frekvensen til det rimmønsteret\n",
    "majority_schemes = [\n",
    "    {\"poem_id\": poem_id, \"scheme\": Counter(schemes).most_common(1)}\n",
    "    for poem_id, schemes in rhymepatterns.items()\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(majority_schemes)\n",
    "\n",
    "df[\"pattern\"] = df.scheme.explode()\n",
    "df[[\"scheme\", \"count\"]] = df[\"pattern\"].apply(pd.Series)\n",
    "\n",
    "df.drop(columns=[\"pattern\"], inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tell antall dikt de ulike mønstrene er vanligst i\n",
    "df.scheme.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hent ut dikt som ikke har enderim, med mønsteret \"abcd\" (hver linje har en ny bokstav, dvs. ingen linjer rimer med noen foregående i samme strofe)\n",
    "# Filtrer vekk diktene der dette mønsteret ikke forekommer mer enn én gang\n",
    "df[(df.scheme == \"abcd\") & (df[\"count\"] > 1)].sort_values(by=\"count\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Legg til kolonne med info om antall strofer of hvilke andre schemes som er brukt i diktet\n",
    "\n",
    "# Hent ut diktene der majoritetsrimmønsteret kun forekommer 1 gang, dvs. at det ikke er noe klart rimmønster\n",
    "df[df[\"count\"] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hent frekvensen til alle rimmønstrene i hvert dikt\n",
    "counted = [\n",
    "    {\"poem_id\": poem_id, \"scheme\": Counter(schemes)}\n",
    "    for poem_id, schemes in rhymepatterns.items()\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(counted)\n",
    "\n",
    "pd.merge(\n",
    "    df[\"poem_id\"], df[\"scheme\"].apply(pd.Series), left_index=True, right_index=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.scheme.str.len().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.scheme.str.len().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.scheme.str.len() == 330]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hvilke ord rimer oftest? \n",
    "\n",
    "Vi har annotasjonene fra rimtaggeren liggende som json-filer, og leser dem inn på nytt for å hente ut siste ord i hver linje for hvert dikt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from poetry_analysis import utils\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "\n",
    "def get_stanzas_from_transcription(transcription: dict) -> list:\n",
    "    \"\"\"Parse a dict of transcribed verse lines and return a list of stanzas.\"\"\"\n",
    "    n_lines = len(transcription.keys()) - 2  # subtract the text_id and dialect keys\n",
    "    logging.debug(\"Number of lines in poem: %s\", n_lines)\n",
    "    poem = []\n",
    "    stanza = []\n",
    "    for n in range(n_lines):\n",
    "        verse = transcription.get(f\"line_{n}\")\n",
    "        if (verse is not None) and (len(verse) > 0):\n",
    "            syllables = utils.syllabify(verse)\n",
    "            stanza.append(syllables)\n",
    "        else:\n",
    "            if len(stanza) == 0:\n",
    "                continue\n",
    "            poem.append(stanza)\n",
    "            stanza = []\n",
    "    if len(poem) == 0 and len(stanza) > 0:\n",
    "        poem.append(stanza)\n",
    "    return poem\n",
    "\n",
    "\n",
    "def annotate_rhyming_patterns(poem: dict) -> list:\n",
    "    rhyming_patterns = []\n",
    "    stanzas = get_stanzas_from_transcription(poem)\n",
    "\n",
    "    for stanza in enumerate(stanzas):\n",
    "        tagged = rd.tag_rhyming_verses(stanza)\n",
    "        rhyme_scheme = rd.collate_rhyme_scheme(tagged)\n",
    "        rhyming_patterns.append(rhyme_scheme)\n",
    "    return rhyming_patterns\n",
    "\n",
    "\n",
    "def fetch_end_words(poem: dict) -> list:\n",
    "    \"\"\"Hent ordene på slutten av hver linje i hver strofe i diktet. Hver strofe er en liste av ord.\"\"\"\n",
    "    n_lines = len(poem) - 2  # subtract the text_id and dialect keys\n",
    "    end_words = []\n",
    "    stanza_words = []\n",
    "    for idx in range(n_lines):\n",
    "        line = poem.get(f\"line_{idx}\")\n",
    "        if (line is not None) and (len(line) > 0):\n",
    "            words = [word[0] for word in line]\n",
    "            stanza_words.append(words[-1])\n",
    "        else:\n",
    "            if not stanza_words:\n",
    "                continue\n",
    "            end_words.append(stanza_words)\n",
    "            stanza_words = []\n",
    "    return end_words\n",
    "\n",
    "\n",
    "# Hent ut rimordene fra diktene\n",
    "def fetch_rhyming_words(folder: Path) -> dict:\n",
    "    rhyming_words = {}\n",
    "    for filename in folder.glob(\"**/*_østnorsk.json\"):\n",
    "        poem_id = filename.stem.split(\"_\")[0]\n",
    "        poem = json.loads(filename.read_text())\n",
    "\n",
    "        poem_title = poem.get(\"text_id\")\n",
    "        try:\n",
    "            patterns = rhymepatterns[poem_id]\n",
    "        except KeyError:\n",
    "            try:\n",
    "                patterns = annotate_rhyming_patterns(poem)\n",
    "            except TypeError:\n",
    "                logging.error(\"No rhyme patterns found for poem %s\", poem_title)\n",
    "                logging.error(poem)\n",
    "                continue\n",
    "        end_words = fetch_end_words(poem)\n",
    "        rhyming_words[poem_id] = {\n",
    "            \"title\": poem_title,\n",
    "            \"patterns\": patterns,\n",
    "            \"end_words\": end_words,\n",
    "        }\n",
    "    return rhyming_words\n",
    "\n",
    "\n",
    "rhyming_words = fetch_rhyming_words(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rhyming_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_pairs = Counter()\n",
    "\n",
    "for poem_id, poem in rhyming_words.items():\n",
    "    patterns = poem[\"patterns\"]\n",
    "    end_words = poem[\"end_words\"]\n",
    "\n",
    "    for pattern, word in zip(patterns, end_words):\n",
    "        # Dette er 1 strofe\n",
    "        # if pattern not in [\"abac\", \"abab\", \"aabb\", \"abcb\"]:\n",
    "        #    continue\n",
    "        rhyme_pairs = {}\n",
    "        for letter, w in zip(pattern, word):\n",
    "            # Dette er 1 linje\n",
    "            # print(poem_id, letter, w)\n",
    "            if letter in rhyme_pairs:\n",
    "                rhyme_pairs[letter].append(w)\n",
    "            else:\n",
    "                rhyme_pairs[letter] = [w]\n",
    "        # print(rhyme_pairs)\n",
    "        rhyme_pairs = [tuple(v) for _, v in rhyme_pairs.items() if len(v) > 1]\n",
    "\n",
    "        word_pairs.update(rhyme_pairs)\n",
    "\n",
    "word_pairs.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Antall rimordgrupper\n",
    "len(word_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se på rimordgrupper som har flere enn 2 ord\n",
    "with Path(\"output/rimordgrupper.csv\").open(\"w\") as fp:\n",
    "    fp.write(\"word_group\\n\")\n",
    "    for key in word_pairs.keys():\n",
    "        if len(key) > 2:\n",
    "            fp.write(f\"{','.join(key)}\\n\")\n",
    "\n",
    "# [key for key in word_pairs.keys() if len(key) > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Path(\"output/word_pairs.csv\").open(\"w\") as fp:\n",
    "    for key, value in word_pairs.most_common():\n",
    "        fp.write(f\"{value},{','.join(key)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
