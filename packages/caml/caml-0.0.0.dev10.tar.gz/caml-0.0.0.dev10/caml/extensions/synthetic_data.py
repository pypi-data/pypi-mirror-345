from typing import Callable

import numpy as np
import pandas as pd
from doubleml.datasets import (
    make_heterogeneous_data,
    make_plr_CCDDHNR2018,
    make_plr_turrell2018,
)
from scipy.linalg import toeplitz
from typeguard import typechecked

from ..generics import experimental


@experimental
@typechecked
class CamlSyntheticDataGenerator:
    r"""Generate highly flexible synthetic data for use in causal inference and CaML testing.

    **CamlSyntheticDataGenerator is experimental and may change significantly in future versions.**

    The general form of the data generating process is:

    $$
    \mathbf{Y_i} = \tau (\mathbf{X_i}) \mathbf{T_i} + g(\mathbf{W_i}, \mathbf{X_i}) + \mathbf{\epsilon_i}
    $$
    $$
    \mathbf{T}_i=f(\mathbf{W}_i, \mathbf{X_{i,\mathcal{S}}})+\mathbf{\eta_i}
    $$

    where $\mathbf{Y_i}$ are the outcome(s), $\mathbf{T_i}$ are the treatment(s), $\mathbf{X_i}$ are the effect modifiers (leveraged for treatment effect heterogeneity)
    with an optional random subset $\mathcal{S}$ selected as confounders, $\mathbf{W_i}$ are the confounders, $\mathbf{\epsilon_i}$ and $\mathbf{\eta_i}$ are the error terms drawn from
    normal distributions with optional specified standard deviation, $\tau$ is the CATE function, $g$ is the linearly seperable/nuisance component of the outcome function,
    and $f$ is the treatment function. Note in the case of no modifier variables, we obtain a purely partially linear model, with $\tau$ as a constant.

    For linear data generating process, $f$ and $g$ consist of strictly linear terms and untransformed variables. $\tau$ consists linear interaction terms.

    For nonlinear data generating process, $f$ and $g$ are generated via Generalized Additive Models (GAMs) with randomly selected transformations and interaction terms
    controlled via `n_nonlinear_transformations`. $\tau$ contains interaction terms with transformed modifiers controlled via `n_nonlinear_interactions`.

    As a DAG, the data generating process can be roughly represented as:

    <div style="text-align: center;">
    ```{mermaid}
    flowchart TD;
        X((X))-->Y((Y));
        W((W))-->Y((Y));
        W((W))-->T((T));
        X((X))-->|"S"|T((T));
        T((T))-->|"Ï„(X)"|Y((Y));

        linkStyle 0,1,2,3,4 stroke:black,stroke-width:2px
    ```
    </div>

    Parameters
    ----------
    n_obs : int
        Number of observations.
    n_cont_outcomes : int
        Number of continuous outcomes ($Y$).
    n_binary_outcomes : int
        Number of binary outcomes ($Y$).
    n_cont_treatments : int
        Number of continuous treatments ($T$).
    n_binary_treatments : int
        Number of binary treatments ($T$).
    n_discrete_treatments : int
        Number of discrete treatments ($T$).
    n_cont_confounders : int
        Number of continuous confounders ($W$).
    n_binary_confounders : int
        Number of binary confounders ($W$).
    n_discrete_confounders : int
        Number of discrete confounders ($W$).
    n_cont_modifiers : int
        Number of continuous treatment effect modifiers ($X$).
    n_binary_modifiers : int
        Number of binary treatment effect modifiers ($X$).
    n_discrete_modifiers : int
        Number of discrete treatment effect modifiers ($X$).
    n_confounding_modifiers : int
        Number of confounding treatment effect modifiers ($X_{\mathcal{S}}$).
    stddev_outcome_noise : float
        Standard deviation of the outcome noise ($\epsilon$).
    stddev_treatment_noise : float
        Standard deviation of the treatment noise ($\eta$).
    causal_model_functional_form : str
        Functional form of the causal model, can be "linear" or "nonlinear".
    n_nonlinear_transformations : int | None
        Number of nonlinear transformations, only applies if causal_model_functional_form="nonlinear".
    n_nonlinear_interactions : int | None
        Number of nonlinear interactions with treatment, introducing heterogeneity, only applies if causal_model_functional_form="nonlinear".
    seed : int | None
        Random seed to use for generating the data.

    Attributes
    ----------
    df : pandas.DataFrame
        The data generated by the data generation process.
    cates : pandas.DataFrame
        The true conditional average treatment effects (CATEs) of the data.
    ates : pandas.DataFrame
        The true average treatment effects (ATEs) of the data.
    dgp : dict[str, pandas.DataFrame]
        The true data generating processes of the treatments and outcomes.

    Examples
    --------
    ```{python}
    from caml.extensions.synthetic_data import CamlSyntheticDataGenerator

    data_generator = CamlSyntheticDataGenerator(seed=10)
    data_generator.df
    ```

    ```{python}
    data_generator.cates
    ```

    ```{python}
    data_generator.ates
    ```

    ```{python}
    for t, df in data_generator.dgp.items():
        print(f"\nDGP for {t}:")
        print(df)
    ```
    """

    def __init__(
        self,
        n_obs: int = 10_000,
        n_cont_outcomes: int = 1,
        n_binary_outcomes: int = 0,
        n_cont_treatments: int = 0,
        n_binary_treatments: int = 1,
        n_discrete_treatments: int = 0,
        n_cont_confounders: int = 2,
        n_binary_confounders: int = 0,
        n_discrete_confounders: int = 0,
        n_cont_modifiers: int = 2,
        n_binary_modifiers: int = 0,
        n_discrete_modifiers: int = 0,
        n_confounding_modifiers: int = 0,
        stddev_outcome_noise: float = 1.0,
        stddev_treatment_noise: float = 1.0,
        causal_model_functional_form: str = "linear",
        n_nonlinear_transformations: int | None = None,
        n_nonlinear_interactions: int | None = None,
        seed: int | None = None,
    ):
        if causal_model_functional_form not in ["linear", "nonlinear"]:
            raise ValueError(
                f"Invalid functional form. Must be choice of {['linear', 'nonlinear']}"
            )
        if n_cont_outcomes + n_binary_outcomes == 0:
            raise ValueError("At least one outcome variable type must be specified.")
        if n_cont_treatments + n_binary_treatments + n_discrete_treatments == 0:
            raise ValueError("At least one treatment variable type must be specified.")
        if n_obs <= 0:
            raise ValueError("Number of observations must be greater than 0.")

        self._n_obs = n_obs
        self._n_cont_outcomes = n_cont_outcomes
        self._n_binary_outcomes = n_binary_outcomes
        self._n_cont_treatments = n_cont_treatments
        self._n_binary_treatments = n_binary_treatments
        self._n_discrete_treatments = n_discrete_treatments
        self._n_cont_confounders = n_cont_confounders
        self._n_binary_confounders = n_binary_confounders
        self._n_discrete_confounders = n_discrete_confounders
        self._n_cont_modifiers = n_cont_modifiers
        self._n_binary_modifiers = n_binary_modifiers
        self._n_discrete_modifiers = n_discrete_modifiers
        self._n_confounding_modifiers = n_confounding_modifiers
        self._stddev_outcome_noise = stddev_outcome_noise
        self._stddev_treatment_noise = stddev_treatment_noise
        self._causal_model_functional_form = causal_model_functional_form
        self._n_nonlinear_transformations = n_nonlinear_transformations
        self._n_nonlinear_interactions = n_nonlinear_interactions
        self._seed = seed if seed is not None else np.random.randint(1, 1000)
        self._rng = np.random.default_rng(seed)

        self._generate_data()

    def _generate_data(self):
        """
        Execute the data generation process end-to-end.

        1. Generates randomly and indepedently drawn confounders from various distributions.
        2. Generates randomly and indepedently drawn heterogeneity inducing covariates (modifiers) from various distributions.
        3. Generates the treatment variables as a function of confounders and a random subset of heterogeneity inducing covariates, per specified by `n_heterogeneity_confounders`.
        4. Generates the outcome variables as a function of confounders and treatment variables, with treatment interactions with heterogeneity inducing covariates.
        5. Sets key attributes of the class including:
            - `df` - The simulated data
            - `cates` - The true conditional average treatment effects (CATEs)
            - `ates` - The true average treatment effects (ATEs)
            - `dgp` - The data generating process specs
        """
        # Generate confounders
        confounders = self._generate_confounder_variables()

        # Generate modifiers
        modifiers = self._generate_modifier_variables()

        # Generate treatment variables
        treatments, treatments_dgp = self._generate_treatment_variables(
            confounders=confounders,
            modifiers=modifiers,
        )

        # Generate outcome variables
        outcomes, cates, outcomes_dgp = self._generate_outcome_variables(
            confounders=confounders,
            modifiers=modifiers,
            treatments=treatments,
        )

        # Combine variables into single dataframe
        synthetic_data = pd.concat(
            [confounders, modifiers, treatments, outcomes], axis=1
        )

        # Prettify CATEs and ATEs report
        cate_df, ate_df = self._treatment_effect_report(cates)

        self.df = synthetic_data
        self.cates = cate_df
        self.ates = ate_df
        self.dgp = treatments_dgp | outcomes_dgp

    def _generate_confounder_variables(self) -> pd.DataFrame:
        """
        Randomly generates confounder variables.

        Returns
        -------
        pd.DataFrame
            Dataframe of confounder variables.
        """
        confounders = {}

        confounder_types = (
            ["continuous"] * self._n_cont_confounders
            + ["binary"] * self._n_binary_confounders
            + ["discrete"] * self._n_discrete_confounders
        )

        for i, t in enumerate(confounder_types):
            confounders[f"W{i + 1}_{t}"] = self._generate_random_variable(
                n_obs=self._n_obs, var_type=t, rng=self._rng
            )

        return pd.DataFrame(confounders)

    def _generate_modifier_variables(self) -> pd.DataFrame:
        """
        Randomly generates treatment effect heterogeneity inducing variables (modifiers).

        Returns
        -------
        pd.DataFrame
            Dataframe of modifier variables
        """
        modifiers = {}

        modifier_types = (
            ["continuous"] * self._n_cont_modifiers
            + ["binary"] * self._n_binary_modifiers
            + ["discrete"] * self._n_discrete_modifiers
        )

        for i, t in enumerate(modifier_types):
            modifiers[f"X{i + 1}_{t}"] = self._generate_random_variable(
                n_obs=self._n_obs, var_type=t, rng=self._rng
            )

        return pd.DataFrame(modifiers)

    def _generate_treatment_variables(
        self, confounders: pd.DataFrame, modifiers: pd.DataFrame
    ) -> tuple[pd.DataFrame, dict]:
        """
        Generate the treatment variables.

        Parameters
        ----------
        confounders : pd.DataFrame
            DataFrame of confounder variables
        modifiers : pd.DataFrame
            DataFrame of modifier variables

        Returns
        -------
        pd.DataFrame
            DataFrame of treatment variables
        dict
            Dictionary of dataframes containing data generating process parameters and variable names for each treatment.
        """
        treatments = {}
        dgp = {}

        subset_modifiers = modifiers.sample(
            n=self._n_confounding_modifiers, axis=1, random_state=self._seed
        )

        all_confounders = pd.concat([confounders, subset_modifiers], axis=1)

        treatment_types = (
            ["continuous"] * self._n_cont_treatments
            + ["binary"] * self._n_binary_treatments
            + ["discrete"] * self._n_discrete_treatments
        )

        if self._causal_model_functional_form == "linear":
            n_nonlinear_transformations = None
            n_nonlinear_interactions = None
        else:
            n_nonlinear_transformations = self._n_nonlinear_transformations
            n_nonlinear_interactions = self._n_nonlinear_interactions

        for i, t in enumerate(treatment_types):
            col_name = f"T{i + 1}_{t}"
            treatments[col_name], dgp[col_name] = self._dgp(
                covariates=all_confounders,
                stddev_err=self._stddev_treatment_noise,
                dep_type=t,
                dgp_type=self._causal_model_functional_form,
                return_treatment_effects=False,
                n_nonlinear_transformations=n_nonlinear_transformations,
                n_nonlinear_interactions=n_nonlinear_interactions,
            )

        return pd.DataFrame(treatments), dgp

    def _generate_outcome_variables(
        self,
        confounders: pd.DataFrame,
        modifiers: pd.DataFrame,
        treatments: pd.DataFrame,
    ) -> tuple[pd.DataFrame, dict, dict]:
        """
        Generates the outcome variables.

        Parameters
        ----------
        confounders : pd.DataFrame
            DataFrame of confounder variables
        modifiers : pd.DataFrame
            DataFrame of modifier variables
        treatments : pd.DataFrame
            DataFrame of treatment variables

        Returns
        -------
        pd.DataFrame
            DataFrame of outcome variables
        dict
            True conditional average treatment effects (CATEs)
        dict
            Dictionary of dataframes containing the true data generating process parameters and variable names.
        """
        outcomes = {}
        cates = {}
        dgp = {}

        outcome_types = ["continuous"] * self._n_cont_outcomes + [
            "binary"
        ] * self._n_binary_outcomes

        if self._causal_model_functional_form == "linear":
            n_nonlinear_transformations = None
            n_nonlinear_interactions = None

            interactions_np = (
                treatments.to_numpy()[:, :, None] * modifiers.to_numpy()[:, None, :]
            ).reshape(self._n_obs, -1)

            interactions = pd.DataFrame(
                interactions_np,
                columns=[
                    f"int_{t}_{x}"
                    for t in treatments.columns
                    for x in modifiers.columns
                ],
            )

            all_features = pd.concat(
                [confounders, modifiers, treatments, interactions], axis=1
            )

        else:
            n_nonlinear_transformations = self._n_nonlinear_transformations
            n_nonlinear_interactions = self._n_nonlinear_interactions
            all_features = pd.concat([confounders, modifiers, treatments], axis=1)

        for i, t in enumerate(outcome_types):
            col_name = f"Y{i + 1}_{t}"
            outcomes[col_name], cates[col_name], dgp[col_name] = self._dgp(
                covariates=all_features,
                stddev_err=self._stddev_outcome_noise,
                dep_type=t,
                dgp_type=self._causal_model_functional_form,
                return_treatment_effects=True,
                n_nonlinear_transformations=n_nonlinear_transformations,
                n_nonlinear_interactions=n_nonlinear_interactions,
            )

        return pd.DataFrame(outcomes), cates, dgp

    def _dgp(
        self,
        covariates: pd.DataFrame,
        stddev_err: float,
        dep_type: str,
        dgp_type: str,
        return_treatment_effects: bool = False,
        n_nonlinear_transformations: int | None = None,
        n_nonlinear_interactions: int | None = None,
    ) -> tuple[np.ndarray, pd.DataFrame] | tuple[np.ndarray, dict, pd.DataFrame]:
        """
        Simulates DGP for treatment and outcome variables, and computes treatment effects for outcomes.

        Return the target variable, parameters + variable names of the data generating process, and, optionally, treatment effects for outcomes.

        Parameters
        ----------
        covariates : pd.DataFrame
            The covariates dataframe used as features in the DGP.
        stddev_err : float
            The standard deviation of the error term.
        dep_type : str
            The dependent variable type. Can be "continuous", "binary", or "discrete".
        dgp_type : str
            The DGP process functional form. Can be "linear" or "nonlinear".
        return_treatment_effects : bool
            Boolean to return treatment effects. Default is False.
        n_nonlinear_transformations : int | None
            Number of random nonlinear transformations. Only applies if dgp_type="nonlinear". Default is None.
        n_nonlinear_interactions : int | None
            Number of random nonlinear interactions with treatment, introducing heterogeneity. Only applies if dgp_type="nonlinear". Default is None.

        Returns
        -------
        np.ndarray
            The target variable generated by the DGP.
        pd.DataFrame
            The parameters of the DGP, if applicable.
        dict
            Dictionary of treatment effects, if applicable.
        """
        n_obs = self._n_obs

        # Handle nonlinear transformations & interactions if applicable
        if dgp_type == "nonlinear":
            transformed_covariates = self._apply_random_nonlinearities(
                data=covariates,
                n_transforms=n_nonlinear_transformations
                if n_nonlinear_transformations
                else covariates.shape[1],
                n_interactions=n_nonlinear_interactions
                if n_nonlinear_interactions
                else 5,
                seed=self._seed,
            )
            X = transformed_covariates.values
            feature_names = transformed_covariates.columns
            n_features = X.shape[1]
        else:
            X = covariates.values
            feature_names = covariates.columns
            n_features = X.shape[1]

        # Generate parameters & noise
        if dep_type == "discrete":
            n_categories = self._rng.choice(range(3, 6))
            params = self._rng.uniform(low=-3, high=3, size=(n_features, n_categories))
            noise = self._rng.normal(0, stddev_err, size=(n_obs, n_categories))
        else:
            params = self._rng.uniform(low=-3, high=3, size=n_features)
            noise = self._rng.normal(0, stddev_err, size=n_obs)

        # Define functions for each dgp_type
        if dep_type == "continuous":

            def f(x):
                scores = x @ params + noise
                return scores
        elif dep_type == "binary":

            def f(x):
                scores = x @ params + noise
                probs = self._sigmoid(scores)
                return self._truncate_and_renormalize_probabilites(probs)
        else:

            def f(x):
                scores = x @ params + noise
                probs = self._softmax(scores)
                return self._truncate_and_renormalize_probabilites(probs)

        scores = f(X)

        if dep_type == "binary":
            y = self._rng.binomial(1, scores)
        elif dep_type == "discrete":
            y = np.array(
                [self._rng.choice(range(n_categories), p=prob) for prob in scores]
            )
        else:
            y = scores

        # Record data generating process=
        dgp = {}
        dgp["covariates"] = feature_names
        dgp["params"] = params
        if dgp["params"].ndim > 1:
            for i in range(dgp["params"].ndim):
                dgp[f"cat_{i + 1}_params"] = dgp["params"][:, i]
            del dgp["params"]

        dgp["global_transformation"] = (
            "Sigmoid"
            if dep_type == "binary"
            else "Softmax"
            if dep_type == "discrete"
            else "None"
        )

        if not return_treatment_effects:
            return y, pd.DataFrame(dgp)
        else:
            cates = self._compute_treatment_effects(
                f,
                covariates,
                dgp_type,
            )
            return y, cates, pd.DataFrame(dgp)

    def _compute_treatment_effects(
        self,
        f: Callable,
        data: pd.DataFrame,
        dgp_type: str,
    ) -> dict:
        """
        Function to call & compute true treatment effects.

        Parameters
        ----------
        f : Callable
            Outcome function.
        data : pd.DataFrame
            Data.
        dgp_type : str
            Type of DGP.

        Returns
        -------
        dict
            Dictionary of true treatment effects.

        """
        cates = {}
        for t in [c for c in data.columns if c.count("_") == 1 and "T" in c]:
            if "continuous" in t:
                levels = ["cont"]
            elif "binary" in t:
                levels = [0, 1]
            elif "discrete" in t:
                levels = data[t].unique().tolist()
            else:
                raise ValueError("Invalid treatment type.")

            cates[t] = self._compute_potential_outcome_differences(
                f,
                data,
                t,
                dgp_type,
                levels=levels,
            )

        return cates

    def _compute_potential_outcome_differences(
        self,
        f: Callable,
        data: pd.DataFrame,
        wrt: str,
        dgp_type: str,
        levels: list,
    ) -> dict[str, np.ndarray] | np.ndarray:
        """
        Computes potential outcome differences of some outcome function for each individual, returing the conditional average treatment effects (CATEs).

        Parameters
        ----------
        f : Callable
            Outcome function.
        data : pd.DataFrame
            Dataframe containing covariates and treatment.
        wrt : str
            With respect to, the name of treatment variable.
        dgp_type : str
            The data generating process type, can be nonlinear or linear.
        levels : list
            The treatment leves to capture potential outcome differences for. For continuous treatments, use 'cont', which measures one unit change in treatment.

        Returns
        -------
        dict[str, np.ndarray] | np.ndarray
            The conditional average treatment effects (CATEs). If levels is a list with more than [0,1], returns a dictionary of CATEs for each level.

        """
        cates = {}
        for lev in levels:
            if lev == 0:
                pass
            else:
                data_treat = data.copy()
                data_control = data.copy()

                if lev == "cont":
                    data_treat[wrt] = data_treat[wrt] + 1
                else:
                    data_treat[wrt] = lev
                    data_control[wrt] = 0

                if dgp_type == "nonlinear":
                    data_treat_transformed = self._apply_random_nonlinearities(
                        data_treat,
                        n_transforms=self._n_nonlinear_transformations
                        if self._n_nonlinear_transformations
                        else data_treat.shape[1],
                        n_interactions=self._n_nonlinear_interactions
                        if self._n_nonlinear_interactions
                        else 5,
                        seed=self._seed,
                    )
                    data_control_transformed = self._apply_random_nonlinearities(
                        data_control,
                        n_transforms=self._n_nonlinear_transformations
                        if self._n_nonlinear_transformations
                        else data_control.shape[1],
                        n_interactions=self._n_nonlinear_interactions
                        if self._n_nonlinear_interactions
                        else 5,
                        seed=self._seed,
                    )

                    cates[f"{lev}_v_0"] = f(data_treat_transformed.values) - f(
                        data_control_transformed.values
                    )
                else:
                    for interaction in [
                        c for c in data.columns if wrt in c and "int" in c
                    ]:
                        covariate = interaction.split(f"{wrt}_")[1]
                        data_treat[interaction] = (
                            data_treat[covariate] * data_treat[wrt]
                        )
                        data_control[interaction] = (
                            data_control[covariate] * data_control[wrt]
                        )

                    cates[f"{lev}_v_0"] = f(data_treat.values) - f(data_control.values)

        if len(cates) == 1:
            return list(cates.values())[0]
        else:
            return cates

    @staticmethod
    def _generate_random_variable(
        n_obs: int,
        var_type: str,
        rng: np.random.Generator,
    ) -> np.ndarray:
        """
        Generates a random variable of n observations from randomly selected distribution given a data type.

        Parameters
        ----------
        n_obs : int
            Number of observations.
        var_type : str
            Type of the variable to generate, choose from "continuous", "binary" or "discrete".
        rng : np.random.Generator
            Numpy random number generator.

        Returns
        -------
        np.ndarray
            Generated random variable.

        """
        valid_types = ["continuous", "binary", "discrete"]
        assert (
            var_type in valid_types
        ), f"Invalid type: {var_type}. Choose from {valid_types}."

        if var_type == "continuous":
            distributions = [
                "normal",
                "uniform",
                "exponential",
                "gamma",
                "beta",
                "laplace",
            ]

            dist = rng.choice(distributions)

            if dist == "normal":
                mean, std = rng.uniform(-5, 5), rng.uniform(0.5, 2)
                res = rng.normal(mean, std, n_obs)
            elif dist == "uniform":
                low, high = rng.uniform(-10, 0), rng.uniform(0, 10)
                res = rng.uniform(low, high, n_obs)
            elif dist == "exponential":
                scale = rng.uniform(1, 3)
                res = rng.exponential(scale, n_obs)
            elif dist == "gamma":
                shape, scale = rng.uniform(1, 3), rng.uniform(1, 3)
                res = rng.gamma(shape, scale, n_obs)
            elif dist == "beta":
                a, b = rng.uniform(1, 3), rng.uniform(1, 3)
                res = rng.beta(a, b, n_obs)
            elif dist == "laplace":
                loc, scale = rng.uniform(-5, 5), rng.uniform(0.5, 2)
                res = rng.laplace(loc, scale, n_obs)
            else:
                raise ValueError("Invalid distribution")

        elif var_type == "binary":
            p = rng.uniform(0.1, 0.9)
            res = rng.binomial(1, p, n_obs)

        elif var_type == "discrete":
            distributions = ["poisson", "geometric", "multinomial", "uniform"]

            dist = rng.choice(distributions)

            if dist == "poisson":
                lam = rng.uniform(1, 10)
                res = rng.poisson(lam, n_obs)

            elif dist == "geometric":
                p = rng.uniform(0.1, 0.9)
                res = rng.geometric(p, n_obs)

            elif dist == "multinomial":
                n_categories = rng.choice(range(2, 7))
                probs = rng.dirichlet(np.ones(n_categories))
                res = rng.choice(range(n_categories), size=n_obs, p=probs)

            elif dist == "uniform":
                n_categories = rng.choice(range(2, 7))
                res = rng.choice(range(0, n_categories), size=n_obs)
            else:
                raise ValueError("Invalid distribution")

        else:
            raise ValueError("Invalid variable type.")

        return res

    @staticmethod
    def _treatment_effect_report(
        cates: dict[str, dict],
    ) -> tuple[pd.DataFrame, pd.DataFrame]:
        """
        Generate a prettified dataframe of the true conditional average treatment effects (CATEs) and average treatment effects (ATE).

        Parameters
        ----------
        cates : dict[str, dict]
            A dictionary including key as outcome name and value as dictionary of CATES of each treatment on that outcome.

        Returns
        -------
        pd.DataFrame, pd.DataFrame
            Prettified dataframe of the CATEs and ATEs.
        """
        dict_effects = {}
        for outcome, effects in cates.items():
            for treatment, values in effects.items():
                var = f"CATE_of_{treatment}_on_{outcome}"
                if isinstance(values, dict):
                    for levels, results in values.items():
                        var_lev = var + f"_level_{levels}"
                        dict_effects[var_lev] = results
                else:
                    dict_effects[var] = values

        cate_df = pd.DataFrame(dict_effects)

        ate_df = cate_df.mean(axis=0).reset_index()
        ate_df.columns = ["Treatment", "ATE"]
        ate_df["Treatment"] = ate_df["Treatment"].str.replace("CATE_of_", "")

        return cate_df, ate_df

    @staticmethod
    def _apply_random_nonlinearities(
        data: pd.DataFrame,
        n_transforms: int = 10,
        n_interactions: int = 5,
        seed: int | None = None,
    ) -> pd.DataFrame:
        """
        Apply a random set of nonlinear transformations to the input features and interactions to introduce heterogenous treatment effects.

        Parameters
        ----------
        data : pd.DataFrame
            The input dataframe containing the features to be transformed.
        n_transforms : int
            The number of nonlinear transformations to apply to the features, by default 10.
        n_interactions : int
            The number of interactions with treatment to apply to the features, by default 5.
        seed : int | None
            Seed for the random number generator, by default None.

        Returns
        -------
        pd.DataFrame
            The transformed dataframe or original dataframe if no transformations are applied.
        """
        np.random.seed(seed)

        if data.shape[1] > 0:
            transformed_data = data.copy()
            trans = 0
            while trans < n_transforms:
                transform = np.random.choice(
                    [
                        "sin",
                        "cos",
                        "square",
                        " log",
                        "2D-interaction",
                        "sqrt",
                    ]
                )
                col_name = np.random.choice(data.columns, size=2, replace=True)

                if transform == "sin":
                    transformed_data[f"sin_{col_name[0]}"] = np.sin(
                        transformed_data[col_name[0]]
                    )
                elif transform == "cos":
                    transformed_data[f"cos_{col_name[0]}"] = np.cos(
                        transformed_data[col_name[0]]
                    )
                elif transform == "square":
                    transformed_data[f"square_{col_name[0]}"] = (
                        transformed_data[col_name[0]] ** 2
                    )
                elif transform == "log":
                    transformed_data[f"log_{col_name[0]}"] = np.log(
                        np.abs(transformed_data[col_name[0]]) + 1
                    )
                elif transform == "2D-interaction":
                    for c in col_name:
                        if c.count("_") == 1 and "T" in c:
                            pass
                        else:
                            transformed_data[f"2Dint_{col_name[0]}_{col_name[1]}"] = (
                                transformed_data[col_name[0]]
                                * transformed_data[col_name[1]]
                            )
                elif transform == "sqrt":
                    transformed_data[f"sqrt_{col_name[0]}"] = np.sqrt(
                        np.abs(transformed_data[col_name[0]])
                    )

                trans = transformed_data.shape[1] - data.shape[1]

            # Add explicit interaction terms for heterogeneity
            transformed_data_w_modifiers = transformed_data.copy()
            for t in [
                c for c in transformed_data.columns if "T" in c and c.count("_") == 1
            ]:
                trans = 0
                while trans < n_interactions:
                    available_cols = [
                        c
                        for c in transformed_data.columns
                        if not ("T" in c and c.count("_") == 1)
                        and ("X" in c and "W" not in c)
                    ]
                    if available_cols == []:
                        break
                    col = np.random.choice(available_cols, size=1)[0]

                    transformed_data_w_modifiers[f"int_{t}_{col}"] = (
                        transformed_data[t] * transformed_data[col]
                    )

                    trans = (
                        transformed_data_w_modifiers.shape[1]
                        - transformed_data.shape[1]
                    )

            return transformed_data_w_modifiers
        else:
            return data

    @staticmethod
    def _sigmoid(x: np.ndarray):
        """
        Numerically stable sigmoid.

        Parameters
        ----------
        x : np.ndarray
            Input matrix of scores

        Returns
        -------
        np.ndarray
            Matrix of probabilities
        """
        result = np.zeros_like(x, dtype=float)

        pos_mask = x >= 0
        neg_mask = ~pos_mask

        result[pos_mask] = 1 / (1 + np.exp(-x[pos_mask]))
        result[neg_mask] = np.exp(x[neg_mask]) / (1 + np.exp(x[neg_mask]))

        return result

    @staticmethod
    def _softmax(x: np.ndarray) -> np.ndarray:
        """
        Numerically stable softmax.

        Parameters
        ----------
        x : np.ndarray
            Input matrix of scores

        Returns
        -------
        np.ndarray
            Matrix of probabilities

        """
        e_x = np.exp(x - np.max(x, axis=1, keepdims=True))
        return e_x / np.sum(e_x, axis=1, keepdims=True)

    @staticmethod
    def _truncate_and_renormalize_probabilites(
        prob_matrix: np.ndarray, epsilon: float = 0.05
    ) -> np.ndarray:
        """
        Truncate and renormalize probabilities (in case of softmax).

        Helps to ensure we satisify positivity/overlap in treatment probabilites and don't have probabilities too extreme.

        Parameters
        ----------
        prob_matrix : np.ndarray
            Matrix of probabilities to be truncated and renormalized
        epsilon : float
            Value to clip probabilities on both ends of the distribution. Default is 0.05.

        Returns
        -------
        np.ndarray
            Matrix of probabilities
        """
        prob_matrix = np.clip(prob_matrix, epsilon, 1 - epsilon)
        if prob_matrix.ndim > 1:
            prob_matrix /= prob_matrix.sum(axis=1, keepdims=True)

        return prob_matrix


@typechecked
def make_partially_linear_dataset_simple(
    n_obs: int = 1000,
    n_confounders: int = 5,
    dim_heterogeneity: int = 2,
    binary_treatment: bool = True,
    seed: int | None = None,
) -> tuple[pd.DataFrame, np.ndarray, float]:
    r"""Simulate data generating process from a partially linear model with a simple 1 or 2 dimensional CATE function.

    The outcome is continuous and the treatment can be binary or continuous. The dataset is generated using the `make_heterogeneous_data` function from the [`doubleml` package](https://docs.doubleml.org/stable/index.html).

    The general form of the data generating process is, in the case of dim_heterogeneity=1:

    $$
    y_i= \\tau (x_0) d_i + g(\mathbf{X_i})+\epsilon_i
    $$
    $$
    d_i=f(\mathbf{X_i})+\eta_i
    $$

    or, in the case of dim_heterogeneity=2:

    $$
    y_i= \\tau (x_0,x_1) d_i + g(\mathbf{X_i})+\epsilon_i
    $$
    $$
    d_i=f(\mathbf{X_i})+\eta_i
    $$

    where $y_i$ is the outcome, $d_i$ is the treatment, $\mathbf{X_i}$ are the confounders, $\epsilon_i$ and $\eta_i$ are the error terms, $\\tau$ is the CATE function, $g$ is the outcome function, and $f$ is the treatment function.

    See the `doubleml` documentation for more details on the specific functional forms of the data generating process.

    Here the ATE is defined as the average of the CATE function over all observations: $\mathbb{E}[\\tau (\cdot)]$

    As a DAG, the data generating process can be roughly represented as:

    <div style="text-align: center;">
    ```{mermaid}
    flowchart TD;
        Xn((X))-->d((d));
        Xn((X))-->y((y));
        d((d))-->|"Ï„(x0,x1)"|y((y));

        linkStyle 0,1 stroke:black,stroke-width:2px
        linkStyle 1,2 stroke:black,stroke-width:2px
    ```
    </div>

    Parameters
    ----------
    n_obs : int
        The number of observations to generate.
    n_confounders : int
        The number of confounders $X$.
    dim_heterogeneity : int
        The dimension of the heterogeneity $x_0$ or $(x_0,x_1)$. Can only be 1 or 2.
    binary_treatment : bool
        Whether the treatment $d$ is binary or continuous.
    seed : int | None
        The seed to use for the random number generator.

    Returns
    -------
    df : pandas.DataFrame
        The generated dataset where y is the outcome, d is the treatment, and X are the confounders with a 1d or 2d subset utilized for heterogeneity.
    true_cates : numpy.ndarray
        The true conditional average treatment effects.
    true_ate : float
        The true average treatment effect.

    Examples
    --------
    ```{python}
    from caml.extensions.synthetic_data import make_partially_linear_dataset_simple
    df, true_cates, true_ate = make_partially_linear_dataset_simple(n_obs=1000,
                                                                    n_confounders=5,
                                                                    dim_heterogeneity=2,
                                                                    binary_treatment=True,
                                                                    seed=1)

    print(f"True CATES: {true_cates[:5]}")
    print(f"True ATE: {true_ate}")
    print(df.head())
    ```
    """
    if dim_heterogeneity not in [1, 2]:
        raise ValueError("dim_heterogeneity must be 1 or 2.")

    np.random.seed(seed)

    data = make_heterogeneous_data(
        n_obs=n_obs,
        p=n_confounders,
        support_size=n_confounders,
        n_x=dim_heterogeneity,
        binary_treatment=binary_treatment,
    )

    df = pd.DataFrame(data["data"])
    df.columns = [c.replace("X_", "X") for c in df.columns]
    true_cates = data["effects"]
    true_ate = true_cates.mean()
    return df, true_cates, true_ate


@typechecked
def make_partially_linear_dataset_constant(
    n_obs: int = 1000,
    ate: float = 4.0,
    n_confounders: int = 10,
    dgp: str = "make_plr_CCDDHNR2018",
    seed: int | None = None,
    **doubleml_kwargs,
) -> tuple[pd.DataFrame, np.ndarray, float]:
    r"""Simulate a data generating process from a partially linear model with a constant treatment effect (ATE only).

    The outcome and treatment are both continuous.The dataset is generated using the `make_plr_CCDDHNR2018` or `make_plr_turrell2018` function from the [`doubleml` package](https://docs.doubleml.org/stable/index.html).

    The general form of the data generating process is:

    $$
    y_i= \tau_0 d_i + g(\mathbf{W_i})+\epsilon_i
    $$
    $$
    d_i=f(\mathbf{W_i})+\eta_i
    $$

    where $y_i$ is the outcome, $d_i$ is the treatment, $\mathbf{W_i}$ are the confounders, $\epsilon_i$ and $\eta_i$ are the error terms, $\tau_0$ is the ATE parameter, $g$ is the outcome function, and $f$ is the treatment function.

    See the `doubleml` documentation for more details on the specific functional forms of the data generating process.

    As a DAG, the data generating process can be roughly represented as:

    <div style="text-align: center;">
    ```{mermaid}
    flowchart TD;
        W((W))-->d((d));
        W((W))-->y((y));
        d((d))-->|"Ï„0"|y((y));
        linkStyle 0,1 stroke:black,stroke-width:2px
        linkStyle 1,2 stroke:black,stroke-width:2px
    ```
    </div>

    Parameters
    ----------
    n_obs : int
        The number of observations to generate.
    ate : float
        The average treatment effect $\tau_0$.
    n_confounders : int
        The number of confounders $\mathbf{W_i}$ to generate.
    dgp : str
        The data generating process to use. Can be "make_plr_CCDDHNR20" or "make_plr_turrell2018".
    seed : int | None
        The seed to use for the random number generator.
    **doubleml_kwargs
        Additional keyword arguments to pass to the data generating process.

    Returns
    -------
    df : pandas.DataFrame
        The generated dataset where y is the outcome, d is the treatment, and W are the confounders.
    true_cates : numpy.ndarray
        The true conditional average treatment effects, which are all equal to the ATE here.
    true_ate : float
        The true average treatment effect.

    Examples
    --------
    ```{python}
    from caml.extensions.synthetic_data import make_partially_linear_dataset_constant
    df, true_cates, true_ate = make_partially_linear_dataset_constant(n_obs=1000,
                                                        ate=4.0,
                                                        n_confounders=10,
                                                        dgp="make_plr_CCDDHNR2018",
                                                        seed=1)

    print(f"True CATES: {true_cates[:5]}")
    print(f"True ATE: {true_ate}")
    print(df.head())
    ```
    """
    np.random.seed(seed)

    if dgp == "make_plr_CCDDHNR2018":
        df = make_plr_CCDDHNR2018(
            n_obs=n_obs,
            dim_x=n_confounders,
            alpha=ate,
            return_type="DataFrame",
            **doubleml_kwargs,
        )
    elif dgp == "make_plr_turrell2018":
        df = make_plr_turrell2018(
            n_obs=n_obs,
            dim_x=n_confounders,
            theta=ate,
            return_type="DataFrame",
            **doubleml_kwargs,
        )
    else:
        raise ValueError(
            "dgp must be 'make_plr_CCDDHNR2018' or 'make_plr_turrell2018'."
        )

    df.columns = [c.replace("X", "W") for c in df.columns if "X" in c] + ["y", "d"]

    true_ate = ate
    true_cates = np.full(n_obs, true_ate)

    return df, true_cates, true_ate


@typechecked
def make_fully_heterogeneous_dataset(
    n_obs: int = 1000,
    n_confounders: int = 5,
    theta: float = 4.0,
    seed: int | None = None,
    **doubleml_kwargs,
) -> tuple[pd.DataFrame, np.ndarray, float]:
    r"""Simulate data generating process from an interactive regression model with fully heterogenous treatment effects.

    The outcome is continuous and the treatment is binary. The dataset is generated using a modified version of `make_irm_data` function from the [`doubleml` package](https://docs.doubleml.org/stable/index.html).

    The general form of the data generating process is:

    $$
    y_i= g(d_i,\mathbf{X_i})+\epsilon_i
    $$
    $$
    d_i=f(\mathbf{X_i})+\eta_i
    $$

    where $y_i$ is the outcome, $d_i$ is the treatment, $\mathbf{X_i}$ are the confounders utilized for full effect heterogeneity, $\epsilon_i$ and $\eta_i$ are the error terms, $g$ is the outcome function, and $f$ is the treatment function.

    See the `doubleml` documentation for more details on the specific functional forms of the data generating process.

    Note that the treatment effect is fully heterogenous, thus the CATE is defined as: $\\tau = \\mathbb{E}[g(1,\mathbf{X}) - g(0,\mathbf{X})|\mathbf{X}]$ for any $\mathbf{X}$.

    The ATE is defined as the average of the CATE function over all observations: $\mathbb{E}[\\tau (\cdot)]$

    As a DAG, the data generating process can be roughly represented as:

    <div style="text-align: center;">
    ```{mermaid}
    flowchart TD;
        X((X))-->d((d));
        X((X))-->y((y));
        d((d))-->|"Ï„(X)"|y((y));
        linkStyle 0,1 stroke:black,stroke-width:2px
        linkStyle 1,2 stroke:black,stroke-width:2px
    ```
    </div>

    Parameters
    ----------
    n_obs : int
        The number of observations to generate.
    n_confounders : int
        The number of confounders $\mathbf{X_i}$ to generate (these are utilized fully for heterogeneity).
    theta : float
        The base parameter for the treatment effect. Note this differs from the ATE.
    seed : int | None
        The seed to use for the random number generator.
    **doubleml_kwargs
        Additional keyword arguments to pass to the data generating process.

    Returns
    -------
    df : pandas.DataFrame
        The generated dataset where y is the outcome, d is the treatment, and X are the confounders which are fully utilized for heterogeneity.
    true_cates : numpy.ndarray
        The true conditional average treatment effects.
    true_ate : float
        The true average treatment effect.

    Examples
    --------
    ```{python}
    from caml.extensions.synthetic_data import make_fully_heterogeneous_dataset
    df, true_cates, true_ate = make_fully_heterogeneous_dataset(n_obs=1000,
                                                                n_confounders=5,
                                                                theta=4.0,
                                                                seed=1)

    print(f"True CATEs: {true_cates[:5]}")
    print(f"True ATE: {true_ate}")
    print(df.head())
    ```
    """
    np.random.seed(seed)

    v = np.random.uniform(
        size=[
            n_obs,
        ]
    )
    zeta = np.random.standard_normal(
        size=[
            n_obs,
        ]
    )

    cov_mat = toeplitz([np.power(0.5, k) for k in range(n_confounders)])
    x = np.random.multivariate_normal(
        np.zeros(n_confounders),
        cov_mat,
        size=[
            n_obs,
        ],
    )

    R2_y = doubleml_kwargs.get("R2_y", 0.5)
    R2_d = doubleml_kwargs.get("R2_d", 0.5)

    beta = [1 / (k**2) for k in range(1, n_confounders + 1)]
    b_sigma_b = np.dot(np.dot(cov_mat, beta), beta)
    c_y = np.sqrt(R2_y / ((1 - R2_y) * b_sigma_b))
    c_d = np.sqrt(np.pi**2 / 3.0 * R2_d / ((1 - R2_d) * b_sigma_b))

    xx = np.exp(np.dot(x, np.multiply(beta, c_d)))
    d = 1.0 * ((xx / (1 + xx)) > v)

    def y_func(d, x, theta):
        return d * theta + d * np.dot(x, np.multiply(beta, c_y)) + zeta

    y = y_func(d, x, theta)

    x_cols = [f"X{i + 1}" for i in np.arange(n_confounders)]
    df = pd.DataFrame(np.column_stack((x, y, d)), columns=x_cols + ["y", "d"])

    d1 = np.ones_like(d)
    d0 = np.zeros_like(d)

    true_cates = y_func(d1, x, theta) - y_func(d0, x, theta)
    true_ate = true_cates.mean()

    return df, true_cates, true_ate
