{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: Pytorch Modules for Training Models for sequential data\n",
    "output-file: core.html\n",
    "title: Inference\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp inference.core\n",
    "#| default_cls_lvl 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from tsfast.datasets.core import extract_mean_std_from_dls\n",
    "from tsfast.data.loader import reset_model_state\n",
    "from tsfast.models.layers import NormalizedModel\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class InferenceWrapper:\n",
    "    \"\"\"\n",
    "    A wrapper class to simplify inference with a trained tsfast/fastai Learner\n",
    "    on NumPy data. Handles normalization and state reset automatically.\n",
    "    \"\"\"\n",
    "    def __init__(self, learner,device='cpu'):\n",
    "        \"\"\"\n",
    "        Initializes the inferencer.\n",
    "\n",
    "        Args:\n",
    "            learner: The trained tsfast/fastai Learner object.\n",
    "            device = 'cpu': The device to run the inference on.\n",
    "        \"\"\"\n",
    "        if not hasattr(learner, 'model') or not hasattr(learner, 'dls'):\n",
    "            raise TypeError(\"Input 'learner' object does not appear to be a valid fastai/tsfast Learner.\")\n",
    "\n",
    "        self.device = device\n",
    "        self.core_model = learner.model.to(self.device)\n",
    "\n",
    "        # Extract normalization stats\n",
    "        mean, std = extract_mean_std_from_dls(learner.dls)\n",
    "        if mean is None or std is None:\n",
    "             raise ValueError(\"Could not extract mean/std from learner's DataLoaders. Ensure normalization was used during training.\")\n",
    "\n",
    "        # Create and store the NormalizedModel\n",
    "        # Assuming the normalization stats are for the combined input if fransys is used\n",
    "        self.norm_model = NormalizedModel(self.core_model, mean, std).to(self.device)\n",
    "        self.norm_model.eval() # Set to evaluation mode\n",
    "\n",
    "    def inference(self, np_input: np.ndarray, np_output_init: np.ndarray = None) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Performs inference on the input NumPy data.\n",
    "\n",
    "        Args:\n",
    "            np_input: The primary input data as a NumPy array.\n",
    "                      Expected shapes: [seq_len] or [seq_len, features] or [1, seq_len, features].\n",
    "            np_output_init: Optional secondary input data (e.g., for FranSys) as a NumPy array.\n",
    "                            Expected shapes should be compatible with np_input after dimension expansion.\n",
    "\n",
    "        Returns:\n",
    "            The model's output as a NumPy array.\n",
    "        \"\"\"\n",
    "        # Store original ndim for potential concatenation axis determination later\n",
    "        original_ndim = np_input.ndim\n",
    "\n",
    "        # Add batch and feature dimensions if needed\n",
    "        if np_input.ndim == 1: # [seq_len] -> [1, seq_len, 1]\n",
    "            np_input = np.expand_dims(np_input, axis=(0, -1))\n",
    "            if np_output_init is not None:\n",
    "                 if np_output_init.ndim == 1:\n",
    "                     np_output_init = np.expand_dims(np_output_init, axis=(0, -1))\n",
    "                 elif np_output_init.ndim == 2: # Handle [seq_len, features] case for init\n",
    "                      np_output_init = np.expand_dims(np_output_init, axis=0)\n",
    "                 elif np_output_init.ndim != 3:\n",
    "                     raise ValueError(f\"np_output_init shape {np_output_init.shape} incompatible with 1D np_input\")\n",
    "\n",
    "        elif np_input.ndim == 2: # [seq_len, features] -> [1, seq_len, features]\n",
    "            np_input = np.expand_dims(np_input, axis=0)\n",
    "            if np_output_init is not None:\n",
    "                if np_output_init.ndim == 1: # Expand [seq_len] -> [1, seq_len, 1]\n",
    "                    np_output_init = np.expand_dims(np_output_init, axis=(0, -1))\n",
    "                elif np_output_init.ndim == 2: # Expand [seq_len, features] -> [1, seq_len, features]\n",
    "                     np_output_init = np.expand_dims(np_output_init, axis=0)\n",
    "                elif np_output_init.ndim != 3:\n",
    "                     raise ValueError(f\"np_output_init shape {np_output_init.shape} incompatible with 2D np_input\")\n",
    "\n",
    "        elif np_input.ndim == 3: # [1, seq_len, features] -> No change needed\n",
    "            if np_input.shape[0] != 1:\n",
    "                 raise ValueError(f\"Input data with 3 dimensions should have batch size 1. Provided shape: {np_input.shape}\")\n",
    "            if np_output_init is not None:\n",
    "                 if np_output_init.ndim == 1: # Expand [seq_len] -> [1, seq_len, 1]\n",
    "                     np_output_init = np.expand_dims(np_output_init, axis=(0, -1))\n",
    "                 elif np_output_init.ndim == 2: # Expand [seq_len, features] -> [1, seq_len, features]\n",
    "                      np_output_init = np.expand_dims(np_output_init, axis=0)\n",
    "                 elif np_output_init.ndim != 3:\n",
    "                      raise ValueError(f\"np_output_init shape {np_output_init.shape} incompatible with 3D np_input\")\n",
    "        else:\n",
    "            raise ValueError(f\"Input data should have 1, 2 or 3 dimensions. Provided shape: {np_input.shape}\")\n",
    "\n",
    "        # Concatenate inputs if np_output_init is provided\n",
    "        if np_output_init is not None:\n",
    "            # Ensure sequence lengths match\n",
    "            if np_input.shape[1] != np_output_init.shape[1]:\n",
    "                raise ValueError(f\"Sequence lengths of np_input ({np_input.shape[1]}) and np_output_init ({np_output_init.shape[1]}) must match.\")\n",
    "            # Concatenate along the feature dimension (last axis)\n",
    "            try:\n",
    "                np_combined_input = np.concatenate((np_input, np_output_init), axis=-1)\n",
    "            except ValueError as e:\n",
    "                 raise ValueError(f\"Could not concatenate inputs. Check shapes: np_input={np_input.shape}, np_output_init={np_output_init.shape}. Error: {e}\")\n",
    "            input_tensor = torch.from_numpy(np_combined_input).float().to(self.device)\n",
    "        else:\n",
    "            input_tensor = torch.from_numpy(np_input).float().to(self.device)\n",
    "\n",
    "\n",
    "        output_tensor = None\n",
    "        with torch.no_grad():\n",
    "            reset_model_state(self.core_model) # Reset state before each inference call\n",
    "            model_output = self.norm_model(input_tensor)\n",
    "\n",
    "            # Handle tuple outputs (common in some RNNs)\n",
    "            if isinstance(model_output, tuple):\n",
    "                output_tensor = model_output[0]\n",
    "            else:\n",
    "                output_tensor = model_output\n",
    "\n",
    "        if output_tensor is None:\n",
    "            raise RuntimeError(\"Model did not return a valid output tensor.\")\n",
    "\n",
    "        # Remove batch dimension and return as NumPy array\n",
    "        return output_tensor.squeeze(0).cpu().numpy()\n",
    "\n",
    "    def __call__(self, np_input: np.ndarray, np_output_init: np.ndarray = None) -> np.ndarray:\n",
    "        \"\"\"Allows calling the predictor instance like a function.\"\"\"\n",
    "        return self.inference(np_input, np_output_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsfast.datasets.core import create_dls_test\n",
    "from tsfast.learner import RNNLearner\n",
    "from tsfast.prediction import FranSysLearner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = create_dls_test()\n",
    "lrn = RNNLearner(dls)\n",
    "model = InferenceWrapper(lrn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(np.random.randn(100, 1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(np.random.randn(100)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(np.random.randn(1,100,1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrn = FranSysLearner(dls,10,attach_output=True)\n",
    "model = InferenceWrapper(lrn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(np.random.randn(100, 1),np.random.randn(100, 1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
