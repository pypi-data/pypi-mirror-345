{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: Pytorch Modules for Training Models for sequential data\n",
    "output-file: core.html\n",
    "title: Inference\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp inference.core\n",
    "#| default_cls_lvl 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from tsfast.datasets.core import extract_mean_std_from_dls\n",
    "from tsfast.data.loader import reset_model_state\n",
    "from tsfast.models.layers import NormalizedModel\n",
    "import warnings\n",
    "from tsfast.prediction.core import PredictionCallback\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class InferenceWrapper:\n",
    "    \"\"\"\n",
    "    (Docstring remains the same)\n",
    "    \"\"\"\n",
    "    def __init__(self, learner, device='cpu'):\n",
    "        # (Initialization remains the same: detect callback, store its state, get main norm)\n",
    "        if not hasattr(learner, 'model') or not hasattr(learner, 'dls'):\n",
    "            raise TypeError(\"Learner object seems invalid.\")\n",
    "        self.device = device\n",
    "        self.core_model = learner.model.to(self.device)\n",
    "        self._uses_prediction_callback = False\n",
    "        self._y_init_norm = None\n",
    "        self._pred_cb_t_offset = 0\n",
    "        for cb in learner.cbs:\n",
    "            if isinstance(cb, PredictionCallback):\n",
    "                if cb.norm is not None:\n",
    "                    self._uses_prediction_callback = True\n",
    "                    self._y_init_norm = cb.norm.to(device)\n",
    "                    self._pred_cb_t_offset = cb.t_offset\n",
    "                    print(f\"InferenceWrapper: Detected PredictionCallback(t_offset={self._pred_cb_t_offset}).\")\n",
    "                    break\n",
    "                else: warnings.warn(\"Found PredictionCallback, but norm uninitialized.\")\n",
    "        mean, std = extract_mean_std_from_dls(learner.dls)\n",
    "        if mean is None or std is None: raise ValueError(\"Could not extract main mean/std.\")\n",
    "        self.norm_model = NormalizedModel(self.core_model, mean, std).to(self.device)\n",
    "        self.norm_model.eval()\n",
    "        self.expected_feature_dim = self.norm_model.mean.shape[-1]\n",
    "\n",
    "    # --- Helper Functions (Keep these separate for clarity) ---\n",
    "    def _normalize_y_init(self, np_output_init: np.ndarray) -> torch.Tensor:\n",
    "        # ... (same as before)\n",
    "        if self._y_init_norm is None: raise RuntimeError(\"y_init normalizer not found.\")\n",
    "        y_init_tensor = torch.from_numpy(np_output_init).float().to(self.device)\n",
    "        return self._y_init_norm.normalize(y_init_tensor)\n",
    "\n",
    "    def _prepare_input_3d(self, np_ar: np.ndarray, name: str) -> np.ndarray:\n",
    "        # ... (same as before)\n",
    "        if np_ar.ndim == 1: np_ar = np.expand_dims(np_ar, axis=(0, -1))\n",
    "        elif np_ar.ndim == 2: np_ar = np.expand_dims(np_ar, axis=0)\n",
    "        elif np_ar.ndim != 3 or np_ar.shape[0] != 1:\n",
    "             raise ValueError(f\"{name} must be 1D/2D/3D(batch=1). Got {np_ar.shape}\")\n",
    "        return np_ar\n",
    "\n",
    "    def _adjust_seq_len(self, np_arr: np.ndarray, target_len: int, name: str) -> np.ndarray:\n",
    "        # ... (same as before)\n",
    "        current_len = np_arr.shape[1]\n",
    "        if current_len == target_len: return np_arr\n",
    "        if current_len < target_len:\n",
    "            pad_width = target_len - current_len\n",
    "            return np.pad(np_arr, ((0, 0), (0, pad_width), (0, 0)), mode='constant', constant_values=0)\n",
    "        # current_len > target_len\n",
    "        warnings.warn(f\"Truncating {name} len from {current_len} to {target_len}.\", UserWarning)\n",
    "        return np_arr[:, :target_len, :]\n",
    "    # -----------------------------------------------------------\n",
    "\n",
    "    def inference(self, np_input: np.ndarray, np_output_init: np.ndarray = None) -> np.ndarray:\n",
    "        # 1. Prepare u (np_input)\n",
    "        np_input = self._prepare_input_3d(np_input, \"np_input\")\n",
    "        u_features = np_input.shape[-1]\n",
    "        input_seq_len = np_input.shape[1]\n",
    "\n",
    "        # 2. Prepare final numpy input based on detected mode\n",
    "        final_np_input = None\n",
    "        if self._uses_prediction_callback:\n",
    "            if np_output_init is None: raise ValueError(\"PredictionCallback model requires np_output_init.\")\n",
    "            np_output_init = self._prepare_input_3d(np_output_init, \"np_output_init\")\n",
    "\n",
    "            effective_len = input_seq_len - self._pred_cb_t_offset\n",
    "            if effective_len <= 0: raise ValueError(f\"Input len too short for offset {self._pred_cb_t_offset}.\")\n",
    "\n",
    "            np_input_adj = np_input[:, self._pred_cb_t_offset:, :]\n",
    "            np_y_init_adj = self._adjust_seq_len(np_output_init, effective_len, \"y_init (for offset)\")\n",
    "            norm_y_init_np = self._normalize_y_init(np_y_init_adj).cpu().numpy()\n",
    "            final_np_input = np.concatenate((np_input_adj, norm_y_init_np), axis=-1)\n",
    "\n",
    "        elif np_output_init is None: # No callback, no y_init -> Check simulation\n",
    "            if u_features != self.expected_feature_dim:\n",
    "                 raise ValueError(f\"No y_init. Expected {self.expected_feature_dim} features, got {u_features}.\")\n",
    "            final_np_input = np_input # Simulation case\n",
    "\n",
    "        else: # No callback, but y_init provided -> Check dimensions\n",
    "             np_output_init = self._prepare_input_3d(np_output_init, \"np_output_init\")\n",
    "             y_init_features = np_output_init.shape[-1]\n",
    "\n",
    "             if u_features == self.expected_feature_dim: # Matches u alone\n",
    "                 warnings.warn(\"Input `u` matches expected features. Ignoring provided y_init.\", UserWarning)\n",
    "                 final_np_input = np_input # Simulation case\n",
    "             elif u_features + y_init_features == self.expected_feature_dim: # Matches u + y_init\n",
    "                 np_y_init_adj = self._adjust_seq_len(np_output_init, input_seq_len, \"y_init\") # Adjust raw y_init length\n",
    "                 final_np_input = np.concatenate((np_input, np_y_init_adj), axis=-1) # Dataloader Prediction case\n",
    "             else: # Dimension mismatch\n",
    "                 raise ValueError(f\"Dim mismatch. Expected {self.expected_feature_dim}. \"\n",
    "                                  f\"u:{u_features}, u+y_init:{u_features + y_init_features}.\")\n",
    "\n",
    "        # 3. Convert final prepared array to tensor\n",
    "        if final_np_input is None: raise RuntimeError(\"Internal error preparing input.\")\n",
    "        input_tensor = torch.from_numpy(final_np_input).float().to(self.device)\n",
    "\n",
    "        # 4. Run Inference\n",
    "        output_tensor = None\n",
    "        with torch.no_grad():\n",
    "            reset_model_state(self.core_model)\n",
    "            model_output = self.norm_model(input_tensor) # Main norm applied here\n",
    "            # Handle tuple outputs if necessary\n",
    "            if isinstance(model_output, tuple): output_tensor = model_output[0]\n",
    "            else: output_tensor = model_output\n",
    "\n",
    "        # 5. Return result\n",
    "        if output_tensor is None: raise RuntimeError(\"Model output is None.\")\n",
    "        return output_tensor.squeeze(0).cpu().numpy()\n",
    "\n",
    "    def __call__(self, np_input: np.ndarray, np_output_init: np.ndarray = None) -> np.ndarray:\n",
    "        return self.inference(np_input, np_output_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsfast.datasets.core import create_dls_test\n",
    "from tsfast.learner import RNNLearner\n",
    "from tsfast.prediction import FranSysLearner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = create_dls_test()\n",
    "lrn = RNNLearner(dls)\n",
    "model = InferenceWrapper(lrn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(np.random.randn(100, 1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(np.random.randn(100)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(np.random.randn(1,100,1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InferenceWrapper: Detected PredictionCallback(t_offset=0).\n"
     ]
    }
   ],
   "source": [
    "lrn = FranSysLearner(dls,10,attach_output=True)\n",
    "model = InferenceWrapper(lrn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(np.random.randn(100, 1),np.random.randn(100, 1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrn = FranSysLearner(dls,10,attach_output=False)\n",
    "model = InferenceWrapper(lrn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pc/13zbh_m514n1tp522cx9npt00000gn/T/ipykernel_5564/249888661.py:90: UserWarning: Input `u` matches expected features. Ignoring provided y_init.\n",
      "  warnings.warn(\"Input `u` matches expected features. Ignoring provided y_init.\", UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(100, 1)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(np.random.randn(100, 1),np.random.randn(100, 1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
