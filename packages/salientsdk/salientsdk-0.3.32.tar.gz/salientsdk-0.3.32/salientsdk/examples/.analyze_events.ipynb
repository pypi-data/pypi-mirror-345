{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Events (Prototype)\n",
    "\n",
    "This example shows how to evaluate Salient's forecasts with an event-and-decision framework. It demonstrates [validation best practices](https://salientpredictions.notion.site/Validation-0220c48b9460429fa86f577914ea5248).\n",
    "\n",
    "Status: under development. Not yet ready for external use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<requests.sessions.Session at 0x7f226f44e590>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score\n",
    "\n",
    "try:\n",
    "    import salientsdk as sk\n",
    "except ModuleNotFoundError as e:\n",
    "    if os.path.exists(\"../salientsdk\"):\n",
    "        sys.path.append(os.path.abspath(\"..\"))\n",
    "        import salientsdk as sk\n",
    "    else:\n",
    "        raise ModuleNotFoundError(\"Install salient SDK with: pip install salientsdk\")\n",
    "\n",
    "# Need Salient SDK v0.3.22 or later to use GEM:\n",
    "assert \"gem\" in sk.forecast_timeseries_api.MODELS\n",
    "\n",
    "# Prevent wrapping on tables for readability\n",
    "pd.set_option(\"display.width\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", 10)\n",
    "pd.set_option(\"display.expand_frame_repr\", False)\n",
    "\n",
    "sk.set_file_destination(\"analyze_events\")\n",
    "sk.login(\"username\", \"password\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customize The Validation\n",
    "\n",
    "This notebook is written flexibly so you have the option of validating Salient and other forecasts multiple ways. These variables will control what, when, and how the validation proceeds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. The meteorological variable that we'll be evaluating:\n",
    "var = \"tmax\"\n",
    "# var = \"tmin\"\n",
    "\n",
    "# 2. Number of standard deviations to be considered \"extreme\"\n",
    "ext_std = -2 if var == \"tmin\" else 2\n",
    "\n",
    "# 3. Number of historical forecast dates to download.\n",
    "if \"beta\" in sk.constants.URL:  # NOSHIP\n",
    "    date_freq = 30  # Get about 1 forecast per month.  Fast and indicative.\n",
    "else:\n",
    "    date_freq = 1  # Get every available historical forecast.  Comprehensive.\n",
    "\n",
    "# 4. Strategy for optimizing extreme thresholds.\n",
    "# groupby = [\"lead\", \"location\"]\n",
    "groupby = [\"lead\"]\n",
    "\n",
    "# 5. Cost-loss framework payoff matrix\n",
    "beta = 1\n",
    "# beta = 2 # F2 weights recall higher than precision\n",
    "\n",
    "# fmt: off\n",
    "payoff = {\n",
    "    # Payoff coefficients for a 2x2 confusion matrix:\n",
    "    \"np\":  -10,  \"pp\":  100, # Acting on a FP costs a little, Correctly calling a TP is worth a lot\n",
    "    \"nn\":    0,  \"pn\":    0, # take no action, gain/lose nothing\n",
    "    # Joint 4x2 confusion matrix strategy\n",
    "    \"npp\": -10, \"ppp\":  100, # both agree. Same payout as 2x2 case.\n",
    "    \"npn\": -20, \"ppn\":  200, # GEM extreme, GEFS normal.  Double position size.\n",
    "    \"nnp\":  40, \"pnp\": -400, # GEFS extreme, GEM normal.  Short the market.  Lose big if an extreme happens.\n",
    "    \"nnn\":   0, \"pnn\":   0,  # neither extreme, take no action.\n",
    "    # For setting axis labels\n",
    "    \"units\": \"$M\",\n",
    "}\n",
    "# fmt: off\n",
    "\n",
    "\n",
    "# The quantity to optimize\n",
    "objective = \"payoff\"\n",
    "# objective = \"f_score\"\n",
    "\n",
    "# Number of days to analyze\n",
    "lead_days = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constants and Settings\n",
    "\n",
    "Not recommended to change these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print diagnostic information\n",
    "verbose = False\n",
    "\n",
    "# Caching strategy:\n",
    "force = False  # Cache data to save on repeat API calls\n",
    "# force = True  # Repeat API calls, even if data exists\n",
    "\n",
    "# The name of the primary forecast model to test\n",
    "gem_model = \"gem\"\n",
    "\n",
    "# The reference model to compare gem_model to\n",
    "ref_model = \"noaa_gefs\"\n",
    "\n",
    "# Set the forecast date range to test over.\n",
    "(start_date, end_date) = (\"2020-10-01\", \"2024-12-31\")\n",
    "date_range = pd.date_range(start=start_date, end=end_date, freq=\"D\")\n",
    "date_range = date_range[::date_freq]\n",
    "\n",
    "if var == \"tmax\":\n",
    "    summer_months = [5, 6, 7, 8]\n",
    "    date_range = date_range[date_range.month.isin(summer_months)]\n",
    "elif var == \"tmin\":\n",
    "    winter_months = [11, 12, 1, 2]\n",
    "    date_range = date_range[date_range.month.isin(winter_months)]\n",
    "\n",
    "date_range = date_range.strftime(\"%Y-%m-%d\").tolist()\n",
    "\n",
    "# Temporal resolution.  \"hourly\" not yet supported\n",
    "freq = \"daily\"\n",
    "\n",
    "# We're going to conduct this investigation in absolute (not anomaly) space\n",
    "field = \"vals\"\n",
    "field_ens = f\"{field}_ens\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Set the Area of Interest\n",
    "\n",
    "The Salient SDK uses a \"Location\" object to specify the geographic bounds of a request. In this case, we will be testing 11 cities representing ERCOT's 8 [weather zones](https://www.ercot.com/gridmktinfo/dashboards/weatherforecast).  In the following code, only `lats`, `lons`, and `names` are required.  The other inputs are for reference purpose only.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        lat       lon name    region    weight               city                   geometry\n",
      "0   31.9686 -102.0779  MAF   FarWest   117.631            Midland  POINT (-102.0779 31.9686)\n",
      "1   33.5779 -101.8552  LBB     North   264.662            Lubbock  POINT (-101.8552 33.5779)\n",
      "2   33.9137  -98.4934  SPS     North   104.683      Wichita Falls   POINT (-98.4934 33.9137)\n",
      "3   32.4487  -99.7331  ABI      West   124.407            Abilene   POINT (-99.7331 32.4487)\n",
      "4   32.8972  -97.0403  DFW  NCentral  7637.387  Dallas/Fort Worth   POINT (-97.0403 32.8972)\n",
      "..      ...       ...  ...       ...       ...                ...                        ...\n",
      "6   30.2672  -97.7431  AUS  SCentral  2227.083             Austin   POINT (-97.7431 30.2672)\n",
      "7   29.4241  -98.4936  SAT  SCentral  1598.964        San Antonio   POINT (-98.4936 29.4241)\n",
      "8   29.7604  -95.3698  IAH     Coast  7122.240            Houston   POINT (-95.3698 29.7604)\n",
      "9   27.8006  -97.3964  CRP     South   326.586     Corpus Christi   POINT (-97.3964 27.8006)\n",
      "10  26.2034  -98.2300  MFE     South   871.377            McAllen     POINT (-98.23 26.2034)\n",
      "\n",
      "[11 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# fmt: off\n",
    "loc = sk.Location(location_file=sk.upload_location_file(\n",
    "    lats    =[  31.9686,   33.5779,  33.9137,  32.4487,    32.8972,  32.3513,    30.2672,    29.4241,  29.7604,  27.8006,  26.2034],\n",
    "    lons    =[-102.0779, -101.8552, -98.4934, -99.7331,   -97.0403, -95.3011,   -97.7431,   -98.4936, -95.3698, -97.3964, -98.2300],\n",
    "    names   =[    \"MAF\",     \"LBB\",    \"SPS\",    \"ABI\",      \"DFW\",    \"TYR\",      \"AUS\",      \"SAT\",    \"IAH\",    \"CRP\",    \"MFE\"],\n",
    "    region  =[\"FarWest\",   \"North\",  \"North\",   \"West\", \"NCentral\",   \"East\", \"SCentral\", \"SCentral\",  \"Coast\",  \"South\",  \"South\"],\n",
    "    weight  =[  117.631,   264.662,  104.683,  124.407,   7637.387,  108.505,   2227.083,   1598.964, 7122.240,  326.586,  871.377],\n",
    "    city    =[\"Midland\", \"Lubbock\", \"Wichita Falls\", \"Abilene\", \"Dallas/Fort Worth\", \"Tyler\", \"Austin\", \"San Antonio\", \"Houston\", \"Corpus Christi\", \"McAllen\"],\n",
    "    geoname =\"ercot_weather_zones\",\n",
    "    force   =force\n",
    "))\n",
    "# fmt: on\n",
    "print(loc.load_location_file())\n",
    "# loc.plot_locations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Forecasts & Observed\n",
    "\n",
    "Use the Salient API to get the Salient GEM forecast, then compare it to historical observed as well as a reference model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset> Size: 428kB\n",
      "Dimensions:   (time: 1573, location: 11)\n",
      "Coordinates:\n",
      "  * time      (time) datetime64[ns] 13kB 2020-09-26 2020-09-27 ... 2025-01-15\n",
      "    lat       (location) float64 88B 31.97 33.58 33.91 32.45 ... 29.76 27.8 26.2\n",
      "    lon       (location) float64 88B -102.1 -101.9 -98.49 ... -97.4 -98.23\n",
      "  * location  (location) <U3 132B 'MAF' 'LBB' 'SPS' 'ABI' ... 'IAH' 'CRP' 'MFE'\n",
      "Data variables:\n",
      "    vals      (time, location) float64 138kB 36.24 36.18 32.55 ... 12.5 13.49\n",
      "    clim      (time, location) float64 138kB 29.87 27.83 30.73 ... 18.95 22.51\n",
      "    stdv      (time, location) float64 138kB 3.775 3.927 4.094 ... 4.292 5.463\n",
      "Attributes:\n",
      "    long_name:   2 metre temperature\n",
      "    units:       degC\n",
      "    clim_start:  1990-01-01\n",
      "    clim_end:    2019-12-31\n",
      "<xarray.DataArray ()> Size: 8B\n",
      "array(256)\n"
     ]
    }
   ],
   "source": [
    "# Historical observed data - what really happened\n",
    "obs_start = np.datetime64(start_date) - np.timedelta64(5, \"D\")\n",
    "obs_end = np.datetime64(end_date) + np.timedelta64(lead_days + 1, \"D\")\n",
    "obs_src = sk.data_timeseries(\n",
    "    loc=loc,\n",
    "    variable=var,\n",
    "    field=field,\n",
    "    start=obs_start,\n",
    "    end=obs_end,\n",
    "    frequency=freq,\n",
    "    verbose=verbose,\n",
    "    force=force,\n",
    ")\n",
    "\n",
    "# Climatology: historical mean & standard deviation on this day\n",
    "clim = sk.data_timeseries_api.extrapolate_trend(\n",
    "    loc=loc, variable=var, start=obs_start, end=obs_end, verbose=verbose, force=force\n",
    ")\n",
    "stdv = sk.data_timeseries_api.extrapolate_trend(\n",
    "    loc=loc, variable=var, start=obs_start, end=obs_end, verbose=verbose, force=force, stdv_mult=1\n",
    ")\n",
    "stdv = stdv - clim\n",
    "\n",
    "obs_ts = xr.merge(\n",
    "    [xr.load_dataset(obs_src), clim.rename({var: \"clim\"}), stdv.rename({var: \"stdv\"})]\n",
    ")\n",
    "\n",
    "print(obs_ts)\n",
    "print((((obs_ts.vals - obs_ts.clim) / obs_ts.stdv) > ext_std).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Salient GEM hindcasts\n",
    "gem_src = sk.forecast_timeseries(\n",
    "    loc=loc,\n",
    "    variable=var,\n",
    "    date=date_range,\n",
    "    model=gem_model,\n",
    "    field=field_ens,\n",
    "    timescale=freq,\n",
    "    strict=False,\n",
    "    force=force,\n",
    "    verbose=verbose,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference model: the forecast we are comparing Salient GEM to\n",
    "ref_src = sk.forecast_timeseries(\n",
    "    loc=loc,\n",
    "    variable=var,\n",
    "    date=date_range,\n",
    "    field=field_ens,\n",
    "    model=ref_model,\n",
    "    timescale=freq,\n",
    "    strict=False,\n",
    "    force=force,\n",
    "    verbose=verbose,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package data into identical forecast_date & lead coordintes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = sk.forecast_timeseries_api.stack_forecast(ref_src)\n",
    "gem = sk.forecast_timeseries_api.stack_forecast(gem_src)\n",
    "\n",
    "# Forecasts have different time horizons.  Align them.\n",
    "ref = ref.isel(lead=slice(0, lead_days))\n",
    "gem = gem.isel(lead=slice(0, lead_days))\n",
    "\n",
    "# Use common dates where both ref and gem have no NaNs\n",
    "valid_dims = [\"lead\", \"location\", \"ensemble\"]\n",
    "valid_dates = ~gem[field_ens].isnull().any(dim=valid_dims) & ~ref[field_ens].isnull().any(\n",
    "    dim=valid_dims\n",
    ")\n",
    "gem = gem.sel(forecast_date=valid_dates)\n",
    "ref = ref.sel(forecast_date=valid_dates)\n",
    "\n",
    "# Let's make sure the forecasts are equivalent\n",
    "xr.testing.assert_equal(gem.time, ref.time)\n",
    "xr.testing.assert_equal(gem.lead, ref.lead)\n",
    "xr.testing.assert_equal(gem.location, ref.location)\n",
    "\n",
    "print(f\"{gem_model} {gem.data_vars}\")\n",
    "print(f\"{ref_model} {ref.data_vars}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape historical obs match forecast dimensions\n",
    "obs = sk.data_timeseries_api.stack_history(obs_ts, gem.forecast_date, gem.lead)\n",
    "\n",
    "# Add population as a weighting factor\n",
    "# obs = sk.merge_location_data(obs, loc, False)\n",
    "\n",
    "xr.testing.assert_equal(gem.time, obs.time)\n",
    "xr.testing.assert_equal(gem.lead, obs.lead)\n",
    "xr.testing.assert_equal(gem.location, obs.location)\n",
    "\n",
    "print(\"ERA5: \" + str(obs.data_vars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set some attributes for later plotting purposes\n",
    "\n",
    "# Preserve model description for later plotting purposes\n",
    "obs[field].attrs[\"model_name\"] = \"ERA5\"\n",
    "gem[field_ens].attrs[\"model_name\"] = gem_model.split(\"_\")[-1].upper()\n",
    "ref[field_ens].attrs[\"model_name\"] = ref_model.split(\"_\")[-1].upper()\n",
    "\n",
    "# Assign each model a distinct color\n",
    "obs[field].attrs[\"color\"] = \"black\"\n",
    "gem[field_ens].attrs[\"color\"] = \"dodgerblue\"\n",
    "ref[field_ens].attrs[\"color\"] = \"#FF8C1E\"\n",
    "\n",
    "# plotting can get confused by timedelta.  Have a convenient numeric version:\n",
    "lead_days = [td.astype(\"timedelta64[D]\").astype(int) for td in gem.lead.values]\n",
    "obs = obs.assign_coords(lead_days=(\"lead\", lead_days))\n",
    "gem = gem.assign_coords(lead_days=(\"lead\", lead_days))\n",
    "ref = ref.assign_coords(lead_days=(\"lead\", lead_days))\n",
    "obs.lead_days.attrs.update({\"long_name\": \"Lead time\", \"units\": \"days\"})\n",
    "gem.lead_days.attrs.update({\"long_name\": \"Lead time\", \"units\": \"days\"})\n",
    "ref.lead_days.attrs.update({\"long_name\": \"Lead time\", \"units\": \"days\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Extremes\n",
    "\n",
    "Define `obs.extreme` as true if the observed variable exceeded the extreme threshold.\n",
    "Define `ref` and `gem.extreme_pct` extreme as a sigmoid function of the normalized extreme as it relates to the threshold.\n",
    "\n",
    "This sets us up to create a classifier that will determine the number of extreme ensembles required for us to say that an extreme is likely.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENS = \"anom_ens_stdv\"\n",
    "with xr.set_options(keep_attrs=True):\n",
    "    # Normalize absolute values into standard deviation anom space\n",
    "    obs[\"anom_stdv\"] = ((obs[field] - obs[\"clim\"]) / obs[\"stdv\"]).assign_attrs(units=\"\\u03c3\")\n",
    "    gem[ENS] = ((gem[field_ens] - obs[\"clim\"]) / obs[\"stdv\"]).assign_attrs(units=\"\\u03c3\")\n",
    "    ref[ENS] = ((ref[field_ens] - obs[\"clim\"]) / obs[\"stdv\"]).assign_attrs(units=\"\\u03c3\")\n",
    "\n",
    "obs[\"extreme\"] = sk.event.classify_event(obs[\"anom_stdv\"], ext_std, width=0)\n",
    "# ref[\"extreme_pct\"] = sk.event.classify_event(ref[ENS], ext_std, dim=\"ensemble\")\n",
    "# gem[\"extreme_pct\"] = sk.event.classify_event(gem[ENS], ext_std, dim=\"ensemble\")\n",
    "gem[\"extreme_pct\"] = sk.event.calibrate_event(obs[\"extreme\"], gem[ENS], groupby)\n",
    "ref[\"extreme_pct\"] = sk.event.calibrate_event(obs[\"extreme\"], ref[ENS], groupby)\n",
    "\n",
    "print(f\"{obs['extreme'].attrs['model_name']} {obs[['extreme']].data_vars}\")\n",
    "print(f\"{ref['extreme_pct'].attrs['model_name']} {ref[['extreme_pct']].data_vars}\")\n",
    "print(f\"{gem['extreme_pct'].attrs['model_name']} {gem[['extreme_pct']].data_vars}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize Extremes Detection Threshold\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gem[\"extreme_threshold\"] = sk.event.optimize_threshold(\n",
    "    observed=obs.extreme,\n",
    "    forecast=gem.extreme_pct,\n",
    "    payoff=payoff,\n",
    "    beta=beta,\n",
    "    groupby=groupby,\n",
    ")\n",
    "\n",
    "ref[\"extreme_threshold\"] = sk.event.optimize_threshold(\n",
    "    observed=obs.extreme,\n",
    "    forecast=ref.extreme_pct,\n",
    "    payoff=payoff,\n",
    "    beta=beta,\n",
    "    groupby=groupby,\n",
    ")\n",
    "\n",
    "with xr.set_options(keep_attrs=True):\n",
    "    gem[\"extreme\"] = gem[\"extreme_pct\"] >= gem[\"extreme_threshold\"]\n",
    "    ref[\"extreme\"] = ref[\"extreme_pct\"] >= ref[\"extreme_threshold\"]\n",
    "\n",
    "print_vars = [\"extreme_threshold\", \"extreme\"]\n",
    "print(f\"{gem.extreme.attrs['model_name']} {gem[print_vars].data_vars}\")\n",
    "print(f\"{ref.extreme.attrs['model_name']} {ref[print_vars].data_vars}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Confusion Matrices\n",
    "\n",
    "A confusion matrix compares predictions against reality in a simple grid format. For any prediction system, it tallies four possible outcomes: correct predictions of both events and non-events (true positives and true negatives), false alarms (false positives), and missed events (false negatives). The name comes from its ability to reveal when the system gets \"confused\" - either crying wolf or missing actual events.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby location & lead\n",
    "display(sk.event.style_confusion_matrix(obs.extreme, gem.extreme, payoff=payoff, beta=beta))\n",
    "display(sk.event.style_confusion_matrix(obs.extreme, ref.extreme, payoff=payoff, beta=beta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payoffs = [\n",
    "    sk.event.calc_f_score(obs.extreme, ref.extreme, groupby=\"lead\", payoff=payoff)[\"payoff\"],\n",
    "    sk.event.calc_f_score(obs.extreme, gem.extreme, groupby=\"lead\", payoff=payoff)[\"payoff\"],\n",
    "]\n",
    "\n",
    "pcolors = [payoff.attrs[\"color\"] for payoff in payoffs]\n",
    "payoffs = {payoff.attrs[\"model_name\"]: payoff.mean().item() for payoff in payoffs}\n",
    "plt.figure(figsize=(8, 4))\n",
    "bars = plt.bar(payoffs.keys(), payoffs.values(), color=pcolors)\n",
    "plt.axhline(y=payoffs[\"GEFS\"], color=\"lightgrey\", linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "lifts = {\"GEM\": (payoffs[\"GEM\"] / payoffs[\"GEFS\"] - 1) * 100}\n",
    "for i, key in enumerate([\"GEM\"]):\n",
    "    lift = lifts[key]\n",
    "    bar = bars[i + 1]\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width() / 2.0,\n",
    "        (bar.get_height() + payoffs[\"GEFS\"]) / 2,\n",
    "        f\"+{lift:.0f}%\",\n",
    "        ha=\"center\",\n",
    "        va=\"center\",\n",
    "        color=\"white\",\n",
    "        fontweight=\"bold\",\n",
    "    )\n",
    "\n",
    "plt.ylabel(\"Expected Payoff [$M]\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code - analysis and visualization\n",
    "\n",
    "This section contains code that will be used later in the notebook for visualization and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_crps(\n",
    "    observations: xr.DataArray, forecast: xr.DataArray, reference: xr.DataArray, groupby: str\n",
    "):\n",
    "    \"\"\"Calculate CRPS for forecast and reference models, then visualize comparison grouped by a dimension.\n",
    "\n",
    "    Args:\n",
    "        observations: DataArray containing observed values\n",
    "        forecast: DataArray containing forecast ensemble values\n",
    "        reference: DataArray containing reference ensemble values\n",
    "        groupby: Dimension to group by (string only)\n",
    "\n",
    "    Returns:\n",
    "        Decisionmaking metrics from forecast and reference.\n",
    "\n",
    "    \"\"\"\n",
    "    fcst_crps = sk.skill._crps_ensemble_core(observations=observations, forecasts=forecast)\n",
    "    ref_crps = sk.skill._crps_ensemble_core(observations=observations, forecasts=reference)\n",
    "\n",
    "    # Calculate mean CRPS across all dimensions except the groupby dimension\n",
    "    dims_to_mean = [dim for dim in fcst_crps.dims if dim != groupby]\n",
    "    fcst_crps_mean = fcst_crps.mean(dim=dims_to_mean)\n",
    "    ref_crps_mean = ref_crps.mean(dim=dims_to_mean)\n",
    "\n",
    "    # Add model names\n",
    "    fcst_model_name = forecast.attrs.get(\"model_name\", \"Forecast\")\n",
    "    ref_model_name = reference.attrs.get(\"model_name\", \"Reference\")\n",
    "\n",
    "    fcst_color = forecast.attrs.get(\"color\", \"dodgerblue\")\n",
    "    ref_color = reference.attrs.get(\"color\", \"#FF8C1E\")\n",
    "\n",
    "    # Determine if the groupby dimension is numerical or categorical\n",
    "    coord_values = forecast[groupby].values\n",
    "\n",
    "    # Check if values are numerical (dates, times, or numbers)\n",
    "    is_numerical = (\n",
    "        np.issubdtype(coord_values.dtype, np.number)\n",
    "        or np.issubdtype(coord_values.dtype, np.datetime64)\n",
    "        or isinstance(coord_values[0], (pd.Timestamp, np.timedelta64))\n",
    "    )\n",
    "\n",
    "    # Create figure\n",
    "    fig, ax = plt.subplots(figsize=(9, 4))\n",
    "\n",
    "    if is_numerical:\n",
    "        # For timedelta, convert to days for better readability\n",
    "        if np.issubdtype(coord_values.dtype, np.timedelta64):\n",
    "            x_values = np.array([td.astype(\"timedelta64[D]\").astype(int) for td in coord_values])\n",
    "            x_label = f\"{groupby} (days)\"\n",
    "            marker = \".\"\n",
    "        else:\n",
    "            x_values = coord_values\n",
    "            x_label = groupby\n",
    "            marker = \"None\"\n",
    "\n",
    "        ax.plot(\n",
    "            x_values,\n",
    "            fcst_crps_mean.values,\n",
    "            linestyle=\"-\",\n",
    "            marker=marker,\n",
    "            color=fcst_color,\n",
    "            linewidth=2,\n",
    "            label=fcst_model_name,\n",
    "        )\n",
    "        ax.plot(\n",
    "            x_values,\n",
    "            ref_crps_mean.values,\n",
    "            linestyle=\"-\",\n",
    "            marker=marker,\n",
    "            color=ref_color,\n",
    "            linewidth=2,\n",
    "            label=ref_model_name,\n",
    "        )\n",
    "\n",
    "        # Format x-axis for dates\n",
    "        if np.issubdtype(coord_values.dtype, np.datetime64):\n",
    "            fig.autofmt_xdate()\n",
    "\n",
    "    else:\n",
    "        # Convert to pandas DataFrame for easier manipulation\n",
    "        df = pd.DataFrame(\n",
    "            {\n",
    "                fcst_model_name: fcst_crps_mean.values,\n",
    "                ref_model_name: ref_crps_mean.values,\n",
    "                \"difference\": ref_crps_mean.values - fcst_crps_mean.values,\n",
    "                groupby: fcst_crps_mean[groupby].values,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Sort by difference between reference and forecast (note: for CRPS, lower is better)\n",
    "        df = df.sort_values(\"difference\", ascending=False)\n",
    "\n",
    "        x = np.arange(len(df))\n",
    "        width = 0.35\n",
    "\n",
    "        ax.bar(x - width / 2, df[fcst_model_name], width, label=fcst_model_name, color=fcst_color)\n",
    "        ax.bar(x + width / 2, df[ref_model_name], width, label=ref_model_name, color=ref_color)\n",
    "\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(df[groupby], rotation=90 if len(df) > 10 else 0)\n",
    "\n",
    "    ax.set_ylabel(\"CRPS\")\n",
    "    ax.set_xlabel(x_label if is_numerical else groupby)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend(loc=\"best\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    results = xr.Dataset({\"forecast\": fcst_crps_mean, \"reference\": ref_crps_mean})\n",
    "\n",
    "    # Add model names as attributes\n",
    "    results.forecast.attrs[\"model_name\"] = fcst_model_name\n",
    "    results.reference.attrs[\"model_name\"] = ref_model_name\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "if False:\n",
    "    crps_date = compare_crps(obs[field], gem[field_ens], ref[field_ens], \"lead\")\n",
    "    # crps_date = compare_crps(obs[field], gem[field_ens], ref[field_ens], \"forecast_date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_extremes_timeseries(\n",
    "    observed: xr.Dataset, forecast: xr.Dataset | None = None, reference: xr.Dataset | None = None\n",
    "):\n",
    "    \"\"\"Plot a time series of observed data with optional forecast and reference data.\n",
    "\n",
    "    Args:\n",
    "        observed: xr.Dataset containing observed data\n",
    "        forecast: Optional xr.Dataset containing forecast data\n",
    "        reference: Optional xr.Dataset containing reference data\n",
    "\n",
    "    Returns:\n",
    "        fig, ax: The figure and axis objects\n",
    "    \"\"\"\n",
    "    if forecast is None and reference is None:\n",
    "        raise ValueError(\"At least one of forecast or reference must be provided\")\n",
    "\n",
    "    lead_days = obs.lead_days.values\n",
    "    target = obs.extreme.attrs.get(\"target\", 1)\n",
    "    sign = 1 if target > 0 else -1\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(9, 4))\n",
    "\n",
    "    ax.plot(lead_days, observed.anom_stdv.values, color=\"black\", linewidth=3, label=\"Observed\")\n",
    "    ax.axhline(y=target, color=\"grey\", linestyle=\"--\", label=f\"Extreme Threshold ({target}\\u03c3)\")\n",
    "    ax.set_xlabel(\"Lead Time [days]\")\n",
    "    ax.set_ylabel(f\"Anomaly [\\u03c3]\")\n",
    "\n",
    "    def plot_forecast_data(data, color, label):\n",
    "        \"\"\"Plot fcst/ref data.\"\"\"\n",
    "        if data is None:\n",
    "            return None\n",
    "        label = data.anom_ens_stdv.attrs.get(\"model_name\", label)\n",
    "        color = data.anom_ens_stdv.attrs.get(\"color\", color)\n",
    "\n",
    "        # Calculate 10-90th percentile band using xarray's native functionality\n",
    "        lower_bound = data.anom_ens_stdv.quantile(0.1, dim=\"ensemble\").values\n",
    "        upper_bound = data.anom_ens_stdv.quantile(0.9, dim=\"ensemble\").values\n",
    "\n",
    "        # Plot the 10-90th percentile band\n",
    "        ax.fill_between(\n",
    "            lead_days, lower_bound, upper_bound, color=color, alpha=0.3, label=f\"{label} p10-p90\"\n",
    "        )\n",
    "\n",
    "        extreme_condition = sign * data.anom_ens_stdv >= sign * target\n",
    "\n",
    "        # Create DataArrays with lead day values repeated for each ensemble member\n",
    "        lead_days_array = xr.DataArray(lead_days, dims=[\"lead\"], coords={\"lead\": data.lead})\n",
    "        lead_days_ens = lead_days_array.expand_dims(ensemble=data.ensemble.size)\n",
    "\n",
    "        # Extract coordinates and values for true positives & false alarms\n",
    "        true_positive_mask = (data.extreme == True) & (observed.extreme == True)\n",
    "        false_alarm_mask = (data.extreme == True) & (observed.extreme == False)\n",
    "        tp_x = lead_days_ens.where(\n",
    "            extreme_condition & true_positive_mask.expand_dims(ensemble=data.ensemble.size)\n",
    "        )\n",
    "        tp_y = data.anom_ens_stdv.where(\n",
    "            extreme_condition & true_positive_mask.expand_dims(ensemble=data.ensemble.size)\n",
    "        )\n",
    "        fa_x = lead_days_ens.where(\n",
    "            extreme_condition & false_alarm_mask.expand_dims(ensemble=data.ensemble.size)\n",
    "        )\n",
    "        fa_y = data.anom_ens_stdv.where(\n",
    "            extreme_condition & false_alarm_mask.expand_dims(ensemble=data.ensemble.size)\n",
    "        )\n",
    "\n",
    "        # Plot true positives\n",
    "        if not tp_x.isnull().all():\n",
    "            # Extract valid points\n",
    "            valid_x = tp_x.values.flatten()[~np.isnan(tp_x.values.flatten())]\n",
    "            valid_y = tp_y.values.flatten()[~np.isnan(tp_y.values.flatten())]\n",
    "\n",
    "            # Add small random jitter in x-direction (±0.2)\n",
    "            jittered_x = valid_x + np.random.uniform(-0.2, 0.2, size=len(valid_x))\n",
    "\n",
    "            ax.scatter(\n",
    "                jittered_x,\n",
    "                valid_y,\n",
    "                s=36,\n",
    "                marker=\"o\",\n",
    "                color=color,\n",
    "                alpha=0.7,\n",
    "                label=f\"{label} True Positive\",\n",
    "            )\n",
    "\n",
    "        # Plot false alarms\n",
    "        if not fa_x.isnull().all():\n",
    "            # Extract valid points\n",
    "            valid_x = fa_x.values.flatten()[~np.isnan(fa_x.values.flatten())]\n",
    "            valid_y = fa_y.values.flatten()[~np.isnan(fa_y.values.flatten())]\n",
    "\n",
    "            # Add small random jitter in x-direction (±0.2)\n",
    "            jittered_x = valid_x + np.random.uniform(-0.2, 0.2, size=len(valid_x))\n",
    "\n",
    "            ax.scatter(\n",
    "                jittered_x,\n",
    "                valid_y,\n",
    "                s=36,\n",
    "                marker=\"o\",\n",
    "                facecolors=\"white\",\n",
    "                edgecolors=color,\n",
    "                linewidths=1.5,\n",
    "                alpha=0.7,\n",
    "                label=f\"{label} False Alarm\",\n",
    "            )\n",
    "\n",
    "    plot_forecast_data(forecast, \"dodgerblue\", \"Forecast\")\n",
    "    plot_forecast_data(reference, \"#FF8C1E\", \"Reference\")\n",
    "\n",
    "    location = observed.location.values\n",
    "    forecast_date = pd.to_datetime(observed.forecast_date.values).strftime(\"%Y-%m-%d\")\n",
    "    ax.set_title(f\"{location}: {forecast_date}\")\n",
    "\n",
    "    ax.legend(prop={\"size\": 8})\n",
    "\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "if False:\n",
    "    dex = \"2023-06-18\"\n",
    "    lex = \"MAF\"\n",
    "    plot_extremes_timeseries(\n",
    "        obs.sel(location=lex, forecast_date=dex),\n",
    "        gem.sel(location=lex, forecast_date=dex),\n",
    "        ref.sel(location=lex, forecast_date=dex),\n",
    "    )\n",
    "\n",
    "\n",
    "if False:\n",
    "    cex = find_confusion_examples(\n",
    "        obs.extreme, gem.extreme, ref.extreme, [\"location\", \"forecast_date\"]\n",
    "    )[\"ppp\"]\n",
    "    dex = cex[\"forecast_date\"].values[0]\n",
    "    lex = cex[\"location\"].values[0]\n",
    "    plot_extremes_timeseries(\n",
    "        obs.sel(location=lex, forecast_date=dex),\n",
    "        gem.sel(location=lex, forecast_date=dex),\n",
    "        ref.sel(location=lex, forecast_date=dex),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_confusion_examples(\n",
    "    observations: xr.DataArray,\n",
    "    forecast: xr.DataArray,\n",
    "    reference: xr.DataArray | None = None,\n",
    "    groupby: str | list[str] | None = None,\n",
    ") -> dict[str, pd.DataFrame]:\n",
    "    \"\"\"Find most compelling examples for each confusion matrix category.\n",
    "\n",
    "    Args:\n",
    "        observations: Binary array of observed events\n",
    "        forecast: Binary array of forecast events\n",
    "        reference: Optional binary array of reference forecast events.\n",
    "            If provided, finds examples for joint (4x2) confusion matrix.\n",
    "            If omitted, finds examples over the simple (2x2) confusion matrix.\n",
    "        groupby: dimensions to include in the return dictionary coordinates\n",
    "\n",
    "    Returns:\n",
    "        Dictionary mapping category names to DataFrames containing top 10 examples\n",
    "        with their coordinates and scores\n",
    "    \"\"\"\n",
    "    cm = sk.event.build_confusion_matrix(observations, forecast, reference, groupby=groupby)\n",
    "\n",
    "    if reference is None:\n",
    "        # 2x2 confusion matrix scoring\n",
    "        scores = {\n",
    "            \"pp\": cm.pp - 0.5 * cm.np - 0.5 * cm.pn,\n",
    "            \"nn\": cm.nn - 0.5 * cm.pp - 0.5 * cm.pn,\n",
    "            \"np\": cm.np - 0.5 * cm.pn - 0.2 * cm.pp,\n",
    "            \"pn\": cm.pn - 0.5 * cm.np - 0.2 * cm.pp,\n",
    "        }\n",
    "    else:\n",
    "        fp = cm.npp + cm.npn + cm.nnp  # all 3 false positive types, cry wolf\n",
    "        fn = cm.pnn + cm.pnp + cm.ppn  # all 3 false negative types, failure to detect\n",
    "\n",
    "        # 4x2 joint confusion matrix scoring\n",
    "        scores = {\n",
    "            # both right\n",
    "            \"ppp\": cm.ppp + 0.1 * (cm.pnp + cm.ppn) - 0.5 * (cm.pnn + fp),\n",
    "            \"nnn\": cm.nnn + 0.1 * (cm.npn + cm.nnp) - 0.5 * (cm.npp + fn),\n",
    "            # both wrong\n",
    "            \"npp\": cm.npp + 0.1 * (cm.npn + cm.nnp) - 0.5 * fn,\n",
    "            \"pnn\": cm.pnn + 0.1 * (cm.pnp + cm.ppn) - 0.5 * fp,\n",
    "            # Mixed, false negative\n",
    "            \"ppn\": cm.ppn + 0.2 * cm.nnp - 0.5 * (cm.npn + cm.ppp + cm.npp + cm.pnn) - 2 * cm.pnp,\n",
    "            \"pnp\": cm.pnp + 0.2 * cm.npn - 0.5 * (cm.nnp + cm.ppp + cm.npp + cm.pnn) - 2 * cm.ppn,\n",
    "            # Mixed, false positive\n",
    "            \"npn\": cm.npn + 0.2 * cm.pnp - 0.5 * (cm.ppn + cm.ppp + cm.pnn + cm.npp) - 2 * cm.nnp,\n",
    "            \"nnp\": cm.nnp + 0.2 * cm.ppn - 0.5 * (cm.pnp + cm.ppp + cm.pnn + cm.npp) - 2 * cm.npn,\n",
    "        }\n",
    "\n",
    "    # Convert each score to a DataFrame with coordinates and get top 10\n",
    "    results = {}\n",
    "    for category, score in scores.items():\n",
    "        dims = list(score.dims)\n",
    "        df = (\n",
    "            score.to_dataframe(name=\"score\").reset_index()[dims + [\"score\"]].reset_index(drop=True)\n",
    "        )\n",
    "        df = df[df[\"score\"] > 0].sort_values(\"score\", ascending=False).head(10)\n",
    "        if not df.empty:\n",
    "            df.attrs[\"long_name\"] = cm[category].attrs.get(\"long_name\", category)\n",
    "            results[category] = df\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "if False:\n",
    "    cex_2x2 = find_confusion_examples(\n",
    "        obs.extreme, gem.extreme, groupby=[\"location\", \"forecast_date\"]\n",
    "    )\n",
    "    print(cex_2x2)\n",
    "\n",
    "    cex_4x2 = find_confusion_examples(\n",
    "        obs.extreme, gem.extreme, ref.extreme, groupby=[\"location\", \"forecast_date\"]\n",
    "    )\n",
    "    print(cex_4x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viz_confusion_examples(\n",
    "    observations: xr.Dataset,\n",
    "    forecast: xr.Dataset,\n",
    "    reference: xr.Dataset | None = None,\n",
    "    groupby: str | list[str] | None = None,\n",
    "    type: str | None = None,\n",
    "    count: int | None = 1,\n",
    "):\n",
    "    \"\"\"Visualize most compelling examples for each confusion matrix category.\n",
    "\n",
    "    Args:\n",
    "        observations: Binary array of observed events\n",
    "        forecast: Binary array of forecast events\n",
    "        reference: Optional binary array of reference forecast events.\n",
    "                  If provided, shows examples for 4x2 confusion matrix.\n",
    "        groupby: Optional dimension(s) to group by\n",
    "        type: Optional confusion matrix category to show (e.g. 'np', 'ppp').\n",
    "              If None, show all categories.\n",
    "        count: Number of examples to show per category. If None, show all examples.\n",
    "    \"\"\"\n",
    "    examples = find_confusion_examples(\n",
    "        observations.extreme,\n",
    "        forecast.extreme,\n",
    "        reference=None if reference is None else reference.extreme,\n",
    "        groupby=groupby,\n",
    "    )\n",
    "\n",
    "    # Filter to specific type if requested\n",
    "    if type is not None:\n",
    "        if type not in examples:\n",
    "            print(f\"No examples found for type {type}\")\n",
    "            return\n",
    "        examples = {type: examples[type]}\n",
    "\n",
    "    for category, df in examples.items():\n",
    "        rows = df.head(count) if count is not None else df\n",
    "        for _, row in rows.iterrows():\n",
    "            coords = {dim: row[dim] for dim in row.index if dim != \"score\"}\n",
    "            fig, ax = plot_extremes_timeseries(\n",
    "                observations.sel(**coords),\n",
    "                forecast.sel(**coords),\n",
    "                reference.sel(**coords) if reference is not None else None,\n",
    "            )\n",
    "            old_title = ax.get_title()\n",
    "            long_name = df.attrs.get(\"long_name\", category)\n",
    "            ax.set_title(f\"{long_name}\\n{old_title}\")\n",
    "\n",
    "\n",
    "if False:\n",
    "    viz_confusion_examples(\n",
    "        obsd, gemd, reference=refd, groupby=[\"forecast_date\", \"location\"], type=\"nnp\", count=5\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viz_search_threshold(\n",
    "    observed: xr.DataArray,\n",
    "    forecast: xr.DataArray,\n",
    "    reference: xr.DataArray,\n",
    "    objective: str = \"payoff\",\n",
    "    beta: float = 1.0,\n",
    "    payoff: dict = sk.event.PAYOFF,\n",
    ") -> tuple[plt.Figure, list]:\n",
    "    \"\"\"Visualize decisionmaking metrics as a function of threshold.\n",
    "\n",
    "    Args:\n",
    "        observed: Boolean DataArray indicating observed extreme events\n",
    "        forecast: Continuous DataArray with forecast values\n",
    "        reference: Continuous DataArray with reference values\n",
    "        objective: Metric to optimize (\"f_score\", \"payoff\", \"precision\", \"recall\")\n",
    "        beta: Weight of recall in F-score calculation (default: 1.0)\n",
    "        payoff: Payoff matrix for cost-loss calculation\n",
    "\n",
    "    Returns:\n",
    "        matplotlib Figure and list of axes\n",
    "    \"\"\"\n",
    "    # Get optimization results\n",
    "    fcst = sk.event.search_threshold(\n",
    "        observed, forecast, beta=beta, payoff=payoff, objective=objective\n",
    "    )\n",
    "    ref = sk.event.search_threshold(\n",
    "        observed, reference, beta=beta, payoff=payoff, objective=objective\n",
    "    )\n",
    "\n",
    "    # Determine which variables to plot (those that have thresholds dimension)\n",
    "    plot_vars = [\n",
    "        var\n",
    "        for var in fcst.data_vars\n",
    "        if \"thresholds\" in fcst[var].dims and var != \"threshold\" and var != \"index\"\n",
    "    ]\n",
    "\n",
    "    # Move objective to the front of the list if it exists\n",
    "    if objective in plot_vars:\n",
    "        plot_vars.remove(objective)\n",
    "        plot_vars.insert(0, objective)\n",
    "\n",
    "    # Create figure with subplots (one per variable)\n",
    "    fig, axes = plt.subplots(len(plot_vars), 1, figsize=(8, 2 * len(plot_vars)), sharex=True)\n",
    "    if len(plot_vars) == 1:\n",
    "        axes = [axes]  # Ensure axes is always a list\n",
    "\n",
    "    # Create dictionary mapping variable names to axes\n",
    "    ax_dict = dict(zip(plot_vars, axes))\n",
    "\n",
    "    # Helper function to process and plot model results\n",
    "    def process_and_plot_model(results, ax_dict):\n",
    "        name = results.attrs.get(\"model_name\", \"Forecast\")\n",
    "        color = results.attrs.get(\"color\", \"grey\")\n",
    "\n",
    "        # Get the optimal threshold value and index\n",
    "        optimal_idx = results.index.item()\n",
    "        optimal_threshold = results.threshold.item()\n",
    "\n",
    "        # Get thresholds from coordinates\n",
    "        thresholds = results.thresholds.values\n",
    "\n",
    "        # Plot each variable\n",
    "        for var_name, ax in ax_dict.items():\n",
    "            values = results[var_name].values\n",
    "            ax.plot(\n",
    "                thresholds,\n",
    "                values,\n",
    "                \"-\",\n",
    "                color=color,\n",
    "                linewidth=2,\n",
    "                label=f\"{name}\"\n",
    "                + (f\" (Best = {optimal_threshold:.4f})\" if var_name == objective else \"\"),\n",
    "            )\n",
    "\n",
    "            # Add a star at the optimal point determined by the objective\n",
    "            # (same position for all metrics)\n",
    "            opt_val = values[optimal_idx]\n",
    "            ax.plot(optimal_threshold, opt_val, \"*\", color=color, markersize=10)\n",
    "\n",
    "            # Vertical line at optimal threshold\n",
    "            ax.axvline(x=optimal_threshold, color=color, linestyle=\"--\", alpha=0.4)\n",
    "\n",
    "    # Plot the forecast and reference models\n",
    "    process_and_plot_model(fcst, ax_dict)\n",
    "    process_and_plot_model(ref, ax_dict)\n",
    "\n",
    "    # Set labels and formatting for each axis\n",
    "    for var_name, ax in ax_dict.items():\n",
    "        # Use attributes for labels where available\n",
    "        long_name = fcst[var_name].attrs.get(\"long_name\", var_name)\n",
    "        ax.set_ylabel(long_name)\n",
    "        ax.legend()\n",
    "        ax.set_ylim(bottom=0)  # Set minimum y-value to zero\n",
    "\n",
    "    # Set xlabel only on bottom axis\n",
    "    axes[-1].set_xlabel(\"Threshold\")\n",
    "\n",
    "    # If lead time information is available, use it in the title\n",
    "    if \"lead\" in fcst.coords:\n",
    "        lead_val = fcst.lead.values\n",
    "        axes[0].set_title(f\"lead {lead_val}\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig, axes  # viz_confusion_examples(obsd, gemd, refd)\n",
    "\n",
    "\n",
    "if False:\n",
    "    dat = np.timedelta64(13, \"D\")\n",
    "    # loc = row[\"location\"]\n",
    "\n",
    "    obss = obs.sel(lead=dat)\n",
    "    refs = ref.sel(lead=dat)\n",
    "    gems = gem.sel(lead=dat)\n",
    "\n",
    "    fig, ax = viz_search_threshold(\n",
    "        obss.extreme,\n",
    "        gems.extreme_pct,\n",
    "        refs.extreme_pct,\n",
    "        objective=objective,\n",
    "        payoff=payoff,\n",
    "    )\n",
    "    ax[0].set_title(f\"lead {dat}\")\n",
    "    ref_search = sk.event.search_threshold(\n",
    "        obss.extreme,\n",
    "        refs.extreme_pct,\n",
    "        objective=objective,\n",
    "        payoff=payoff,\n",
    "    )\n",
    "    print(ref_search.payoff.isel(thresholds=ref_search.index.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_f_score(\n",
    "    observed: xr.DataArray,\n",
    "    forecast: xr.DataArray,\n",
    "    reference: xr.DataArray,\n",
    "    groupby: str,\n",
    "    payoff: dict = sk.event.PAYOFF,\n",
    "    beta: float = 1.0,\n",
    "    figsize: tuple = (10, 10),\n",
    ") -> tuple[plt.Figure, list]:\n",
    "    \"\"\"Compare F-score and related metrics between two forecasts along a dimension.\n",
    "\n",
    "    Args:\n",
    "        observed: Boolean DataArray indicating observed extreme events\n",
    "        forecast: Boolean DataArray indicating forecasted extreme events\n",
    "        reference: Boolean DataArray indicating reference forecasted extreme events\n",
    "        groupby: Dimension to group by for comparison\n",
    "        payoff: Dictionary specifying the value for each confusion matrix element\n",
    "        beta: Weight of recall in F-score calculation (default: 1.0 for F1 score)\n",
    "        figsize: Figure size (width, height)\n",
    "\n",
    "    Returns:\n",
    "        Figure and axes objects showing the comparison\n",
    "    \"\"\"\n",
    "    # Calculate metrics for both forecast and reference\n",
    "    fcst_metrics = sk.event.calc_f_score(\n",
    "        observed, forecast, groupby=groupby, payoff=payoff, beta=beta\n",
    "    )\n",
    "    ref_metrics = sk.event.calc_f_score(\n",
    "        observed, reference, groupby=groupby, payoff=payoff, beta=beta\n",
    "    )\n",
    "    dif_metrics = fcst_metrics - ref_metrics\n",
    "\n",
    "    # Create unified dataset with model dimension\n",
    "    fcst_name = getattr(forecast, \"model_name\", \"Forecast\")\n",
    "    ref_name = getattr(reference, \"model_name\", \"Reference\")\n",
    "    models = [fcst_name, ref_name]\n",
    "\n",
    "    # Get model colors from attributes\n",
    "    fcst_color = forecast.attrs.get(\"color\", \"dodgerblue\")\n",
    "    ref_color = reference.attrs.get(\"color\", \"#ff7f0e\")\n",
    "    colors = {fcst_name: fcst_color, ref_name: ref_color}\n",
    "\n",
    "    # Staple the two metrics arrays together\n",
    "    metrics = []\n",
    "    for model, data in zip(models, [fcst_metrics, ref_metrics]):\n",
    "        # Add model dimension to each dataset\n",
    "        model_ds = data.expand_dims(dim={\"model\": [model]})\n",
    "        # expand_dims drops attrs: preserve them.\n",
    "        for var in model_ds.data_vars:\n",
    "            model_ds[var].attrs = data[var].attrs\n",
    "        metrics.append(model_ds)\n",
    "    combined_metrics = xr.concat(metrics, dim=\"model\")\n",
    "\n",
    "    if isinstance(combined_metrics[groupby].values[0], str):  # only sort if categorical\n",
    "        objective = \"f_score\" if payoff is None else \"payoff\"\n",
    "        sort_order = dif_metrics[objective].values.argsort()[::-1]\n",
    "        combined_metrics = combined_metrics.isel({groupby: sort_order})\n",
    "        dif_metrics = dif_metrics.isel({groupby: sort_order})\n",
    "\n",
    "    # Create figure with subplots\n",
    "    plot_vars = list(combined_metrics.data_vars)\n",
    "    num_plots = len(plot_vars)\n",
    "    fig_height = max(5, 2 * num_plots)\n",
    "    fig, axes = plt.subplots(num_plots, 1, figsize=(figsize[0], fig_height))\n",
    "\n",
    "    # Plot each metric using xarray's built-in plotting\n",
    "    for i, var in enumerate(plot_vars):\n",
    "        plot = combined_metrics[var].plot(\n",
    "            ax=axes[i],\n",
    "            x=groupby,\n",
    "            hue=\"model\",\n",
    "            marker=\"o\",\n",
    "            markersize=4,\n",
    "        )\n",
    "        for line, model in zip(axes[i].lines, colors.keys()):\n",
    "            if model in colors:\n",
    "                line.set_color(colors[model])\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    dif_metrics = dif_metrics.assign_coords(model=[\"DIFF\"])\n",
    "    combined_metrics = xr.concat([combined_metrics, dif_metrics], dim=\"model\")\n",
    "\n",
    "    return combined_metrics\n",
    "\n",
    "\n",
    "if False:\n",
    "    cmp = compare_f_score(obs.extreme, gem.extreme, ref.extreme, groupby=\"location\", payoff=payoff)\n",
    "# print(cmp.payoff.sel(model=\"DIFF\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decompose Scores by Location and Lead\n",
    "\n",
    "**Precision**: \"When we predict an event will happen, how often are we right?\" High precision means few false alarms. `pp/(pp + np)`: correct event predictions divided by total event predictions.\n",
    "\n",
    "**Recall**: \"Of all the events that actually happened, how many did we catch?\"\n",
    "High recall means we detect most events. `pp/(pp + pn)`: caught events divided by total actual events.\n",
    "\n",
    "**False Positive Rate**: \"Of all the non-events, what fraction did the forecast falsely flag as events?\"  In other words, when nothing extreme is happening, how often does the forecast cry wolf?  `np/(np + nn)`: false alarms divided by total non-events\n",
    "\n",
    "\n",
    "- `pp` = forecast predicted it and it happened\n",
    "- `np` = forecast predicted it but it didn't happen (false alarm)\n",
    "- `pn` = it happened but the forecast missed it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_f_score(obs.extreme, gem.extreme, ref.extreme, \"lead_days\", payoff, beta)\n",
    "compare_f_score(obs.extreme, gem.extreme, ref.extreme, \"location\", payoff, beta);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When Forecasts Differ: Joint Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A paired confusion matrix extends the standard format to compare two prediction systems against reality simultaneously. Instead of just \"event\" or \"no event\" for a single system, it shows all possible combinations: both systems correct, both wrong, and cases where one system gets it right while the other fails. This format is particularly powerful for understanding not just how often each system succeeds or fails, but whether they tend to make the same mistakes or complement each other's strengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(sk.event.style_confusion_matrix(obs.extreme, gem.extreme, ref.extreme, beta, payoff))\n",
    "\n",
    "# display(sk.event.style_confusion_matrix(obs.extreme, gem.extreme, ref.extreme, beta=beta, payoff=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payoffs = sk.event.calc_f_score(obs.extreme, gem.extreme, ref.extreme, \"lead\", beta, payoff)[\n",
    "    \"payoff\"\n",
    "]\n",
    "fig = payoffs.plot(x=\"lead_days\", hue=\"forecast\")\n",
    "print(fig);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payoffs = sk.event.calc_f_score(obs.extreme, gem.extreme, ref.extreme, None, beta, payoff)[\n",
    "    \"payoff\"\n",
    "]\n",
    "payoffs = payoffs.sel(forecast=[\"reference\", \"forecast\", \"paired\"])\n",
    "\n",
    "bars = plt.bar(\n",
    "    [ref.extreme.attrs[\"model_name\"], gem.extreme.attrs[\"model_name\"], \"Paired\"], payoffs.values\n",
    ")\n",
    "\n",
    "bars[0].set_color(ref.extreme.attrs[\"color\"])\n",
    "bars[1].set_color(gem.extreme.attrs[\"color\"])\n",
    "bars[2].set_color(\"#9467bd\")\n",
    "plt.axhline(y=payoffs.sel(forecast=\"reference\"), color=\"lightgrey\", linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "for idx in [1, 2]:\n",
    "    plt.text(\n",
    "        bars[idx].get_x() + bars[idx].get_width() / 2,\n",
    "        (bars[idx].get_height() + bars[0].get_height()) / 2,\n",
    "        f\"+{(bars[idx].get_height() / bars[0].get_height() - 1) * 100:.0f}%\",\n",
    "        ha=\"center\",\n",
    "        va=\"center\",\n",
    "        fontweight=\"bold\",\n",
    "        color=\"white\",\n",
    "    )\n",
    "plt.ylabel(f\"{payoffs.attrs['long_name']} [{payoffs.attrs['units']}]\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Threshold Optimization\n",
    "\n",
    "The choosing a threshold is a balance between precision and recall.  View the tradeoff here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's find a compelling example for comparing strategy.\n",
    "gem_f = sk.event.calc_f_score(obs.extreme, gem.extreme, groupby=groupby, payoff=payoff, beta=beta)\n",
    "ref_f = sk.event.calc_f_score(obs.extreme, ref.extreme, groupby=groupby, payoff=payoff, beta=beta)\n",
    "obs_counts = obs.extreme.sum(dim=[\"forecast_date\", \"location\"])\n",
    "\n",
    "# Create DataFrame with f-scores and add observation counts\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"gem\": gem_f.f_score.to_dataframe()[\"f_score\"],\n",
    "        \"ref\": ref_f.f_score.to_dataframe()[\"f_score\"],\n",
    "        \"obs_count\": obs_counts.to_dataframe()[\"extreme\"],\n",
    "    }\n",
    ").reset_index()\n",
    "df[\"dif\"] = df[\"gem\"] - df[\"ref\"]\n",
    "\n",
    "result = (\n",
    "    df[(df[\"gem\"] > 0) & (df[\"ref\"] > 0) & (df[\"obs_count\"] > 2)]\n",
    "    .sort_values(\"dif\", ascending=False)\n",
    "    .head()\n",
    ")\n",
    "idx = 1\n",
    "row = result.iloc[idx]\n",
    "dat = row[\"lead\"]\n",
    "# loc = row[\"location\"]\n",
    "# dat = np.timedelta64(13,\"D\")\n",
    "\n",
    "\n",
    "obss = obs.sel(lead=dat)\n",
    "refs = ref.sel(lead=dat)\n",
    "gems = gem.sel(lead=dat)\n",
    "\n",
    "fig, ax = viz_search_threshold(\n",
    "    obss.extreme,\n",
    "    gems.extreme_pct,\n",
    "    refs.extreme_pct,\n",
    "    objective=objective,\n",
    "    payoff=payoff,\n",
    ")\n",
    "ax[0].set_title(f\"lead {dat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix - Statistical Skill / CRPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_crps(obs[field], gem[field_ens], ref[field_ens], \"lead\")\n",
    "compare_crps(obs[field], gem[field_ens], ref[field_ens], \"location\")\n",
    "crps_date = compare_crps(obs[field], gem[field_ens], ref[field_ens], \"forecast_date\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix - Classifier Diagnostics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnostic - forecast calibration\n",
    "if False:\n",
    "    pct = xr.Dataset(\n",
    "        {\n",
    "            \"obs\": sk.event.classify_event(\n",
    "                obs[\"anom_stdv\"], ext_std, width=0, dim=[\"forecast_date\", \"location\"]\n",
    "            ),\n",
    "            \"gem\": sk.event.classify_event(\n",
    "                gem[\"anom_ens_stdv\"],\n",
    "                ext_std,\n",
    "                width=0,\n",
    "                dim=[\"forecast_date\", \"location\", \"ensemble\"],\n",
    "            ),\n",
    "            \"ref\": sk.event.classify_event(\n",
    "                ref[\"anom_ens_stdv\"],\n",
    "                ext_std,\n",
    "                width=0,\n",
    "                dim=[\"forecast_date\", \"location\", \"ensemble\"],\n",
    "            ),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 4))\n",
    "    pct.obs.plot.line(x=\"lead_days\", label=pct.obs.attrs[\"model_name\"], color=\"black\")\n",
    "    pct.gem.plot.line(\n",
    "        x=\"lead_days\", label=pct.gem.attrs[\"model_name\"], color=pct.gem.attrs[\"color\"]\n",
    "    )\n",
    "    pct.ref.plot.line(\n",
    "        x=\"lead_days\", label=pct.ref.attrs[\"model_name\"], color=pct.ref.attrs[\"color\"]\n",
    "    )\n",
    "    ax.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_extreme_scatter(dataset, obs, ax, ext_std):\n",
    "    \"\"\"Plot extreme probability vs mean standardized anomaly for a dataset.\"\"\"\n",
    "    dataset[\"anom_mean\"] = dataset.anom_ens_stdv.mean(dim=\"ensemble\", keep_attrs=True)\n",
    "    obs[\"extreme_pct\"] = sk.event.classify_event(obs[\"anom_stdv\"], ext_std)\n",
    "    obs.plot.scatter(\n",
    "        x=\"anom_stdv\", y=\"extreme_pct\", alpha=0.05, s=5, color=\"black\", rasterized=True, ax=ax\n",
    "    )\n",
    "    dataset.plot.scatter(\n",
    "        x=\"anom_mean\",\n",
    "        y=\"extreme_pct\",\n",
    "        alpha=0.05,\n",
    "        s=5,\n",
    "        color=dataset[\"anom_ens_stdv\"].attrs[\"color\"],\n",
    "        rasterized=True,\n",
    "        ax=ax,\n",
    "    )\n",
    "    ax.axvline(x=ext_std, color=\"gray\", linestyle=\"--\", label=f\"Target threshold: {ext_std}\")\n",
    "    ax.set_title(dataset.extreme_pct.attrs.get(\"model_name\", \"Model\"))\n",
    "    del dataset[\"anom_mean\"]\n",
    "\n",
    "\n",
    "if True:\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 5), sharey=True)\n",
    "    plot_extreme_scatter(gem, obs, ax1, ext_std)\n",
    "    plot_extreme_scatter(ref, obs, ax2, ext_std)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_classifier_performance(forecast, observed, ax, color):\n",
    "    \"\"\"Plot classifier performance: extreme_pct (x) vs observed standardized anomaly (y).\"\"\"\n",
    "    # Temporarily add the observed standardized anomaly to the forecast dataset\n",
    "    forecast[\"obs_anom\"] = observed.anom_stdv\n",
    "    forecast[\"obs_anom\"].attrs[\"long_name\"] = \"Observed \" + forecast[\"obs_anom\"].attrs[\"long_name\"]\n",
    "\n",
    "    # Create the scatter plot\n",
    "    forecast.plot.scatter(\n",
    "        x=\"extreme_pct\",\n",
    "        y=\"obs_anom\",\n",
    "        alpha=np.clip(0.3 - (0.25 * (forecast.extreme_pct.size - 1000) / 9000), 0.05, 0.3),\n",
    "        s=5,\n",
    "        color=color,\n",
    "        rasterized=True,\n",
    "        ax=ax,\n",
    "    )\n",
    "    ax.axhline(y=ext_std, color=\"gray\", linestyle=\":\", label=f\"Extreme threshold: {ext_std}\")\n",
    "    # ax.set_ylim(bottom=0)\n",
    "\n",
    "    # Flatten arrays for metric calculation\n",
    "    y_true_flat = observed.extreme.values.flatten()\n",
    "    y_pred_flat = forecast.extreme_pct.values.flatten()\n",
    "    mask = ~np.isnan(y_true_flat) & ~np.isnan(y_pred_flat)\n",
    "    y_true_flat = y_true_flat[mask]\n",
    "    y_pred_flat = y_pred_flat[mask]\n",
    "\n",
    "    # Calculate AUC-ROC (Area Under the Receiver Operating Characteristic curve)\n",
    "    auc_roc = roc_auc_score(y_true_flat, y_pred_flat)\n",
    "\n",
    "    # Calculate AUC-PR (Area Under the Precision-Recall curve)\n",
    "    auc_pr = average_precision_score(y_true_flat, y_pred_flat)\n",
    "\n",
    "    # Calculate rank correlation (Spearman)\n",
    "    correlation, _ = spearmanr(y_true_flat, y_pred_flat)\n",
    "\n",
    "    model_name = forecast.extreme_pct.attrs.get(\"model_name\", \"Model\")\n",
    "    ax.set_title(\n",
    "        f\"{model_name}\\nAUC-ROC: {auc_roc:.3f}, AUC-PR: {auc_pr:.3f}\\nRank Correlation: {correlation:.3f}\"\n",
    "    )\n",
    "\n",
    "    del forecast[\"obs_anom\"]\n",
    "\n",
    "\n",
    "if True:\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 5), sharey=True)\n",
    "    plot_classifier_performance(gem, obs, ax1, \"dodgerblue\")\n",
    "    plot_classifier_performance(ref, obs, ax2, \"#FF8C1E\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if False:\n",
    "    location = \"DFW\"\n",
    "    lead = np.timedelta64(15, \"D\")\n",
    "    gem_subset = gem.sel(location=location, lead=lead)\n",
    "    ref_subset = ref.sel(location=location, lead=lead)\n",
    "    obs_subset = obs.sel(location=location, lead=lead)\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6), sharey=True)\n",
    "    plot_classifier_performance(gem_subset, obs_subset, ax1, \"dodgerblue\")\n",
    "    plot_classifier_performance(ref_subset, obs_subset, ax2, \"#FF8C1E\")\n",
    "\n",
    "    # Add location and lead time to the overall figure title\n",
    "    fig.suptitle(f\"Classifier Performance for {location} at {lead}-day Lead Time\", fontsize=16)\n",
    "\n",
    "    # sk.event._viz_search_f_score(obs_subset.extreme, gem_subset.extreme_pct, ref_subset.extreme_pct)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix - Plot Extreme Thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_extreme_thresholds(model, ax, obs):\n",
    "    \"\"\"Plot extreme thresholds for a model on a given axis.\n",
    "\n",
    "    Args:\n",
    "        model: The model data containing extreme thresholds\n",
    "        ax: The matplotlib axis to plot on\n",
    "        highlight_color: Color for the average threshold line\n",
    "        obs: Observations data to calculate climatology\n",
    "        ext_std: Standard deviation threshold for extreme classification\n",
    "    \"\"\"\n",
    "    color = model.extreme_threshold.attrs[\"color\"]\n",
    "    ext_std = obs.extreme.attrs[\"target\"]\n",
    "\n",
    "    # Plot individual location thresholds\n",
    "    model.extreme_threshold.plot.line(\n",
    "        ax=ax,\n",
    "        x=\"lead_days\",\n",
    "        hue=\"location\",\n",
    "        add_legend=False,\n",
    "        color=color,\n",
    "        alpha=0.8,\n",
    "        linewidth=1,\n",
    "    )\n",
    "    # Plot climatology reference\n",
    "    # clim = sk.event.classify_event(obs[\"anom_stdv\"], ext_std, dim=[\"forecast_date\", \"location\"])\n",
    "    # clim.plot.line(ax=ax, x=\"lead_days\", color=\"grey\", linestyle=\"dashed\")\n",
    "\n",
    "    ax.set_ylabel(\"Extreme Threshold\")\n",
    "    ax.grid(True, alpha=0.2)\n",
    "\n",
    "    # Set title using model name, extracting post-underscore part and uppercasing\n",
    "    ax.set_title(f\"{model.extreme.attrs['model_name']} Thresholds\")\n",
    "\n",
    "\n",
    "if True:\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4), sharey=True)\n",
    "    plot_extreme_thresholds(gem, ax1, obs)\n",
    "    plot_extreme_thresholds(ref, ax2, obs)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix: Example Timeseries - False Positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cex = viz_confusion_examples(\n",
    "    obs, gem, ref, groupby=[\"location\", \"forecast_date\"], type=\"nnp\", count=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix - Unique Alpha\n",
    "\n",
    "Highlight instances where GEM finds extremes that GEFS doesn't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cex = viz_confusion_examples(\n",
    "    obs, gem, ref, groupby=[\"location\", \"forecast_date\"], type=\"ppn\", count=10\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "salientsdk",
   "language": "python",
   "name": "salientsdk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
