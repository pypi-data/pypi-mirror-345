{
  "python": "import re\nfrom bs4 import BeautifulSoup\n\ndef parse_element(html: str) -> dict[str, str|int|list|dict]:\n    def parse_number(text: str) -> int | None:\n        if not text:\n            return None\n        text = text.strip().upper().replace(',', '')\n        match = re.match(r\"^(\\d+\\.?\\d*)([KM])?$\", text)\n        if not match:\n            try:\n                return int(text)\n            except Exception:\n                return None\n        number, magnitude = match.groups()\n        try:\n            number = float(number)\n        except Exception:\n            return None\n        if magnitude == 'K':\n            number *= 1_000\n        elif magnitude == 'M':\n            number *= 1_000_000\n        return int(number)\n\n    soup = BeautifulSoup(html, 'html.parser')\n    result = {}\n\n    # ID extraction from data-id attribute first\n    id_attr = None\n    # Check for 'data-id' attribute or id digit in the root element\n    root = soup.find(True)\n    if root and root.has_attr('data-id'):\n        id_attr = root['data-id']\n    elif root and root.has_attr('id') and root['id'].isdigit():\n        id_attr = root['id']\n\n    # Identify primary URL: try to find an <a> that links to the main item\n    # Heuristic: link inside a title container or first meaningful href\n    primary_url = None\n    title_link = None\n\n    for selector in ['.title a', 'a.titleline', 'h1 a', 'h2 a', 'h3 a']:\n        link = soup.select_one(selector)\n        if link and link.has_attr('href') and link['href'].strip():\n            primary_url = link['href'].strip()\n            title_link = link\n            break\n    if not primary_url:\n        first_a = soup.find('a', href=True)\n        if first_a:\n            primary_url = first_a['href'].strip()\n\n    # Extract datetime and timestamp from <time> tag inside primary link or anywhere\n    datetime_val = None\n    timestamp_val = None\n    time_tag = None\n    if title_link:\n        time_tag = title_link.find('time', datetime=True)\n    if not time_tag:\n        time_tag = soup.find('time', datetime=True)\n    if time_tag:\n        datetime_val = time_tag.get('datetime')\n        if time_tag.string and time_tag.string.strip():\n            timestamp_val = time_tag.string.strip()\n\n    if primary_url:\n        result['primary_url'] = primary_url\n\n    # Extract stable ID from URL if id_attr not set\n    if id_attr:\n        result['id'] = id_attr\n    elif primary_url:\n        try:\n            parts = primary_url.strip('/').split('/')\n            if parts:\n                last_part = parts[-1]\n                if last_part:\n                    last_part = last_part.split('?')[0]\n                    if last_part:\n                        result['id'] = last_part\n        except Exception:\n            pass\n\n    if datetime_val:\n        result['datetime'] = datetime_val\n    if timestamp_val:\n        result['timestamp'] = timestamp_val\n\n    # Title extraction - from <h1>, <h2>, <h3>, or the title link text\n    title = None\n    for tag_name in ['h1', 'h2', 'h3']:\n        tag = soup.find(tag_name)\n        if tag and tag.get_text(strip=True):\n            title = tag.get_text(strip=True)\n            break\n    if not title and title_link:\n        title = title_link.get_text(strip=True)\n    if not title:\n        aria_label = soup.find(attrs={'aria-label': True})\n        if aria_label:\n            title = aria_label['aria-label'].strip()\n    if title:\n        result['title'] = title\n\n    # Author extraction\n    author = None\n    author_url = None\n    author_tag = soup.find(attrs={'rel': 'author'})\n    if not author_tag:\n        author_tag = soup.find(class_=re.compile('author', re.I))\n    if author_tag:\n        author = author_tag.get_text(strip=True)\n        if author_tag.has_attr('href'):\n            author_url = author_tag['href']\n    if not author or not author_url:\n        avatar_img = soup.find('img', alt=re.compile('avatar', re.I))\n        if avatar_img:\n            parent_link = avatar_img.find_parent('a', href=True)\n            if parent_link:\n                if not author_url:\n                    author_url = parent_link['href']\n                if not author:\n                    alt = avatar_img.get('alt')\n                    title_attr = avatar_img.get('title')\n                    author = alt if alt else title_attr\n    if author:\n        result['author'] = author\n    if author_url:\n        result['author_url'] = author_url\n\n    # Description extraction: Find largest meaningful text excluding title and metadata\n    description = None\n    # Combine text from all <p> tags that are not too short\n    paragraphs = soup.find_all('p')\n    body_texts = [p.get_text(separator=' ', strip=True) for p in paragraphs if len(p.get_text(strip=True)) >= 25]\n    if body_texts:\n        description = '  '.join(body_texts)\n    else:\n        # fallback: largest div\n        divs = soup.find_all('div')\n        max_len = 0\n        big_div = None\n        for d in divs:\n            text = d.get_text(separator=' ', strip=True)\n            if text and len(text) > max_len and len(text) >= 25:\n                max_len = len(text)\n                big_div = d\n        if big_div:\n            description = big_div.get_text(separator=' ', strip=True)\n    if description:\n        result['description'] = description\n\n    # Images extraction excluding data URLs and author avatar\n    imgs = []\n    seen_srcs = set()\n    for img in soup.find_all('img'):\n        src = img.get('src')\n        if not src or src.startswith('data:'):\n            continue\n        alt = img.get('alt')\n        if alt and 'avatar' in alt.lower() and (author_url or True):\n            # exclude avatar images\n            continue\n        title_img = img.get('title')\n        width = img.get('width')\n        height = img.get('height')\n        img_dict = {'src': src}\n        if alt:\n            img_dict['alt'] = alt\n        if title_img:\n            img_dict['title'] = title_img\n        if width:\n            try:\n                img_dict['width'] = int(width)\n            except Exception:\n                img_dict['width'] = width\n        if height:\n            try:\n                img_dict['height'] = int(height)\n            except Exception:\n                img_dict['height'] = height\n        for attr, val in img.attrs.items():\n            if attr.startswith('data-'):\n                img_dict[attr] = val\n        if src not in seen_srcs:\n            imgs.append(img_dict)\n            seen_srcs.add(src)\n    if imgs:\n        result['images'] = imgs\n\n    # Metric extraction\n    metrics_map = {\n        'reply_count': ['reply', 'replies', 'comment', 'comments'],\n        'repost_count': ['repost', 'retweet', 'retweets'],\n        'like_count': ['like', 'likes'],\n        'bookmark_count': ['bookmark', 'bookmarks'],\n        'view_count': ['view', 'views']\n    }\n    counts_found = {}\n    text_candidates = []\n    for tag in soup.find_all(True):\n        aria_label = tag.get('aria-label')\n        if aria_label:\n            text_candidates.append(aria_label.strip())\n        if tag.string and tag.string.strip():\n            text_candidates.append(tag.string.strip())\n    for text in text_candidates:\n        text_low = text.lower()\n        for key, keywords in metrics_map.items():\n            if any(k in text_low for k in keywords):\n                num_match = re.search(r'([\\d.,]+\\s*[KM]?)', text)\n                if num_match:\n                    num = parse_number(num_match.group(1))\n                    if num is not None:\n                        if key not in counts_found or counts_found[key] < num:\n                            counts_found[key] = num\n    result.update(counts_found)\n\n    # Rank\n    rank = None\n    if root and root.has_attr('data-rank'):\n        try:\n            rank = int(root['data-rank'])\n        except Exception:\n            rank = None\n    if rank is not None:\n        result['rank'] = rank\n\n    # Other URLs\n    urls = set()\n    for a in soup.find_all('a', href=True):\n        href = a['href']\n        if href != primary_url:\n            urls.add(href)\n    if urls:\n        result['urls'] = sorted(urls)\n\n    return result",
  "selector": "tr.athing.submission",
  "selector_description": "All posts in the main feed"
}