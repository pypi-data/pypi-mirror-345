`opsmate ingest-prometheus-metrics-metadata` ingests metrics metadata into the knowledge base.

## OPTIONS

```
Usage: opsmate ingest-prometheus-metrics-metadata [OPTIONS]

  Ingest prometheus metrics metadata into the knowledge base. The ingestion is
  done via fetching the metrics metadata from the prometheus server, and then
  storing it into the knowledge base. The ingested metrics metadata will be
  used for providing context to the LLM when querying prometheus based metrics
  Note this only enqueues the tasks to ingest metrics. To execute the actual
  ingestion in the background, run `opsmate worker`. Please run: `opsmate
  worker -w 1 -q lancedb-batch-ingest`

Options:
  --prometheus-endpoint TEXT      Prometheus endpoint. If not provided it uses
                                  $PROMETHEUS_ENDPOINT environment variable,
                                  or defaults to http://localhost:9090
                                  [default: (dynamic)]
  --prometheus-user-id TEXT       Prometheus user id. If not provided it uses
                                  $PROMETHEUS_USER_ID environment variable, or
                                  defaults to empty string  [default:
                                  (dynamic)]
  --prometheus-api-key TEXT       Prometheus api key. If not provided it uses
                                  $PROMETHEUS_API_KEY environment variable, or
                                  defaults to empty string  [default:
                                  (dynamic)]
  --tools TEXT                    The tools to use for the session. Run
                                  `opsmate list-tools` to see the available
                                  tools. By default the tools from the context
                                  are used. (env: OPSMATE_TOOLS)  [default:
                                  ""]
  --loglevel TEXT                 Set loglevel (env: OPSMATE_LOGLEVEL)
                                  [default: INFO]
  --categorise BOOLEAN            Whether to categorise the embeddings (env:
                                  OPSMATE_CATEGORISE)  [default: True]
  --reranker-name TEXT            The name of the reranker model (env:
                                  OPSMATE_RERANKER_NAME)  [default: ""]
  --embedding-model-name TEXT     The name of the embedding model (env:
                                  OPSMATE_EMBEDDING_MODEL_NAME)  [default:
                                  text-embedding-ada-002]
  --embedding-registry-name TEXT  The name of the embedding registry (env:
                                  OPSMATE_EMBEDDING_REGISTRY_NAME)  [default:
                                  openai]
  --embeddings-db-path TEXT       The path to the lance db. When s3:// is used
                                  for AWS S3, az:// is used for Azure Blob
                                  Storage, and gs:// is used for Google Cloud
                                  Storage (env: OPSMATE_EMBEDDINGS_DB_PATH)
                                  [default: /root/.opsmate/embeddings]
  -c, --context TEXT              The context to use for the session. Run
                                  `opsmate list-contexts` to see the available
                                  contexts. (env: OPSMATE_CONTEXT)  [default:
                                  cli]
  --contexts-dir TEXT             Set contexts_dir (env: OPSMATE_CONTEXTS_DIR)
                                  [default: /root/.opsmate/contexts]
  --plugins-dir TEXT              Set plugins_dir (env: OPSMATE_PLUGINS_DIR)
                                  [default: /root/.opsmate/plugins]
  -m, --model TEXT                The model to use for the session. Run
                                  `opsmate list-models` to see the available
                                  models. (env: OPSMATE_MODEL)  [default:
                                  gpt-4o]
  --db-url TEXT                   Set db_url (env: OPSMATE_DB_URL)  [default:
                                  sqlite:////root/.opsmate/opsmate.db]
  --auto-migrate BOOLEAN          Automatically migrate the database to the
                                  latest version  [default: True]
  --help                          Show this message and exit.
```

## DESCRIPTION

The `ingest-prometheus-metrics-metadata` command enqueues tasks to ingest [prometheus-based](https://prometheus.io/) metrics metadata into the Opsmate knowledge base. The ingested metrics metadata will be used for improve the retrieval and precision of the Prometheus query results generated by the LLM.

Note this only enqueues the tasks to ingest metrics. To execute the actual ingestion in the background, run `opsmate worker`. Please run: `opsmate worker -w 1 -q lancedb-batch-ingest`

## EXAMPLES

### Ingest metrics metadata from Prometheus

The following command enqueues tasks to ingest metrics metadata from a Prometheus endpoint:

```bash
opsmate ingest-prometheus-metrics-metadata
```

By default, the command uses dynamic values for the Prometheus endpoint, user ID, and API key. You can specify these values explicitly as below.

```bash
opsmate ingest-prometheus-metrics-metadata \
  --prometheus-endpoint="https://prometheus-prod-01-eu-west-0.grafana.net/api/prom" \
  --prometheus-user-id="xxxxx" \
  --prometheus-api-key="glc_xxxx"
```

If the endpoints are not provided, the command will use the values from the environment variables:

```bash
export PROMETHEUS_ENDPOINT="https://prometheus-prod-01-eu-west-0.grafana.net/api/prom"
export PROMETHEUS_USER_ID="xxxxx"
export PROMETHEUS_API_KEY="glc_xxxx"
opsmate ingest-prometheus-metrics-metadata
```

### Running the worker to process the ingestion tasks

After enqueuing the tasks, you need to run a worker to process them:

```bash
opsmate worker -w 1 -q lancedb-batch-ingest
```

## SEE ALSO

- [opsmate worker](./worker.md)
- [opsmate serve](./serve.md)
- [opsmate chat](./chat.md)
