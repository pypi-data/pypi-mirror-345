Metadata-Version: 2.4
Name: justai
Version: 4.0.10
Summary: Makes working with LLMs like OpenAI GPT, Anthropic Claude, Google Gemini and Open source models super easy
Author-email: HP Harmsen <hp@harmsen.nl>
License-Expression: MIT
Project-URL: Homepage, https://github.com/hpharmsen/justai
Keywords: ChatGPT,GPT4o,GPT4,api,Claude,Anthropic,Lllama,Gemini,Grok,Perplexity,Sonar
Classifier: Programming Language :: Python
Classifier: Programming Language :: Python :: 3
Requires-Python: >=3.10
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: absl-py
Requires-Dist: anthropic
Requires-Dist: google-generativeai
Requires-Dist: httpx
Requires-Dist: justdays
Requires-Dist: lxml
Requires-Dist: openai
Requires-Dist: pillow
Requires-Dist: pydantic
Requires-Dist: python-dateutil
Requires-Dist: python-dotenv
Requires-Dist: rich
Requires-Dist: tiktoken
Requires-Dist: tomli; python_version < "3.11"
Provides-Extra: dev
Requires-Dist: black; extra == "dev"
Requires-Dist: pytest; extra == "dev"
Requires-Dist: build; extra == "dev"
Requires-Dist: twine; extra == "dev"
Requires-Dist: nox; extra == "dev"
Provides-Extra: llama
Requires-Dist: llama-cpp-python; extra == "llama"
Dynamic: license-file

# JustAI

Package to make working with Large Language models in Python super easy.
Supports OpenAI, Anthropic Claude, Google Gemini, X Grok, DeepSeek and open source .guff models.

Author: Hans-Peter Harmsen (hp@harmsen.nl) \
Current version: 4.0.10

Version 4.x is not compatible with the 3.x series.

## Installation
1. Install the package:
~~~~bash
python -m pip install justai
~~~~
2. Create an OpenAI acccount (for OpenAI models) [here](https://platform.openai.com/) or an Anthropic account [here](https://console.anthropic.com/) or a Google account
3. Create an OpenAI api key [here](https://platform.openai.com/account/api-keys) or an Anthropic api key [here](https://console.anthropic.com/settings/keys) or a Google api key [here](https://aistudio.google.com/app/apikey)
4. Create a .env file with the following content, depending on the model you intend to use:
```bash
OPENAI_API_KEY=your-openai-api-key
OPENAI_ORGANIZATION=your-openai-organization-id
ANTHROPIC_API_KEY=your-anthropic-api-key
GOOGLE_API_KEY=your-google-api-key
X_API_KEY=your-x-ai-api-key
DEEPSKEEK_API_KEY=your-deepseek-api-key
```
## Usage

```Python
from justai import Model

model = Model('gpt-4o-mini')
model.system = """You are a movie critic. I feed you with movie
                  titles and you give me a review in 50 words."""

message = model.chat("Forrest Gump")
print(message)
```
output
```
Forrest Gump is an American classic that tells the story of
a man with a kind heart and simple mind who experiences major
events in history. Tom Hanks gives an unforgettable performance, 
making us both laugh and cry. A heartwarming and nostalgic 
movie that still resonates with audiences today.
```
## Other models
Justai can use different types of models:

**OpenAI** models like GPT-4 and O3\
**Anthropic** models like the Claude-3 models\
**Google** models like the Gemini models\
**X AI** models like the Grok models\
**DeekSeek** models like Deepseek V-3 (deepseek-chat) and reasoning model Deepseek-R1 (deepseek-reasoning)\
**Open source** models like Llama2-7b or Mixtral-8x7b-instruct as long as they are in the GGUF format.

The provider is chosen depending on the model name. E.g. if a model name starts with gpt, OpenAI is chosen as the provider.
To use an open source model, just pass the full path to the .gguf file as the model name.


## Using the examples
Install dependencies:
```bash
python -m pip install -r requirements.txt
```


### Basic
```bash
python examples/basic.py
```
Shows basic use of Justai

### Returning json or other types
```bash
python examples/return_types.py
```
You can specify a specific return type (like a list of dicts) for the completion. 
This is useful when you want to extract structured data from the completion.

To return json, just pass return_json=True to model.chat() and tell the model in the 
prompt how you want your json to be structured.

To define a specific return type you can use the return_type parameter.
Currently this works with the Google models (pass a Python type definition, returns Json)
and with OpenAI (pass a Pydatic type definition, returns a Pydantic model).\
See the example code for more details.

### Images
```bash
python examples/vision.py
```
Pass images to the model. An image can either be:
* An url to an image
* The raw image data
* A PIL image

### Asynchronous use
```bash
python examples/async.py
```
Shows how to use Justai asynchronously.

### Prompt caching
```bash
python examples/prompt_caching.py
```
Shows how to use Prompt caching in Anthropic models.
