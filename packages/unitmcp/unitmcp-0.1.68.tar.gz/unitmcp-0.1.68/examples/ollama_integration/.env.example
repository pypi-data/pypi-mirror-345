# Server configuration
SERVER_HOST=0.0.0.0
SERVER_PORT=8080
LOG_LEVEL=INFO

# Ollama configuration
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama2
TEMPERATURE=0.7
MAX_TOKENS=1024
TOP_P=0.9
TOP_K=40
REPEAT_PENALTY=1.1

# Hardware integration
SIMULATION=1
ENABLE_VOICE_INPUT=false
ENABLE_VOICE_OUTPUT=false

# Application settings
RESPONSE_FORMAT=json
STREAM_RESPONSE=true
CACHE_RESPONSES=false
CACHE_TTL=3600
