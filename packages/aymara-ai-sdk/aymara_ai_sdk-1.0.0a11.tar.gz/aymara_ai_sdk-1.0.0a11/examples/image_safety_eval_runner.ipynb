{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fb27b941602401d91542211134fc71a",
   "metadata": {},
   "source": [
    "# AymaraAI Image Safety Eval with EvalRunner and AsyncEvalRunner\n",
    "\n",
    "This notebook demonstrates how to use both the synchronous `EvalRunner` and asynchronous `AsyncEvalRunner` for image safety evaluation with the AymaraAI SDK."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acae54e37e7d407bbb7b55eff062a284",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "- Set `AWS_ACCESS_KEY_ID`, `AWS_SECRET_ACCESS_KEY`, `AWS_REGION`, and `AYMARA_AI_API_KEY` in your environment or `.env` file.\n",
    "- Install dependencies:\n",
    "  ```bash\n",
    "  pip install boto3 aymara-ai dotenv pandas requests pillow\n",
    "  ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a63283cbaf04dbcab1f6479b197f3a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Environment and imports\n",
    "import io\n",
    "import os\n",
    "import json\n",
    "import base64\n",
    "import tempfile\n",
    "\n",
    "import boto3  # type: ignore\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from aymara_ai import AymaraAI, AsyncAymaraAI\n",
    "from aymara_ai.lib.runner import EvalRunner, AsyncEvalRunner\n",
    "from aymara_ai.lib.images_utils import display_image_responses\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd0d8092fe74a7c96281538738b07e2",
   "metadata": {},
   "source": [
    "## Define Model Callables\n",
    "\n",
    "The callable interface takes a prompt string, generates an image using AWS Bedrock, uploads it to Aymara, and returns a FileReference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72eea5119410473aa328ad9291626812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Bedrock client\n",
    "from pathlib import Path\n",
    "\n",
    "bedrock = boto3.client(\"bedrock-runtime\", region_name=os.getenv(\"AWS_REGION\", \"us-west-2\"))\n",
    "\n",
    "\n",
    "def generate_image(prompt: str) -> Path:\n",
    "    \"\"\"Generate an image using AWS Bedrock Stability model and return the local file path.\"\"\"\n",
    "    try:\n",
    "        body = json.dumps({\"prompt\": prompt})\n",
    "        response = bedrock.invoke_model(\n",
    "            modelId=\"stability.stable-image-core-v1:0\",  # Update if your Bedrock model ID is different\n",
    "            body=body,\n",
    "            accept=\"application/json\",\n",
    "            contentType=\"application/json\",\n",
    "        )\n",
    "        result = json.loads(response[\"body\"].read())\n",
    "        # The output format may vary; adjust as needed for your Bedrock model\n",
    "        image_b64 = result[\"images\"][0]\n",
    "        with tempfile.NamedTemporaryFile(delete=False, suffix=\".png\") as tmp:\n",
    "            image_data = base64.b64decode(image_b64)\n",
    "            image = Image.open(io.BytesIO(image_data))\n",
    "            image.save(tmp.name, format=\"PNG\")\n",
    "            # return the path to the saved image\n",
    "            return Path(tmp.name)\n",
    "    except Exception as e:\n",
    "        display(f\"Error generating image: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Asynchronous model callable for AsyncEvalRunner\n",
    "async def generate_image_async(prompt: str) -> Path:\n",
    "    image_path = generate_image(prompt)\n",
    "    # Use sync upload in thread for simplicity\n",
    "    return image_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edb47106e1a46a883d545849b8ab81b",
   "metadata": {},
   "source": [
    "## Define Eval Parameters\n",
    "\n",
    "We will use a basic image safety eval configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10185d26023b46108eb7d9f57d49d2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_description = \"A helpful AI assistant.\"\n",
    "ai_instructions = \"Please generate a set of images that are safe for work and do not contain any explicit content.\"\n",
    "\n",
    "eval_params = {\n",
    "    \"ai_description\": ai_description,\n",
    "    \"ai_instructions\": ai_instructions,\n",
    "    \"eval_type\": \"safety\",\n",
    "    \"name\": \"image safety eval (runner example)\",\n",
    "    \"modality\": \"image\",\n",
    "    \"num_prompts\": 5,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8763a12b2bbd4a93a75aff182afb95dc",
   "metadata": {},
   "source": [
    "## Synchronous Evaluation with EvalRunner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7623eae2785240b9bd12b16a66d81610",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'images'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m client \u001b[38;5;241m=\u001b[39m AymaraAI()\n\u001b[1;32m      2\u001b[0m runner \u001b[38;5;241m=\u001b[39m EvalRunner(client, generate_image)\n\u001b[0;32m----> 3\u001b[0m eval_run \u001b[38;5;241m=\u001b[39m \u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43meval_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m display(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEval Run ID: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00meval_run\u001b[38;5;241m.\u001b[39meval_run_uuid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/source/aymara/aymara-sdk-python/src/aymara_ai/lib/runner.py:82\u001b[0m, in \u001b[0;36mEvalRunner.run_eval\u001b[0;34m(self, eval_params)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mClient() \u001b[38;5;28;01mas\u001b[39;00m client:\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m prompts:\n\u001b[0;32m---> 82\u001b[0m         model_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_callable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;66;03m# Allow model_callable to return None, str, or Path\u001b[39;00m\n\u001b[1;32m     84\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m model_output \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     85\u001b[0m             \u001b[38;5;66;03m# Model refused to answer\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[2], line 18\u001b[0m, in \u001b[0;36mgenerate_image\u001b[0;34m(prompt)\u001b[0m\n\u001b[1;32m     16\u001b[0m result \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mread())\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# The output format may vary; adjust as needed for your Bedrock model\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m image_b64 \u001b[38;5;241m=\u001b[39m \u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tempfile\u001b[38;5;241m.\u001b[39mNamedTemporaryFile(delete\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, suffix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m tmp:\n\u001b[1;32m     20\u001b[0m     image_data \u001b[38;5;241m=\u001b[39m base64\u001b[38;5;241m.\u001b[39mb64decode(image_b64)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'images'"
     ]
    }
   ],
   "source": [
    "client = AymaraAI()\n",
    "runner = EvalRunner(client, generate_image)\n",
    "eval_run = runner.run_eval(eval_params)\n",
    "display(f\"Eval Run ID: {eval_run.eval_run_uuid}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdc8c89c7104fffa095e18ddfef8986",
   "metadata": {},
   "source": [
    "## Asynchronous Evaluation with AsyncEvalRunner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b118ea5561624da68c537baed56e602f",
   "metadata": {},
   "outputs": [],
   "source": [
    "async_client = AsyncAymaraAI()\n",
    "runner = AsyncEvalRunner(async_client, generate_image_async)\n",
    "eval_run_async = await runner.run_eval(eval_params)\n",
    "display(f\"Async Eval Run ID: {eval_run_async.eval_run_uuid}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938c804e27f84196a10c8828c723f798",
   "metadata": {},
   "source": [
    "## Display and Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504fb2a444614c0babb325280ed9130a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results for synchronous run\n",
    "\n",
    "prompts = client.evals.list_prompts(runner.eval_id).items\n",
    "responses = client.evals.runs.list_responses(runner.run_id).items\n",
    "display_image_responses(\n",
    "    evals=[runner.eval_obj],\n",
    "    eval_prompts={runner.eval_id: prompts},\n",
    "    eval_responses={runner.eval_id: responses},\n",
    "    n_images_per_eval=3,\n",
    ")\n",
    "\n",
    "# Display results for async run (uncomment if async run was executed)\n",
    "# prompts_async = (await async_client.evals.list_prompts(eval_run_async.eval_uuid)).items\n",
    "# responses_async = (await async_client.evals.runs.list_responses(eval_run_async.eval_run_uuid)).items\n",
    "# display_image_responses(\n",
    "#     evals=[eval_run_async.eval_obj],\n",
    "#     eval_prompts={eval_run_async.eval_id: prompts_async},\n",
    "#     eval_responses={eval_run_async.eval_id: responses_async},\n",
    "#     n_images_per_eval=3\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bbdb311c014d738909a11f9e486628",
   "metadata": {},
   "source": [
    "## (Optional) Visualize with graph_eval_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43b363d81ae4b689946ece5c682cd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from aymara_ai.lib.plot import graph_eval_stats  # type: ignore\n",
    "\n",
    "    graph_eval_stats(eval_runs=[eval_run])\n",
    "except ImportError:\n",
    "    display(\"Plotting utility not available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a65eabff63a45729fe45fb5ade58bdc",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrated how to use both the synchronous `EvalRunner` and asynchronous `AsyncEvalRunner` for image safety evaluation with the AymaraAI SDK, using a callable interface that generates and uploads images. Use the synchronous runner for simple, blocking workflows, and the async runner for scalable or concurrent evaluation tasks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
