Metadata-Version: 2.4
Name: ncon-torch
Version: 0.2.7
Summary: Tensor network contraction function with GPU and autograd support via PyTorch.
Home-page: https://github.com/alam-faisal/ncon-torch
Author: Faisal Alam
Author-email: mfalam2@illinois.edu
License: MIT
Keywords: tensor networks
Classifier: Programming Language :: Python :: 3
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Classifier: Topic :: Scientific/Engineering
Requires-Python: >=3.8
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: torch>=1.12
Requires-Dist: numpy>=1.20
Provides-Extra: tests
Requires-Dist: pytest; extra == "tests"
Requires-Dist: coverage; extra == "tests"
Requires-Dist: pytest-cov; extra == "tests"
Dynamic: author
Dynamic: author-email
Dynamic: classifier
Dynamic: description
Dynamic: description-content-type
Dynamic: home-page
Dynamic: keywords
Dynamic: license
Dynamic: license-file
Dynamic: provides-extra
Dynamic: requires-dist
Dynamic: requires-python
Dynamic: summary

# ncon-torch
![PyPI version](https://img.shields.io/pypi/v/ncon-torch)

ncon-torch is a fork of the ncon package, modified to include GPU and autograd support via PyTorch

## Installation

`pip install ncon-torch`

## Usage

See original package [repo](https://github.com/mhauru/ncon) for examples. 

## Benchmark 

Below we compare NumPy and PyTorch based contractions of a two-qubit gate with an n-qubit state. The benchmark was done on Google Colab with a T4 GPU. 

![Benchmark: NumPy vs PyTorch](benchmark.png)
