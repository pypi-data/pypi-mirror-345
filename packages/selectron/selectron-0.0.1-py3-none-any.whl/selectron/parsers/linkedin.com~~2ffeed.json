{
  "python": "import re\nfrom bs4 import BeautifulSoup\n\ndef parse_element(html: str) -> dict[str, object]:\n    def parse_number(text: str) -> int | None:\n        if not text:\n            return None\n        text = text.strip()\n        multiplier = 1\n        if text[-1].upper() == 'K':\n            multiplier = 1000\n            text = text[:-1]\n        elif text[-1].upper() == 'M':\n            multiplier = 1000000\n            text = text[:-1]\n        text = text.replace(',', '')\n        try:\n            return int(float(text) * multiplier)\n        except ValueError:\n            return None\n\n    soup = BeautifulSoup(html, 'html.parser')\n    data = {}\n\n    # Primary url and datetime\n    best_a = None\n    best_a_score = -1\n    for a in soup.find_all('a', href=True):\n        time_elem = a.find('time', datetime=True)\n        score = 0\n        if time_elem:\n            score += 10\n        if a.get('aria-label'):\n            score += 1\n        if score > best_a_score:\n            best_a_score = score\n            best_a = a\n    if best_a and best_a.has_attr('href'):\n        data['primary_url'] = best_a['href']\n        time_elem = best_a.find('time', datetime=True)\n        if time_elem and time_elem.get('datetime'):\n            data['datetime'] = time_elem['datetime']\n            ttext = time_elem.string\n            if ttext and ttext.strip():\n                data['timestamp'] = ttext.strip()\n\n    if 'datetime' not in data:\n        time_elem = soup.find('time', datetime=True)\n        if time_elem and time_elem.get('datetime'):\n            data['datetime'] = time_elem['datetime']\n            ttext = time_elem.string\n            if ttext and ttext.strip():\n                data['timestamp'] = ttext.strip()\n\n    # ID extraction\n    id_ = None\n    if soup.has_attr('data-id'):\n        id_ = soup['data-id']\n    elif 'primary_url' in data:\n        url = data['primary_url'].rstrip('/')\n        m = re.search(r'/([^/?#&=]+)(?:[/?#&]|$)', url)\n        if m:\n            candidate = m.group(1).strip()\n            if candidate and not re.match(r'^https?:?$', candidate) and not re.search(r'\\.', candidate):\n                id_ = candidate\n            else:\n                id_ = url\n    if id_ and id_ != data.get('primary_url'):\n        data['id'] = id_\n\n    # Title extraction\n    title = None\n    meta_title = (soup.find('meta', property='og:title') or \n                  soup.find('meta', attrs={'name':'twitter:title'}))\n    if meta_title and meta_title.has_attr('content') and meta_title['content'].strip():\n        title = meta_title['content'].strip()\n    if not title:\n        for tag in ['h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'title']:\n            t = soup.find(tag)\n            if t and t.string and t.string.strip():\n                title = t.string.strip()\n                break\n    if not title:\n        label = soup.get('aria-label')\n        if label and label.strip():\n            title = label.strip()\n    if title:\n        data['title'] = title\n\n    # Author info extraction\n    author = None\n    author_url = None\n    candidates = []\n    for a in soup.find_all('a', href=True):\n        href = a['href']\n        text = a.get_text(separator=' ', strip=True) or ''\n        if not href or href.startswith('mailto:'):\n            continue\n        if re.search(r'/(in|user|company|profile)/', href):\n            if text:\n                candidates.append((text, href))\n    if candidates:\n        author, author_url = candidates[0]\n        # Clean author string from repeated parts\n        author_words = author.split()\n        if len(author_words) > 4 and author_words[0] == author_words[1]:\n            author = ' '.join(author_words[1:])\n        data['author'] = author\n        data['author_url'] = author_url\n\n    # Description extraction\n    description = None\n    content_selectors = [\n        '.feed-shared-update-v2__description',\n        '.update-components-update-v2__commentary',\n        '.update-components-text',\n        '.feed-shared-update-v2__content',\n        'article',\n        'section'\n    ]\n    texts = []\n    for selector in content_selectors:\n        elems = soup.select(selector)\n        for el in elems:\n            txt = el.get_text(separator=' ', strip=True)\n            if txt and len(txt) > 25:\n                texts.append(txt)\n    if not texts:\n        for p in soup.find_all('p'):\n            txt = p.get_text(separator=' ', strip=True)\n            if txt and len(txt) > 25:\n                texts.append(txt)\n    if texts:\n        description = max(texts, key=len)\n        # Remove repeated substrings\n        # Simple heuristic: if text is formed by repetition, pick first segment\n        for i in range(1, len(description)//2 + 1):\n            if description == description[:i] * (len(description)//i):\n                description = description[:i]\n                break\n        data['description'] = description\n\n    # Images\n    images = []\n    img_is_avatar = set()\n    if author_url:\n        for a in soup.find_all('a', href=author_url):\n            for img in a.find_all('img', src=True):\n                img_is_avatar.add(img['src'])\n    for img in soup.find_all('img', src=True):\n        src = img['src']\n        if not src or src.startswith('data:') or src in img_is_avatar:\n            continue\n        img_dict = {'src': src}\n        alt = img.get('alt')\n        title_img = img.get('title')\n        width = img.get('width')\n        height = img.get('height')\n        if alt:\n            img_dict['alt'] = alt\n        if title_img:\n            img_dict['title'] = title_img\n        if width and width.isdigit():\n            img_dict['width'] = int(width)\n        if height and height.isdigit():\n            img_dict['height'] = int(height)\n        for k, v in img.attrs.items():\n            if k.startswith('data-') and v:\n                img_dict[k] = v\n        images.append(img_dict)\n    if images:\n        data['images'] = images\n\n    # Metrics\n    metrics_map = {\n        'reply_count': ['reply', 'replies'],\n        'repost_count': ['repost', 'retweet', 'retweets'],\n        'like_count': ['like', 'likes', 'react', 'reactions'],\n        'bookmark_count': ['bookmark'],\n        'view_count': ['view', 'views'],\n    }\n    for key, keywords in metrics_map.items():\n        found_num = None\n        for kw in keywords:\n            elems = soup.find_all(attrs={'aria-label': re.compile(kw, re.I)})\n            for el in elems:\n                text = el.get_text(strip=True)\n                num = parse_number(text)\n                if num is not None:\n                    found_num = num\n                    break\n            if found_num is not None:\n                break\n            elems = soup.find_all(class_=re.compile(kw, re.I))\n            for el in elems:\n                text = el.get_text(strip=True)\n                num = parse_number(text)\n                if num is not None:\n                    found_num = num\n                    break\n            if found_num is not None:\n                break\n        if found_num is not None:\n            data[key] = found_num\n\n    # Rank\n    rank = None\n    if soup.has_attr('data-rank'):\n        try:\n            rank = int(soup['data-rank'])\n        except Exception:\n            rank = None\n    if rank is not None:\n        data['rank'] = rank\n\n    return data",
  "selector": "div.feed-shared-update-v2[role='article']",
  "selector_description": "The posts in the feed"
}