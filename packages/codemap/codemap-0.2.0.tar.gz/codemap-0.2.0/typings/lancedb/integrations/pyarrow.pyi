"""
This type stub file was generated by pyright.
"""

import pyarrow as pa
from typing import Any, List, Literal, Optional, Tuple, Union
from ..table import Table

Filter = Union[str, pa.compute.Expression]
Keys = Union[str, List[str]]
JoinType = Literal["left semi", "right semi", "left anti", "right anti", "inner", "left outer", "right outer", "full outer",]
class PyarrowScannerAdapter(pa.dataset.Scanner):
    def __init__(self, table: Table, columns: Optional[List[str]] = ..., filter: Optional[Filter] = ..., batch_size: Optional[int] = ..., batch_readahead: Optional[int] = ..., fragment_readahead: Optional[int] = ..., fragment_scan_options: Optional[Any] = ..., use_threads: bool = ..., memory_pool: Optional[Any] = ...) -> None:
        ...
    
    def count_rows(self): # -> int:
        ...
    
    def from_batches(self, **kwargs):
        ...
    
    def from_dataset(self, **kwargs):
        ...
    
    def from_fragment(self, **kwargs):
        ...
    
    def head(self, num_rows: int):
        ...
    
    @property
    def projected_schema(self):
        ...
    
    def scan_batches(self):
        ...
    
    def take(self, indices: List[int]):
        ...
    
    def to_batches(self):
        ...
    
    def to_table(self):
        ...
    
    def to_reader(self, *, limit: Optional[int] = ...):
        ...
    


class PyarrowDatasetAdapter(pa.dataset.Dataset):
    def __init__(self, table: Table) -> None:
        ...
    
    def count_rows(self, filter: Optional[Filter] = ...): # -> int:
        ...
    
    def get_fragments(self, filter: Optional[Filter] = ...):
        ...
    
    def head(self, num_rows: int, columns: Optional[List[str]] = ..., filter: Optional[Filter] = ..., batch_size: Optional[int] = ..., batch_readahead: Optional[int] = ..., fragment_readahead: Optional[int] = ..., fragment_scan_options: Optional[Any] = ..., use_threads: bool = ..., memory_pool: Optional[Any] = ...):
        ...
    
    def join(self, right_dataset: Any, keys: Keys, right_keys: Optional[Keys] = ..., join_type: Optional[JoinType] = ..., left_suffix: Optional[str] = ..., right_suffix: Optional[str] = ..., coalesce_keys: bool = ..., use_threads: bool = ...):
        ...
    
    def join_asof(self, right_dataset: Any, on: str, by: Keys, tolerance: int, right_on: Optional[str] = ..., right_by: Optional[Keys] = ...):
        ...
    
    @property
    def partition_expression(self):
        ...
    
    def replace_schema(self, schema: pa.Schema):
        ...
    
    def scanner(self, columns: Optional[List[str]] = ..., filter: Optional[Filter] = ..., batch_size: Optional[int] = ..., batch_readahead: Optional[int] = ..., fragment_readahead: Optional[int] = ..., fragment_scan_options: Optional[Any] = ..., use_threads: bool = ..., memory_pool: Optional[Any] = ...): # -> PyarrowScannerAdapter:
        ...
    
    @property
    def schema(self):
        ...
    
    def sort_by(self, sorting: Union[str, List[Tuple[str, bool]]]):
        ...
    
    def take(self, indices: List[int], columns: Optional[List[str]] = ..., filter: Optional[Filter] = ..., batch_size: Optional[int] = ..., batch_readahead: Optional[int] = ..., fragment_readahead: Optional[int] = ..., fragment_scan_options: Optional[Any] = ..., use_threads: bool = ..., memory_pool: Optional[Any] = ...):
        ...
    
    def to_batches(self, columns: Optional[List[str]] = ..., filter: Optional[Filter] = ..., batch_size: Optional[int] = ..., batch_readahead: Optional[int] = ..., fragment_readahead: Optional[int] = ..., fragment_scan_options: Optional[Any] = ..., use_threads: bool = ..., memory_pool: Optional[Any] = ...):
        ...
    
    def to_table(self, columns: Optional[List[str]] = ..., filter: Optional[Filter] = ..., batch_size: Optional[int] = ..., batch_readahead: Optional[int] = ..., fragment_readahead: Optional[int] = ..., fragment_scan_options: Optional[Any] = ..., use_threads: bool = ..., memory_pool: Optional[Any] = ...):
        ...
    


