{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatizing new matches downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining match data from the website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Match_data:\n",
    "    def __init__(self, url, max):\n",
    "        \"\"\"\n",
    "        Initialize the class with the given URL and optional limits for the number of links, gameweeks, and scores.\n",
    "\n",
    "        Args:\n",
    "            url (str): The URL to scrape match data from.\n",
    "            max (int or None): Maximum number of match links, gameweeks, and scores to scrape. If None, no limit is applied.\n",
    "        \"\"\"\n",
    "        self.url = url  # Store the URL as an attribute of the class\n",
    "        self.max_links = max  # Limit for match links\n",
    "        self.max_gameweeks = max  # Limit for gameweeks\n",
    "        self.max_scores = max  # Limit for scores\n",
    "        self.links = []  # List to store match links\n",
    "        self.gameweeks = []  # List to store gameweek data\n",
    "        self.scores = []  # List to store match scores (home and away goals)\n",
    "        self.result = []  # List of results\n",
    "        self.previous_gameweek = None  # Variable to store the last valid gameweek\n",
    "\n",
    "    def get_match_data(self):\n",
    "        \"\"\"\n",
    "        Get match report links, gameweek data, result and match scores (home and away goals) from the provided URL.\n",
    "\n",
    "        This function scrapes the provided URL for match report links, gameweek data, result and match scores,\n",
    "        and stores them in the respective lists.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame, pd.DataFrame, pd.DataFrame: Three DataFrames containing match report links, gameweek data, scores and result.\n",
    "        \"\"\"\n",
    "        headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:131.0) Gecko/20100101 Firefox/131.0\",\n",
    "            \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8\",\n",
    "            \"Accept-Language\": \"en-US,en;q=0.5\",  # Indicates preferred language\n",
    "            \"Accept-Encoding\": \"gzip, deflate, br\",  # Indicates that compressed responses are accepted\n",
    "            \"Connection\": \"keep-alive\",  # Keeps the connection open for better efficiency\n",
    "            \"Upgrade-Insecure-Requests\": \"1\",  # Indicates that the client prefers HTTPS\n",
    "            \"DNT\": \"1\",  # Indicates that tracking is not desired (optional)\n",
    "        }\n",
    "\n",
    "        # Send HTTP request to the URL\n",
    "        response = requests.get(self.url, headers=headers)\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")  # Parse the HTML content\n",
    "\n",
    "        # Get match report links\n",
    "        report_cells = soup.find_all(\"td\", {\"data-stat\": \"match_report\"})\n",
    "        for cell in report_cells:\n",
    "            if len(self.links) >= self.max_links:\n",
    "                break  # Stop once we reach the limit\n",
    "            link = cell.find(\"a\")  # Find the <a> tag in the cell\n",
    "            if link:\n",
    "                url = link[\"href\"]  # Extract the URL from the link\n",
    "                self.links.append(\n",
    "                    f\"https://fbref.com{url}\"\n",
    "                )  # Append the full URL to the links list\n",
    "            time.sleep(6)  # Sleep to avoid making too many requests in a short time\n",
    "\n",
    "        # Get gameweek data\n",
    "        gameweek_cells = soup.find_all(\"th\", {\"data-stat\": \"gameweek\"})\n",
    "        for cell in gameweek_cells:\n",
    "            if len(self.gameweeks) >= self.max_gameweeks:\n",
    "                break  # Stop once we reach the limit\n",
    "            gameweek_value = (\n",
    "                cell.text.strip() if cell else \"N/A\"\n",
    "            )  # Extract and clean the gameweek value\n",
    "            if gameweek_value in [\"Sem.\", \"\"]:  # Skip 'Sem.' or empty values\n",
    "                continue\n",
    "\n",
    "            if gameweek_value == \"N/A\" and self.previous_gameweek:\n",
    "                # If no gameweek found, use the previous gameweek\n",
    "                gameweek_value = self.previous_gameweek\n",
    "\n",
    "            try:\n",
    "                # Convert gameweek_value to an integer\n",
    "                gameweek_value = int(gameweek_value)\n",
    "            except ValueError:\n",
    "                gameweek_value = -1  # Use -1 if the gameweek is not a valid integer\n",
    "\n",
    "            self.gameweeks.append(\n",
    "                gameweek_value\n",
    "            )  # Append the value to the gameweeks list\n",
    "            self.previous_gameweek = gameweek_value  # Update the previous gameweek\n",
    "            time.sleep(6)  # Sleep to avoid making too many requests in a short time\n",
    "\n",
    "        # Get match scores (home and away goals)\n",
    "        score_cells = soup.find_all(\"td\", {\"data-stat\": \"score\"})\n",
    "        for cell in score_cells:\n",
    "            if len(self.scores) >= self.max_scores:\n",
    "                break  # Stop once we reach the limit\n",
    "            score_text = cell.text.strip() if cell else \"\"\n",
    "            if score_text:\n",
    "                # Extract home and away goals\n",
    "                score_parts = score_text.split(\"–\")\n",
    "                if len(score_parts) == 2:\n",
    "                    try:\n",
    "                        home_goals = int(score_parts[0].strip())\n",
    "                        away_goals = int(score_parts[1].strip())\n",
    "                        self.scores.append(\n",
    "                            (home_goals, away_goals)\n",
    "                        )  # Append the tuple of scores\n",
    "\n",
    "                        # Determine the result and append it to self.result\n",
    "                        if home_goals > away_goals:\n",
    "                            result = 1  # Home team wins\n",
    "                        elif home_goals < away_goals:\n",
    "                            result = -1  # Away team wins\n",
    "                        else:\n",
    "                            result = 0  # Draw\n",
    "\n",
    "                        self.result.append(result)  # Add the result to the result list\n",
    "\n",
    "                    except ValueError:\n",
    "                        self.scores.append(\n",
    "                            (0, 0)\n",
    "                        )  # Use (0, 0) if there is a problem parsing the scores\n",
    "\n",
    "            time.sleep(6)  # Sleep to avoid making too many requests in a short time\n",
    "\n",
    "        # Return match report links, gameweek data, scores, and results\n",
    "        return self.links, self.gameweeks, self.scores, self.result\n",
    "\n",
    "    def create_matches_csv(self):\n",
    "        \"\"\"\n",
    "        Create a CSV file with match data, combining gameweek, match information, and goals.\n",
    "\n",
    "        This function combines match details (e.g., teams, date, time), gameweek data, and goals into a single DataFrame.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: DataFrame containing match details, gameweek data, and goals.\n",
    "        \"\"\"\n",
    "        # Create a DataFrame with empty values for the match data\n",
    "        df = pd.DataFrame(\n",
    "            {\n",
    "                \"id\": pd.Series(\n",
    "                    [None] * len(self.links)\n",
    "                ),  # Create a new column with unique IDs for each match\n",
    "                \"date_of_match\": pd.Series([None] * len(self.links)),\n",
    "                \"hour_of_the_match\": pd.Series([None] * len(self.links)),\n",
    "                \"day_of_week\": pd.Series([None] * len(self.links)),\n",
    "                \"day_of_year\": pd.Series([None] * len(self.links)),\n",
    "                \"hour_of_day\": pd.Series([None] * len(self.links)),\n",
    "                \"home_team_name\": pd.Series([None] * len(self.links), dtype=\"str\"),\n",
    "                \"away_team_name\": pd.Series([None] * len(self.links), dtype=\"str\"),\n",
    "                \"home_trainer\": pd.Series([None] * len(self.links), dtype=\"str\"),\n",
    "                \"away_trainer\": pd.Series([None] * len(self.links), dtype=\"str\"),\n",
    "                \"stadium\": pd.Series([None] * len(self.links), dtype=\"str\"),\n",
    "                \"attendance\": pd.Series([None] * len(self.links), dtype=\"str\"),\n",
    "                \"capacity\": pd.Series([None] * len(self.links), dtype=\"int\"),\n",
    "                \"attendance%\": pd.Series([None] * len(self.links), dtype=\"float\"),\n",
    "                \"referee\": pd.Series([None] * len(self.links), dtype=\"str\"),\n",
    "                \"var\": pd.Series([None] * len(self.links), dtype=\"str\"),\n",
    "                \"home_team_lineup\": pd.Series([None] * len(self.links), dtype=\"str\"),\n",
    "                \"away_team_lineup\": pd.Series([None] * len(self.links), dtype=\"str\"),\n",
    "                \"home_possession\": pd.Series([None] * len(self.links), dtype=\"float\"),\n",
    "                \"away_possession\": pd.Series([None] * len(self.links), dtype=\"float\"),\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Ensure that the 'date_of_match' column is converted to datetime format\n",
    "        df[\"date_of_match\"] = pd.to_datetime(\n",
    "            df[\"date_of_match\"], format=\"%Y-%m-%d\", errors=\"coerce\"\n",
    "        )\n",
    "\n",
    "        # Ensure that the 'hour_of_the_match' column is converted to datetime format\n",
    "        df[\"hour_of_the_match\"] = pd.to_datetime(\n",
    "            df[\"hour_of_the_match\"], format=\"%H:%M\", errors=\"coerce\"\n",
    "        ).dt.time\n",
    "\n",
    "        # Get the match data (links, gameweeks, and goals)\n",
    "        links, gameweeks, scores, result = self.get_match_data()\n",
    "\n",
    "        # Create DataFrames from the gameweek, links, and scores data\n",
    "        df_gameweeks = pd.DataFrame(gameweeks, columns=[\"gameweek\"])\n",
    "        df_links = pd.DataFrame(links, columns=[\"link\"])\n",
    "        df_scores = pd.DataFrame(scores, columns=[\"home_team_goals\", \"away_team_goals\"])\n",
    "        df_result = pd.DataFrame(result, columns=[\"result\"])\n",
    "\n",
    "        # Combine all DataFrames into one final DataFrame\n",
    "        df_final = pd.concat([df_gameweeks, df], axis=1)\n",
    "        df_final = pd.concat([df_final, df_links], axis=1)\n",
    "        df_final = pd.concat([df_final, df_scores], axis=1)\n",
    "        df_final = pd.concat([df_final, df_result], axis=1)\n",
    "\n",
    "        # Assign the final DataFrame to the class attribute with the new name\n",
    "        self.df_final = df_final\n",
    "\n",
    "        return self.df_final  # Return the DataFrame to be used later\n",
    "\n",
    "    def get_statistics(self):\n",
    "        \"\"\"\n",
    "        Get match statistics from the links and save them to a CSV file.\n",
    "\n",
    "        This function extracts detailed statistics (e.g., team lineups, referee, attendance) from the match links.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: DataFrame containing match statistics.\n",
    "        \"\"\"\n",
    "        links = self.df_final[\"link\"].tolist()\n",
    "        id = 0\n",
    "\n",
    "        for idx, link in enumerate(links):\n",
    "            try:\n",
    "                print(f\"Processing link {idx + 1}: {link}\")\n",
    "                headers = {\n",
    "                    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:131.0) Gecko/20100101 Firefox/131.0\",\n",
    "                    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8\",\n",
    "                    \"Accept-Language\": \"en-US,en;q=0.5\",\n",
    "                    \"Accept-Encoding\": \"gzip, deflate, br\",\n",
    "                    \"Connection\": \"keep-alive\",\n",
    "                    \"Upgrade-Insecure-Requests\": \"1\",\n",
    "                    \"DNT\": \"1\",\n",
    "                }\n",
    "                response = requests.get(link, headers=headers)\n",
    "                soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "                # Assign a unique ID for each match\n",
    "                id += 1\n",
    "                self.df_final.at[idx, \"id\"] = id\n",
    "\n",
    "                # Extract match date and time\n",
    "                date_element = soup.find(\"span\", {\"class\": \"venuetime\"})\n",
    "                if date_element:\n",
    "                    match_date = date_element.get(\"data-venue-date\")\n",
    "                    match_date = pd.to_datetime(match_date, errors=\"coerce\")  # Convert to datetime\n",
    "                    day_of_week = match_date.dayofweek  # Day of the week\n",
    "                    day_of_year = match_date.dayofyear  # Day of the year\n",
    "                    match_time = date_element.get(\"data-venue-time\")\n",
    "                    # Convert match_time to datetime and extract hour and minute\n",
    "                    match_time = pd.to_datetime(\n",
    "                        match_time, format=\"%H:%M\", errors=\"coerce\"\n",
    "                    )\n",
    "                    hour_of_day = (\n",
    "                        match_time.hour + match_time.minute / 60\n",
    "                    )  # Convert to decimal (e.g., 19:30 -> 19.5)\n",
    "                    # Store the values in the DataFrame\n",
    "                    self.df_final.at[idx, \"date_of_match\"] = match_date\n",
    "                    self.df_final.at[idx, \"day_of_week\"] = day_of_week\n",
    "                    self.df_final.at[idx, \"day_of_year\"] = day_of_year\n",
    "                    self.df_final.at[idx, \"hour_of_the_match\"] = match_time.strftime(\n",
    "                        \"%H:%M\"\n",
    "                    )  # Store as time\n",
    "                    self.df_final.at[idx, \"hour_of_day\"] = (\n",
    "                        hour_of_day  # Store as decimal\n",
    "                    )\n",
    "\n",
    "                # Extract team names\n",
    "                teams_elements = soup.find_all(\"span\", class_=\"teamandlogo\")\n",
    "                if len(teams_elements) >= 2:\n",
    "                    home_team_name = teams_elements[0].text.strip()\n",
    "                    away_team_name = teams_elements[1].text.strip()\n",
    "                else:\n",
    "                    print(f\"Team names not found for link {link}. Assigning NaN.\")\n",
    "                    home_team_name = away_team_name = \"NaN\"\n",
    "                # Remove accents and replace spaces with underscores\n",
    "                home_team_name = unidecode(home_team_name).replace(\" \", \"_\")\n",
    "                away_team_name = unidecode(away_team_name).replace(\" \", \"_\")\n",
    "                # Assign the processed names to the DataFrame\n",
    "                self.df_final.at[idx, \"home_team_name\"] = home_team_name\n",
    "                self.df_final.at[idx, \"away_team_name\"] = away_team_name\n",
    "\n",
    "                # Extract coaches (trainers) names\n",
    "                trainers_elements = soup.find_all(\"div\", class_=\"datapoint\")\n",
    "                trainer_count = 0\n",
    "                for trainer_element in trainers_elements:\n",
    "                    if \"Director Técnico\" in trainer_element.text:\n",
    "                        trainer_name = trainer_element.text.split(\":\")[-1].strip()\n",
    "                        if trainer_count == 0:\n",
    "                            home_trainer = trainer_name\n",
    "                            trainer_count += 1\n",
    "                        elif trainer_count == 1:\n",
    "                            away_trainer = trainer_name\n",
    "                            trainer_count += 1\n",
    "                if \"home_trainer\" not in locals():\n",
    "                    print(f\"Home coach not found for link {link}. Assigning NaN.\")\n",
    "                    home_trainer = \"NaN\"\n",
    "                if \"away_trainer\" not in locals():\n",
    "                    print(f\"Away coach not found for link {link}. Assigning NaN.\")\n",
    "                    away_trainer = \"NaN\"\n",
    "                # Remove accents and replace spaces with underscores\n",
    "                home_trainer = unidecode(home_trainer).replace(\" \", \"_\")\n",
    "                away_trainer = unidecode(away_trainer).replace(\" \", \"_\")\n",
    "                # Assign the processed names to the DataFrame\n",
    "                self.df_final.at[idx, \"home_trainer\"] = home_trainer\n",
    "                self.df_final.at[idx, \"away_trainer\"] = away_trainer\n",
    "\n",
    "                # List of stadiums without accents\n",
    "                stadiums = [\n",
    "                    \"San_Mames\",\n",
    "                    \"Estadio_de_Balaidos\",\n",
    "                    \"Estadio_de_Mestalla\",\n",
    "                    \"Iberostar_Estadi\",\n",
    "                    \"Estadio_Municipal_de_Butarque\",\n",
    "                    \"Estadio_de_la_Ceramica\",\n",
    "                    \"Estadio_de_Mendizorroza\",\n",
    "                    \"RCDE_Stadium\",\n",
    "                    \"Estadio_Benito_Villamarin\",\n",
    "                    \"Estadio_Wanda_Metropolitano\",\n",
    "                    \"Estadio_Nuevo_Los_Carmenes\",\n",
    "                    \"Estadio_Ciudad_de_Valencia\",\n",
    "                    \"Estadio_El_Sadar\",\n",
    "                    \"Estadio_Santiago_Bernabeu\",\n",
    "                    \"Coliseum_Alfonso_Perez\",\n",
    "                    \"Camp_Nou\",\n",
    "                    \"Estadio_Ramon_Sanchez_Pizjuan\",\n",
    "                    \"Estadio_Municipal_de_Anoeta\",\n",
    "                    \"Estadio_Municipal_de_Ipurua\",\n",
    "                    \"Estadio_Municipal_Jose_Zorrilla\",\n",
    "                    \"Estadio_Alfredo_Di_Stefano\",\n",
    "                    \"Estadio_Ramon_de_Carranza\",\n",
    "                    \"Estadio_El_Alcoraz\",\n",
    "                    \"Estadio_Manuel_Martinez_Valero\",\n",
    "                    \"Estadio_Nuevo_Mirandilla\",\n",
    "                    \"Estadio_del_Rayo_Vallecano\",\n",
    "                    \"Power_Horse_Stadium\",\n",
    "                    \"Estadio_Civitas_Metropolitano\",\n",
    "                    \"Reale_Arena\",\n",
    "                    \"Estadi_Municipal_de_Montilivi\",\n",
    "                    \"Estadio_de_Gran_Canaria\",\n",
    "                    \"Estadio_Abanca_Balaidos\",\n",
    "                    \"Estadi_Mallorca_Son_Moix\",\n",
    "                    \"Estadi_Olimpic_Lluis_Companys\",\n",
    "                    \"Estadio_Municipal_de_Riazor\",\n",
    "                    \"Estadio_La_Rosaleda\"\n",
    "                ]\n",
    "                # List of corresponding stadium capacities\n",
    "                capacities = [\n",
    "                    53289,\n",
    "                    24870,\n",
    "                    49430,\n",
    "                    26020,\n",
    "                    12454,\n",
    "                    23500,\n",
    "                    19840,\n",
    "                    40500,\n",
    "                    60721,\n",
    "                    68456,\n",
    "                    19189,\n",
    "                    26354,\n",
    "                    23576,\n",
    "                    78297,\n",
    "                    16500,\n",
    "                    99354,\n",
    "                    43883,\n",
    "                    40000,\n",
    "                    8164,\n",
    "                    27618,\n",
    "                    5600,\n",
    "                    20724,\n",
    "                    9100,\n",
    "                    31388,\n",
    "                    20724,\n",
    "                    14708,\n",
    "                    18331,\n",
    "                    68456,\n",
    "                    40000,\n",
    "                    14624,\n",
    "                    32400,\n",
    "                    24870,\n",
    "                    26020,\n",
    "                    55926,\n",
    "                    32490,\n",
    "                    30044\n",
    "                ]\n",
    "                # Create a dictionary of stadiums and their corresponding capacities\n",
    "                stadium_capacity_dict = dict(zip(stadiums, capacities))\n",
    "                # Extract stadium information\n",
    "                stadium_element = soup.find(\"div\", class_=\"scorebox_meta\")\n",
    "                if stadium_element:\n",
    "                    stadium_info = stadium_element.find(\"strong\", string=\"Sedes\")\n",
    "                    if stadium_info:\n",
    "                        stadium = (\n",
    "                            stadium_info.find_next(\"small\")\n",
    "                            .find_next(\"small\")\n",
    "                            .text.strip()\n",
    "                        )\n",
    "                    else:\n",
    "                        print(f\"Stadium not found for link {link}. Assigning NaN.\")\n",
    "                        stadium = \"NaN\"\n",
    "                else:\n",
    "                    print(f\"Stadium not found for link {link}. Assigning NaN.\")\n",
    "                    stadium = \"NaN\"\n",
    "                # Remove everything after the comma (including the comma itself)\n",
    "                if \",\" in stadium:\n",
    "                    stadium = stadium.split(\",\")[0].strip()\n",
    "                # Remove accents and replace spaces with underscores\n",
    "                stadium = unidecode(stadium).replace(\" \", \"_\")\n",
    "                # Assign the processed stadium name to the DataFrame\n",
    "                self.df_final.at[idx, \"stadium\"] = stadium\n",
    "                # Check if the stadium exists in the dictionary and assign the corresponding capacity\n",
    "                if stadium in stadium_capacity_dict:\n",
    "                    # Assign the corresponding capacity to the 'capacity' column\n",
    "                    self.df_final.at[idx, \"capacity\"] = stadium_capacity_dict[stadium]\n",
    "                else:\n",
    "                    # If the stadium is not found in the dictionary, assign NaN\n",
    "                    print(\n",
    "                        f\"Stadium '{stadium}' not found in dictionary. Assigning NaN.\"\n",
    "                    )\n",
    "                    self.df_final.at[idx, \"capacity\"] = np.nan\n",
    "\n",
    "                # Extract attendance information\n",
    "                attendance_element = soup.find(\"div\", class_=\"scorebox_meta\")\n",
    "                if attendance_element:\n",
    "                    attendance_info = attendance_element.find(\n",
    "                        \"strong\", string=\"Asistencia\"\n",
    "                    )\n",
    "                    if attendance_info:\n",
    "                        attendance = (\n",
    "                            attendance_info.find_next(\"small\")\n",
    "                            .find_next(\"small\")\n",
    "                            .text.strip()\n",
    "                        )\n",
    "                        try:\n",
    "                            attendance = int(\n",
    "                                attendance.replace(\",\", \"\").replace(\".\", \"\")\n",
    "                            )\n",
    "                        except ValueError:\n",
    "                            attendance = 0\n",
    "                else:\n",
    "                    print(f\"Attendance not found for link {link}. Assigning 0.\")\n",
    "                    attendance = 0\n",
    "\n",
    "                # Assign attendance value to the DataFrame\n",
    "                self.df_final.at[idx, \"attendance\"] = attendance\n",
    "\n",
    "                # Calculate and assign attendance percentage (ensure capacity is not NaN)\n",
    "                if (\n",
    "                    pd.notna(self.df_final.at[idx, \"capacity\"])\n",
    "                    and self.df_final.at[idx, \"capacity\"] > 0\n",
    "                ):\n",
    "                    attendance_percentage = (\n",
    "                        attendance / self.df_final.at[idx, \"capacity\"]\n",
    "                    )\n",
    "                    # Ensure attendance% does not exceed 1\n",
    "                    if attendance_percentage > 1:\n",
    "                        attendance_percentage = 1\n",
    "                    self.df_final.at[idx, \"attendance%\"] = attendance_percentage\n",
    "                else:\n",
    "                    self.df_final.at[idx, \"attendance%\"] = (\n",
    "                        np.nan\n",
    "                    )  # If capacity is NaN or 0, set attendance% as NaN\n",
    "\n",
    "                # Extract referee information\n",
    "                referee_element = soup.find(\"div\", class_=\"scorebox_meta\")\n",
    "                if referee_element:\n",
    "                    referee_info = referee_element.find_next(\n",
    "                        \"strong\", string=\"Autoridades\"\n",
    "                    )\n",
    "                    if referee_info:\n",
    "                        referee_span = (\n",
    "                            referee_info.find_next(\"small\")\n",
    "                            .find_next(\"small\")\n",
    "                            .find(\"span\", style=\"display:inline-block\")\n",
    "                        )\n",
    "                        if referee_span:\n",
    "                            referee = referee_span.text.strip()\n",
    "                            # Remove accents, replace spaces with underscores, and remove \" (Arbitro)\"\n",
    "                            referee = (\n",
    "                                unidecode(referee)\n",
    "                                .replace(\" \", \"_\")\n",
    "                                .replace(\"_(Arbitro)\", \"\")\n",
    "                            )\n",
    "                else:\n",
    "                    print(f\"Referee not found for link {link}. Assigning NaN.\")\n",
    "                    referee = \"NaN\"\n",
    "                self.df_final.at[idx, \"referee\"] = referee\n",
    "\n",
    "                # Extract VAR information\n",
    "                var_element = soup.find(\"div\", class_=\"scorebox_meta\")\n",
    "                if var_element:\n",
    "                    var_info = var_element.find_next(\"strong\", string=\"Autoridades\")\n",
    "                    if var_info:\n",
    "                        var_span = (\n",
    "                            var_info.find_next(\"small\")\n",
    "                            .find_next(\"small\")\n",
    "                            .find_next(\"span\")\n",
    "                            .find_next(\"span\")\n",
    "                            .find_next(\"span\")\n",
    "                            .find_next(\"span\")\n",
    "                            .find_next(\"span\")\n",
    "                        )\n",
    "                        if var_span:\n",
    "                            var = var_span.text.strip()\n",
    "                            # Remove accents, replace spaces with underscores, and remove \" (VAR)\"\n",
    "                            var = unidecode(var).replace(\" \", \"_\").replace(\"_(VAR)\", \"\")\n",
    "                else:\n",
    "                    print(f\"VAR not found for link {link}. Assigning NaN.\")\n",
    "                    var = \"NaN\"\n",
    "                self.df_final.at[idx, \"var\"] = var\n",
    "\n",
    "                # Extract team lineups\n",
    "                lineup_elements = soup.find_all(\n",
    "                    \"th\", string=lambda text: text and \"(\" in text and \")\" in text\n",
    "                )\n",
    "                if len(lineup_elements) >= 1:\n",
    "                    home_match = re.search(r\"\\((.*?)\\)\", lineup_elements[0].text)\n",
    "                    if home_match:\n",
    "                        home_team_lineup = home_match.group(1)\n",
    "                else:\n",
    "                    print(f\"Home lineup not found for link {link}. Assigning NaN.\")\n",
    "                    home_team_lineup = \"NaN\"\n",
    "\n",
    "                if len(lineup_elements) >= 2:\n",
    "                    away_match = re.search(r\"\\((.*?)\\)\", lineup_elements[1].text)\n",
    "                    if away_match:\n",
    "                        away_team_lineup = away_match.group(1)\n",
    "                else:\n",
    "                    print(f\"Away lineup not found for link {link}. Assigning NaN.\")\n",
    "                    away_team_lineup = \"NaN\"\n",
    "\n",
    "                self.df_final.at[idx, \"home_team_lineup\"] = home_team_lineup\n",
    "                self.df_final.at[idx, \"away_team_lineup\"] = away_team_lineup\n",
    "\n",
    "                # Extract team possession\n",
    "                possession_header = soup.find(\"th\", string=\"Posesión del balón\")\n",
    "\n",
    "                if possession_header:\n",
    "                    possession_row = possession_header.find_parent(\n",
    "                        \"tr\"\n",
    "                    ).find_next_sibling(\"tr\")\n",
    "\n",
    "                    if possession_row:\n",
    "                        possession_values = possession_row.find_all(\"td\")\n",
    "\n",
    "                        if len(possession_values) == 2:\n",
    "                            home_possession = (\n",
    "                                possession_values[0].text.strip().strip(\"%\")\n",
    "                            )\n",
    "                            away_possession = (\n",
    "                                possession_values[1].text.strip().strip(\"%\")\n",
    "                            )\n",
    "\n",
    "                            self.df_final.at[idx, \"home_possession\"] = (\n",
    "                                float(home_possession) if home_possession else None\n",
    "                            )\n",
    "                            self.df_final.at[idx, \"away_possession\"] = (\n",
    "                                float(away_possession) if away_possession else None\n",
    "                            )\n",
    "                        else:\n",
    "                            print(\n",
    "                                f\"Possession values not found for link {link}. Assigning NaN.\"\n",
    "                            )\n",
    "                    else:\n",
    "                        print(\n",
    "                            f\"Possession row not found for link {link}. Assigning NaN.\"\n",
    "                        )\n",
    "                else:\n",
    "                    print(\n",
    "                        f\"Possession header not found for link {link}. Assigning NaN.\"\n",
    "                    )\n",
    "\n",
    "                # Remove rows that are completely empty\n",
    "                self.df_final = self.df_final.dropna(how=\"all\")\n",
    "\n",
    "                time.sleep(6)  # Sleep to avoid making too many requests in a short time\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing link {link}: {e}\")\n",
    "                continue\n",
    "\n",
    "        self.df_matches = self.df_final\n",
    "        return self.df_matches\n",
    "\n",
    "    def save_to_csv(self, season):\n",
    "        \"\"\"\n",
    "        Save the processed data into a CSV file, with the season included in the filename.\n",
    "\n",
    "        Args:\n",
    "            season (str): The season to be included in the filename.\n",
    "        \"\"\"\n",
    "        # Define the filename with the season\n",
    "        filename = f\"matches_{season}.csv\"\n",
    "\n",
    "        try:\n",
    "            # Save the DataFrame to a CSV file in the parent directory\n",
    "            self.df_matches.to_csv(filename, index=False)\n",
    "\n",
    "            # Print confirmation message with the file path\n",
    "            print(f\"File saved successfully as {filename}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving file {filename}: {e}\")\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Execute the full process: get links, get gameweeks, get statistics, and save to CSV files for both teams.\n",
    "        \"\"\"\n",
    "        print(f\"Starting to collect matches data...\")\n",
    "\n",
    "        # Step 1: Extract the season from the URL\n",
    "        season_match = re.search(\n",
    "            r\"(\\d{4})-(\\d{4})\", self.url\n",
    "        )  # Use self.url instead of passing it as a parameter\n",
    "        if season_match:\n",
    "            season = season_match.group(0)\n",
    "            print(f\"Season extracted: {season}\")\n",
    "        else:\n",
    "            season = \"unknown_season\"  # Default value if the season cannot be extracted\n",
    "            print(\"Season not found in the URL. Using default value 'unknown_season'.\")\n",
    "\n",
    "        # Step 2: Get all the links to the match pages from the provided URL\n",
    "\n",
    "        # Step 3: Get the gameweek data from the provided URL\n",
    "\n",
    "        # Step 4: Create a CSV file with match details, such as teams, dates, and other match-related information\n",
    "        self.create_matches_csv()\n",
    "\n",
    "        # Step 5: Retrieve statistics for each match, such as goals, assists, and other relevant data\n",
    "        df_matches = self.get_statistics()\n",
    "\n",
    "        # Step 6: Save the processed data into a CSV file with the season name in the filename\n",
    "        self.save_to_csv(season)\n",
    "\n",
    "        print(f\"Collecting matches data process completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining players and keeper data from the website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Players_data:\n",
    "    def __init__(self, filename, links_file, gameweeks_file):\n",
    "        \"\"\"\n",
    "        Initializes the Players_data with links and gameweeks files.\n",
    "        - links_file: Path to the CSV file containing match links.\n",
    "        - gameweeks_file: Path to the CSV file containing gameweek data.\n",
    "        \"\"\"\n",
    "        self.filename = filename\n",
    "        self.links_file = links_file  # Store the path to the links file\n",
    "        self.gameweeks_file = gameweeks_file  # Store the path to the gameweeks file\n",
    "        self.soup = None  # Initialize BeautifulSoup object as None\n",
    "        self.teams_data = {}  # Dictionary to store team information\n",
    "\n",
    "    def fetch_page(self):\n",
    "        \"\"\"\n",
    "        Fetches the web page content from the provided URL and initializes BeautifulSoup.\n",
    "        Adds a delay to prevent overloading the server.\n",
    "        \"\"\"\n",
    "        headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:131.0) Gecko/20100101 Firefox/131.0\",\n",
    "            \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8\",\n",
    "            \"Accept-Language\": \"en-US,en;q=0.5\",\n",
    "            \"Accept-Encoding\": \"gzip, deflate, br\",\n",
    "            \"Connection\": \"keep-alive\",\n",
    "            \"Upgrade-Insecure-Requests\": \"1\",\n",
    "            \"DNT\": \"1\",\n",
    "        }\n",
    "        response = requests.get(self.link, headers=headers)\n",
    "\n",
    "        if response.status_code != 200:\n",
    "            raise Exception(f\"Error accessing the page: {response.status_code}\")\n",
    "\n",
    "        self.soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        time.sleep(6)\n",
    "\n",
    "    def extract_teams_ids(self):\n",
    "        \"\"\"\n",
    "        Extracts the IDs and names of the home and away teams using team logos.\n",
    "        \"\"\"\n",
    "        # Verifica que el link esté definido antes de intentar acceder a la página\n",
    "        if not hasattr(self, \"link\") or self.link is None:\n",
    "            raise Exception(\"Link not defined for the match.\")\n",
    "\n",
    "        self.fetch_page()  # Fetch the web page content for the provided URL\n",
    "\n",
    "        # Buscar las imágenes de los equipos\n",
    "        team_imgs = self.soup.find_all(\"img\", class_=\"teamlogo\", src=True)\n",
    "\n",
    "        # Verifica si se encontraron al menos dos imágenes de los equipos\n",
    "        if len(team_imgs) >= 2:\n",
    "            self.teams_data = {\n",
    "                \"home\": {\n",
    "                    \"id\": team_imgs[0][\"src\"].split(\"/\")[-1].split(\".\")[0],\n",
    "                    \"name\": team_imgs[0][\"alt\"]\n",
    "                    .replace(\" Club Crest\", \"\")\n",
    "                    .replace(\" \", \"_\"),\n",
    "                },\n",
    "                \"away\": {\n",
    "                    \"id\": team_imgs[1][\"src\"].split(\"/\")[-1].split(\".\")[0],\n",
    "                    \"name\": team_imgs[1][\"alt\"]\n",
    "                    .replace(\" Club Crest\", \"\")\n",
    "                    .replace(\" \", \"_\"),\n",
    "                },\n",
    "            }\n",
    "        else:\n",
    "            raise Exception(\n",
    "                \"Not enough team logos found. Expected at least two team logos.\"\n",
    "            )\n",
    "\n",
    "    def extract_players_table(\n",
    "        self, team_type, table_type, header_offset, columns_to_drop\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Extracts a specific player statistics table for the given team and table type.\n",
    "        - team_type: \"home\" or \"away\".\n",
    "        - table_type: Type of the table (e.g., \"summary\", \"passing\").\n",
    "        - header_offset: Number of header columns to skip.\n",
    "        - columns_to_drop: List of columns to drop from the table.\n",
    "        \"\"\"\n",
    "        # Get the team ID based on the team type (home or away)\n",
    "        team_id = self.teams_data[team_type][\"id\"]\n",
    "\n",
    "        # Construct the CSS selector for the specific table\n",
    "        players_table_selector = f\"#div_stats_{team_id}_{table_type}\"\n",
    "\n",
    "        # Select the table element using the constructed selector\n",
    "        table = self.soup.select_one(players_table_selector)\n",
    "\n",
    "        # Check if the table exists\n",
    "        if not table:\n",
    "            raise Exception(\n",
    "                f\"Payers table {table_type} not found for team {team_type}.\"\n",
    "            )\n",
    "\n",
    "        # Extract headers from the table, skipping the specified number of columns\n",
    "        headers = [th.text.strip() for th in table.find(\"thead\").find_all(\"th\")][\n",
    "            header_offset:\n",
    "        ]\n",
    "\n",
    "        # Extract rows of data from the table body\n",
    "        rows = [\n",
    "            [cell.text.strip() for cell in row.find_all([\"td\", \"th\"])]\n",
    "            for row in table.find(\"tbody\").find_all(\"tr\")\n",
    "        ]\n",
    "\n",
    "        # Create a DataFrame from the extracted rows and headers\n",
    "        df = pd.DataFrame(rows, columns=headers)\n",
    "\n",
    "        # Drop unnecessary columns specified in the columns_to_drop list\n",
    "        df = df.loc[:, ~df.columns.isin(columns_to_drop)]\n",
    "\n",
    "        return df\n",
    "\n",
    "        # Add a delay to avoid overloading the server\n",
    "        time.sleep(6)\n",
    "\n",
    "    def process_players_data(self, team_type):\n",
    "        \"\"\"\n",
    "        Processes all player statistics tables for a specific team (home or away).\n",
    "        Combines data from multiple table types into a dictionary of DataFrames.\n",
    "        \"\"\"\n",
    "        # Define columns to drop for each table type\n",
    "        columns_to_drop = {\n",
    "            \"summary\": [\n",
    "                \"Gls\",\n",
    "                \"Ass\",\n",
    "                \"TP\",\n",
    "                \"TPint\",\n",
    "                \"TA\",\n",
    "                \"TR\",\n",
    "                \"Toques\",\n",
    "                \"Tkl\",\n",
    "                \"Int\",\n",
    "                \"Bloqueos\",\n",
    "                \"xG\",\n",
    "                \"npxG\",\n",
    "                \"xAG\",\n",
    "                \"ACT\",\n",
    "                \"ACG\",\n",
    "                \"Cmp\",\n",
    "                \"Int.\",\n",
    "                \"% Cmp\",\n",
    "                \"PrgP\",\n",
    "                \"Transportes\",\n",
    "                \"PrgC\",\n",
    "                \"Att\",\n",
    "                \"Succ\",\n",
    "            ],\n",
    "            \"passing\": [\"Jugador\", \"núm.\", \"País\", \"Posc\", \"Edad\", \"Mín\"],\n",
    "            \"passing_types\": [\n",
    "                \"Jugador\",\n",
    "                \"núm.\",\n",
    "                \"País\",\n",
    "                \"Posc\",\n",
    "                \"Edad\",\n",
    "                \"Mín\",\n",
    "                \"Int.\",\n",
    "                \"Cmp\",\n",
    "            ],\n",
    "            \"defense\": [\"Jugador\", \"núm.\", \"País\", \"Posc\", \"Edad\", \"Mín\"],\n",
    "            \"possession\": [\n",
    "                \"Jugador\",\n",
    "                \"núm.\",\n",
    "                \"País\",\n",
    "                \"Posc\",\n",
    "                \"Edad\",\n",
    "                \"Mín\",\n",
    "                \"Tkld\",\n",
    "                \"Tkld%\",\n",
    "            ],\n",
    "            \"misc\": [\n",
    "                \"Jugador\",\n",
    "                \"núm.\",\n",
    "                \"País\",\n",
    "                \"Posc\",\n",
    "                \"Edad\",\n",
    "                \"Mín\",\n",
    "                \"Pcz\",\n",
    "                \"PA\",\n",
    "                \"Int\",\n",
    "                \"TklG\",\n",
    "                \"GC\",\n",
    "            ],\n",
    "        }\n",
    "\n",
    "        # Initialize an empty dictionary to store DataFrames for each table type\n",
    "        tables = {}\n",
    "\n",
    "        # Loop through each table type and extract its data\n",
    "        for table_type, header_offset in [\n",
    "            (\"summary\", 7),\n",
    "            (\"passing\", 9),\n",
    "            (\"passing_types\", 4),\n",
    "            (\"defense\", 5),\n",
    "            (\"possession\", 5),\n",
    "            (\"misc\", 3),\n",
    "        ]:\n",
    "            tables[table_type] = self.extract_players_table(\n",
    "                team_type,\n",
    "                table_type,\n",
    "                header_offset,\n",
    "                columns_to_drop.get(table_type, []),\n",
    "            )\n",
    "\n",
    "        return tables\n",
    "\n",
    "    def save_players_tables(self, match, season):\n",
    "        \"\"\"\n",
    "        Processes and saves player statistics tables for both home and away teams.\n",
    "        Combines data from all table types and writes the final table to a CSV file.\n",
    "        \"\"\"\n",
    "        # Extract IDs and names of the teams\n",
    "        self.extract_teams_ids()\n",
    "\n",
    "        # Process data for both home and away teams\n",
    "        for team_type in [\"home\", \"away\"]:\n",
    "            # Get the team name\n",
    "            team_name = self.teams_data[team_type][\"name\"]\n",
    "\n",
    "            # Extract and process all player statistics tables for the team\n",
    "            team_tables = self.process_players_data(team_type)\n",
    "\n",
    "            # Combine all extracted tables into a single DataFrame\n",
    "            final_table = pd.concat(team_tables.values(), axis=1)\n",
    "\n",
    "            # Define the new column names for the dataset with the team_type prefix\n",
    "            new_columns = [\n",
    "                f\"{team_type}_Players\",\n",
    "                f\"{team_type}_Number\",\n",
    "                f\"{team_type}_Nationality\",\n",
    "                f\"{team_type}_Position\",\n",
    "                f\"{team_type}_PlayersAge\",\n",
    "                f\"{team_type}_PlayersMinutes\",\n",
    "                f\"{team_type}_PlayersGoals\",\n",
    "                f\"{team_type}_PlayersShots\",\n",
    "                f\"{team_type}_PlayersShotsOnTarget\",\n",
    "                f\"{team_type}_PlayersCompletedPasses\",\n",
    "                f\"{team_type}_PlayersAttemptedPasses\",\n",
    "                f\"{team_type}_Players%CompletedPasses\",\n",
    "                f\"{team_type}_PlayersDistancePasses\",\n",
    "                f\"{team_type}_PlayersDistanceProgression\",\n",
    "                f\"{team_type}_PlayersShortPasses\",\n",
    "                f\"{team_type}_PlayersAttemptedShortPasses\",\n",
    "                f\"{team_type}_Players%ShortCompletedPasses\",\n",
    "                f\"{team_type}_PlayersMediumPasses\",\n",
    "                f\"{team_type}_PlayersAttemptedMediumPasses\",\n",
    "                f\"{team_type}_Players%MediumCompletedPasses\",\n",
    "                f\"{team_type}_PlayersLongPasses\",\n",
    "                f\"{team_type}_PlayersAttemptedLongPasses\",\n",
    "                f\"{team_type}_Players%LongCompletedPasses\",\n",
    "                f\"{team_type}_PlayersAssistance\",\n",
    "                f\"{team_type}_PlayersExpectedGoalsAssistance\",\n",
    "                f\"{team_type}_PlayersExpectedAssistance\",\n",
    "                f\"{team_type}_PlayersKeyPasses\",\n",
    "                f\"{team_type}_PlayersLast1/3Passes\",\n",
    "                f\"{team_type}_PlayersGoalAreaPasses\",\n",
    "                f\"{team_type}_PlayersGoalAreaCrosses\",\n",
    "                f\"{team_type}_PlayersGoalPasses\",\n",
    "                f\"{team_type}_PlayersLiveBallPasses\",\n",
    "                f\"{team_type}_PlayersDeadBallPasses\",\n",
    "                f\"{team_type}_PlayersFreeKick\",\n",
    "                f\"{team_type}_PlayersLongPasses\",\n",
    "                f\"{team_type}_PlayersSidePasses\",\n",
    "                f\"{team_type}_PlayersCrosses\",\n",
    "                f\"{team_type}_PlayersStrongcrosses\",\n",
    "                f\"{team_type}_PlayersCorner\",\n",
    "                f\"{team_type}_PlayersCornerIn\",\n",
    "                f\"{team_type}_PlayersCornerOut\",\n",
    "                f\"{team_type}_PlayersCornerRect\",\n",
    "                f\"{team_type}_PlayersOffsidePasses\",\n",
    "                f\"{team_type}_PlayersPassesBlocked\",\n",
    "                f\"{team_type}_PlayersTackles\",\n",
    "                f\"{team_type}_PlayersSuccessfulTackles\",\n",
    "                f\"{team_type}_PlayersTacklesInDefense\",\n",
    "                f\"{team_type}_PlayersTacklesInMedium\",\n",
    "                f\"{team_type}_PlayersTacklesInAttack\",\n",
    "                f\"{team_type}_PlayersDribblerTackles\",\n",
    "                f\"{team_type}_PlayersAttemptedDribblerTackles\",\n",
    "                f\"{team_type}_Players%DribblerTacklesCompleted\",\n",
    "                f\"{team_type}_PlayersDribblerTacklesNonCompleted\",\n",
    "                f\"{team_type}_PlayersBallsBlocked\",\n",
    "                f\"{team_type}_PlayersShotsBlocked\",\n",
    "                f\"{team_type}_PlayersPassesBlocked\",\n",
    "                f\"{team_type}_PlayersInterceptions\",\n",
    "                f\"{team_type}_PlayersTackles+Interceptions\",\n",
    "                f\"{team_type}_PlayersClearances\",\n",
    "                f\"{team_type}_PlayersMistakesRivalShots\",\n",
    "                f\"{team_type}_PlayersTouches\",\n",
    "                f\"{team_type}_PlayersOwnPenaltyAreaTouches\",\n",
    "                f\"{team_type}_PlayersTouchesInDefense\",\n",
    "                f\"{team_type}_PlayersTouchesInMedium\",\n",
    "                f\"{team_type}_PlayersTouchesInAttack\",\n",
    "                f\"{team_type}_PlayersAwayPenaltyAreaTouches\",\n",
    "                f\"{team_type}_PlayersLiveBallTouches\",\n",
    "                f\"{team_type}_PlayersAttemptedDribbles\",\n",
    "                f\"{team_type}_PlayersDribblesCompleted\",\n",
    "                f\"{team_type}_Players%DribblesCompleted\",\n",
    "                f\"{team_type}_PlayersBallCarries\",\n",
    "                f\"{team_type}_PlayersDistanceCarried\",\n",
    "                f\"{team_type}_PlayersForwardDistanceCarried\",\n",
    "                f\"{team_type}_PlayersForwardCarries\",\n",
    "                f\"{team_type}_PlayersCarriesInAttack\",\n",
    "                f\"{team_type}_PlayersAwayPenaltyAreaCarries\",\n",
    "                f\"{team_type}_PlayersLostControlCarries\",\n",
    "                f\"{team_type}_PlayersLostCarries\",\n",
    "                f\"{team_type}_PlayersPassesReception\",\n",
    "                f\"{team_type}_PlayersAttackPassesReception\",\n",
    "                f\"{team_type}_PlayersYellowCards\",\n",
    "                f\"{team_type}_PlayersRedCards\",\n",
    "                f\"{team_type}_PlayersSecondYellowCards\",\n",
    "                f\"{team_type}_PlayersFouls\",\n",
    "                f\"{team_type}_PlayersFoulsReceived\",\n",
    "                f\"{team_type}_PlayersPenalties\",\n",
    "                f\"{team_type}_PlayersPenaltiesConceded\",\n",
    "                f\"{team_type}_PlayersLostBallRecoveries\",\n",
    "                f\"{team_type}_PlayersAerialsWon\",\n",
    "                f\"{team_type}_PlayersAerialsLost\",\n",
    "                f\"{team_type}_Players%AerialsWon\",\n",
    "            ]\n",
    "\n",
    "            # Rename the columns of the DataFrame\n",
    "            final_table.columns = new_columns\n",
    "\n",
    "            # Convert the 'Age' column to integer by extracting the first two characters\n",
    "            final_table[f\"{team_type}_PlayersAge\"] = final_table[\n",
    "                f\"{team_type}_PlayersAge\"\n",
    "            ].apply(lambda x: int(x[:2]) if isinstance(x, str) else 0)\n",
    "\n",
    "            # Define columns to calculate the mean\n",
    "            columns_to_mean = [\n",
    "                f\"{team_type}_PlayersAge\",\n",
    "                f\"{team_type}_Players%CompletedPasses\",\n",
    "                f\"{team_type}_Players%ShortCompletedPasses\",\n",
    "                f\"{team_type}_Players%MediumCompletedPasses\",\n",
    "                f\"{team_type}_Players%LongCompletedPasses\",\n",
    "                f\"{team_type}_Players%DribblerTacklesCompleted\",\n",
    "                f\"{team_type}_Players%DribblesCompleted\",\n",
    "                f\"{team_type}_Players%AerialsWon\",\n",
    "            ]\n",
    "\n",
    "            # Define columns to calculate the sum\n",
    "            columns_to_sum = [\n",
    "                f\"{team_type}_PlayersMinutes\",\n",
    "                f\"{team_type}_PlayersGoals\",\n",
    "                f\"{team_type}_PlayersShots\",\n",
    "                f\"{team_type}_PlayersShotsOnTarget\",\n",
    "                f\"{team_type}_PlayersCompletedPasses\",\n",
    "                f\"{team_type}_PlayersAttemptedPasses\",\n",
    "                f\"{team_type}_PlayersDistancePasses\",\n",
    "                f\"{team_type}_PlayersDistanceProgression\",\n",
    "                f\"{team_type}_PlayersShortPasses\",\n",
    "                f\"{team_type}_PlayersAttemptedShortPasses\",\n",
    "                f\"{team_type}_PlayersMediumPasses\",\n",
    "                f\"{team_type}_PlayersAttemptedMediumPasses\",\n",
    "                f\"{team_type}_PlayersLongPasses\",\n",
    "                f\"{team_type}_PlayersAttemptedLongPasses\",\n",
    "                f\"{team_type}_PlayersAssistance\",\n",
    "                f\"{team_type}_PlayersExpectedGoalsAssistance\",\n",
    "                f\"{team_type}_PlayersExpectedAssistance\",\n",
    "                f\"{team_type}_PlayersKeyPasses\",\n",
    "                f\"{team_type}_PlayersLast1/3Passes\",\n",
    "                f\"{team_type}_PlayersGoalAreaPasses\",\n",
    "                f\"{team_type}_PlayersGoalAreaCrosses\",\n",
    "                f\"{team_type}_PlayersGoalPasses\",\n",
    "                f\"{team_type}_PlayersLiveBallPasses\",\n",
    "                f\"{team_type}_PlayersDeadBallPasses\",\n",
    "                f\"{team_type}_PlayersFreeKick\",\n",
    "                f\"{team_type}_PlayersLongPasses\",\n",
    "                f\"{team_type}_PlayersSidePasses\",\n",
    "                f\"{team_type}_PlayersCrosses\",\n",
    "                f\"{team_type}_PlayersStrongcrosses\",\n",
    "                f\"{team_type}_PlayersCorner\",\n",
    "                f\"{team_type}_PlayersCornerIn\",\n",
    "                f\"{team_type}_PlayersCornerOut\",\n",
    "                f\"{team_type}_PlayersCornerRect\",\n",
    "                f\"{team_type}_PlayersOffsidePasses\",\n",
    "                f\"{team_type}_PlayersPassesBlocked\",\n",
    "                f\"{team_type}_PlayersTackles\",\n",
    "                f\"{team_type}_PlayersSuccessfulTackles\",\n",
    "                f\"{team_type}_PlayersTacklesInDefense\",\n",
    "                f\"{team_type}_PlayersTacklesInMedium\",\n",
    "                f\"{team_type}_PlayersTacklesInAttack\",\n",
    "                f\"{team_type}_PlayersDribblerTackles\",\n",
    "                f\"{team_type}_PlayersAttemptedDribblerTackles\",\n",
    "                f\"{team_type}_PlayersDribblerTacklesNonCompleted\",\n",
    "                f\"{team_type}_PlayersBallsBlocked\",\n",
    "                f\"{team_type}_PlayersShotsBlocked\",\n",
    "                f\"{team_type}_PlayersPassesBlocked\",\n",
    "                f\"{team_type}_PlayersInterceptions\",\n",
    "                f\"{team_type}_PlayersTackles+Interceptions\",\n",
    "                f\"{team_type}_PlayersClearances\",\n",
    "                f\"{team_type}_PlayersMistakesRivalShots\",\n",
    "                f\"{team_type}_PlayersTouches\",\n",
    "                f\"{team_type}_PlayersOwnPenaltyAreaTouches\",\n",
    "                f\"{team_type}_PlayersTouchesInDefense\",\n",
    "                f\"{team_type}_PlayersTouchesInMedium\",\n",
    "                f\"{team_type}_PlayersTouchesInAttack\",\n",
    "                f\"{team_type}_PlayersAwayPenaltyAreaTouches\",\n",
    "                f\"{team_type}_PlayersLiveBallTouches\",\n",
    "                f\"{team_type}_PlayersAttemptedDribbles\",\n",
    "                f\"{team_type}_PlayersDribblesCompleted\",\n",
    "                f\"{team_type}_PlayersBallCarries\",\n",
    "                f\"{team_type}_PlayersDistanceCarried\",\n",
    "                f\"{team_type}_PlayersForwardDistanceCarried\",\n",
    "                f\"{team_type}_PlayersForwardCarries\",\n",
    "                f\"{team_type}_PlayersCarriesInAttack\",\n",
    "                f\"{team_type}_PlayersAwayPenaltyAreaCarries\",\n",
    "                f\"{team_type}_PlayersLostControlCarries\",\n",
    "                f\"{team_type}_PlayersLostCarries\",\n",
    "                f\"{team_type}_PlayersPassesReception\",\n",
    "                f\"{team_type}_PlayersAttackPassesReception\",\n",
    "                f\"{team_type}_PlayersYellowCards\",\n",
    "                f\"{team_type}_PlayersRedCards\",\n",
    "                f\"{team_type}_PlayersSecondYellowCards\",\n",
    "                f\"{team_type}_PlayersFouls\",\n",
    "                f\"{team_type}_PlayersFoulsReceived\",\n",
    "                f\"{team_type}_PlayersPenalties\",\n",
    "                f\"{team_type}_PlayersPenaltiesConceded\",\n",
    "                f\"{team_type}_PlayersLostBallRecoveries\",\n",
    "                f\"{team_type}_PlayersAerialsWon\",\n",
    "                f\"{team_type}_PlayersAerialsLost\",\n",
    "            ]\n",
    "\n",
    "            # Convert the mean columns to numeric\n",
    "            for col in columns_to_mean:\n",
    "                final_table[col] = final_table[col].apply(\n",
    "                    pd.to_numeric, errors=\"coerce\"\n",
    "                )\n",
    "\n",
    "            # Convert the sum columns to numeric\n",
    "            for col in columns_to_sum:\n",
    "                final_table[col] = final_table[col].apply(\n",
    "                    pd.to_numeric, errors=\"coerce\"\n",
    "                )\n",
    "\n",
    "            # Calculate the mean and sum for specified columns\n",
    "            mean_values = final_table[columns_to_mean].mean()\n",
    "            sum_values = final_table[columns_to_sum].sum()\n",
    "\n",
    "            # Create a new row for totals with placeholder values\n",
    "            total_row = {col: \"-\" for col in final_table.columns}\n",
    "\n",
    "            # Populate the total row with mean values\n",
    "            for col, mean in mean_values.items():\n",
    "                total_row[col] = mean\n",
    "\n",
    "            # Populate the total row with sum values\n",
    "            for col, total in sum_values.items():\n",
    "                total_row[col] = total\n",
    "\n",
    "            # Add the number of rows (lines) to the first column of the total row\n",
    "            num_lines = len(final_table)\n",
    "            total_row[final_table.columns[0]] = num_lines\n",
    "\n",
    "            # Check if the 'id' column exists, if not, create it with NaN values\n",
    "            if \"id\" not in final_table.columns:\n",
    "                final_table[\"id\"] = np.nan  # Create the column with NaN values\n",
    "\n",
    "            # Add the match ID to the total row\n",
    "            total_row[\"id\"] = match\n",
    "\n",
    "            # Append the total row to the DataFrame\n",
    "            final_table.loc[len(final_table)] = total_row\n",
    "\n",
    "            # Define the columns to append to the existing CSV\n",
    "            columns_to_append = [\n",
    "                f\"{team_type}_Players\",\n",
    "                f\"{team_type}_PlayersAge\",\n",
    "                f\"{team_type}_PlayersMinutes\",\n",
    "                f\"{team_type}_PlayersShots\",\n",
    "                f\"{team_type}_PlayersShotsOnTarget\",\n",
    "                f\"{team_type}_PlayersCompletedPasses\",\n",
    "                f\"{team_type}_PlayersAttemptedPasses\",\n",
    "                f\"{team_type}_Players%CompletedPasses\",\n",
    "                f\"{team_type}_PlayersDistancePasses\",\n",
    "                f\"{team_type}_PlayersDistanceProgression\",\n",
    "                f\"{team_type}_PlayersShortPasses\",\n",
    "                f\"{team_type}_PlayersAttemptedShortPasses\",\n",
    "                f\"{team_type}_Players%ShortCompletedPasses\",\n",
    "                f\"{team_type}_PlayersMediumPasses\",\n",
    "                f\"{team_type}_PlayersAttemptedMediumPasses\",\n",
    "                f\"{team_type}_Players%MediumCompletedPasses\",\n",
    "                f\"{team_type}_PlayersLongPasses\",\n",
    "                f\"{team_type}_PlayersAttemptedLongPasses\",\n",
    "                f\"{team_type}_Players%LongCompletedPasses\",\n",
    "                f\"{team_type}_PlayersAssistance\",\n",
    "                f\"{team_type}_PlayersExpectedGoalsAssistance\",\n",
    "                f\"{team_type}_PlayersExpectedAssistance\",\n",
    "                f\"{team_type}_PlayersKeyPasses\",\n",
    "                f\"{team_type}_PlayersLast1/3Passes\",\n",
    "                f\"{team_type}_PlayersGoalAreaPasses\",\n",
    "                f\"{team_type}_PlayersGoalAreaCrosses\",\n",
    "                f\"{team_type}_PlayersGoalPasses\",\n",
    "                f\"{team_type}_PlayersLiveBallPasses\",\n",
    "                f\"{team_type}_PlayersDeadBallPasses\",\n",
    "                f\"{team_type}_PlayersFreeKick\",\n",
    "                f\"{team_type}_PlayersLongPasses\",\n",
    "                f\"{team_type}_PlayersSidePasses\",\n",
    "                f\"{team_type}_PlayersCrosses\",\n",
    "                f\"{team_type}_PlayersStrongcrosses\",\n",
    "                f\"{team_type}_PlayersCorner\",\n",
    "                f\"{team_type}_PlayersCornerIn\",\n",
    "                f\"{team_type}_PlayersCornerOut\",\n",
    "                f\"{team_type}_PlayersCornerRect\",\n",
    "                f\"{team_type}_PlayersOffsidePasses\",\n",
    "                f\"{team_type}_PlayersPassesBlocked\",\n",
    "                f\"{team_type}_PlayersTackles\",\n",
    "                f\"{team_type}_PlayersSuccessfulTackles\",\n",
    "                f\"{team_type}_PlayersTacklesInDefense\",\n",
    "                f\"{team_type}_PlayersTacklesInMedium\",\n",
    "                f\"{team_type}_PlayersTacklesInAttack\",\n",
    "                f\"{team_type}_PlayersDribblerTackles\",\n",
    "                f\"{team_type}_PlayersAttemptedDribblerTackles\",\n",
    "                f\"{team_type}_Players%DribblerTacklesCompleted\",\n",
    "                f\"{team_type}_PlayersDribblerTacklesNonCompleted\",\n",
    "                f\"{team_type}_PlayersBallsBlocked\",\n",
    "                f\"{team_type}_PlayersShotsBlocked\",\n",
    "                f\"{team_type}_PlayersPassesBlocked\",\n",
    "                f\"{team_type}_PlayersInterceptions\",\n",
    "                f\"{team_type}_PlayersTackles+Interceptions\",\n",
    "                f\"{team_type}_PlayersClearances\",\n",
    "                f\"{team_type}_PlayersMistakesRivalShots\",\n",
    "                f\"{team_type}_PlayersTouches\",\n",
    "                f\"{team_type}_PlayersOwnPenaltyAreaTouches\",\n",
    "                f\"{team_type}_PlayersTouchesInDefense\",\n",
    "                f\"{team_type}_PlayersTouchesInMedium\",\n",
    "                f\"{team_type}_PlayersTouchesInAttack\",\n",
    "                f\"{team_type}_PlayersAwayPenaltyAreaTouches\",\n",
    "                f\"{team_type}_PlayersLiveBallTouches\",\n",
    "                f\"{team_type}_PlayersAttemptedDribbles\",\n",
    "                f\"{team_type}_PlayersDribblesCompleted\",\n",
    "                f\"{team_type}_Players%DribblesCompleted\",\n",
    "                f\"{team_type}_PlayersBallCarries\",\n",
    "                f\"{team_type}_PlayersDistanceCarried\",\n",
    "                f\"{team_type}_PlayersForwardDistanceCarried\",\n",
    "                f\"{team_type}_PlayersForwardCarries\",\n",
    "                f\"{team_type}_PlayersCarriesInAttack\",\n",
    "                f\"{team_type}_PlayersAwayPenaltyAreaCarries\",\n",
    "                f\"{team_type}_PlayersLostControlCarries\",\n",
    "                f\"{team_type}_PlayersLostCarries\",\n",
    "                f\"{team_type}_PlayersPassesReception\",\n",
    "                f\"{team_type}_PlayersAttackPassesReception\",\n",
    "                f\"{team_type}_PlayersYellowCards\",\n",
    "                f\"{team_type}_PlayersRedCards\",\n",
    "                f\"{team_type}_PlayersSecondYellowCards\",\n",
    "                f\"{team_type}_PlayersFouls\",\n",
    "                f\"{team_type}_PlayersFoulsReceived\",\n",
    "                f\"{team_type}_PlayersPenalties\",\n",
    "                f\"{team_type}_PlayersPenaltiesConceded\",\n",
    "                f\"{team_type}_PlayersLostBallRecoveries\",\n",
    "                f\"{team_type}_PlayersAerialsWon\",\n",
    "                f\"{team_type}_PlayersAerialsLost\",\n",
    "                f\"{team_type}_Players%AerialsWon\",\n",
    "            ]\n",
    "\n",
    "            # Extract the last row from final_table (this contains the sums and means)\n",
    "            last_row = final_table.iloc[-1][columns_to_append]\n",
    "\n",
    "            # Define the filename for the current season\n",
    "            filename = f\"matches_{season}.csv\"\n",
    "\n",
    "            # Load the existing CSV file from the parent directory\n",
    "            existing_df = pd.read_csv(filename)\n",
    "\n",
    "            # Get the ID from the last row of final_table\n",
    "            last_row_id = final_table.iloc[-1][\"id\"]\n",
    "\n",
    "            # Find the row in the existing CSV based on the ID\n",
    "            row_index = existing_df[existing_df[\"id\"] == last_row_id].index\n",
    "\n",
    "            # Check if the row exists\n",
    "            if row_index.empty:\n",
    "                raise ValueError(\n",
    "                    f\"Error: No row with ID {last_row_id} found in {filename}\"\n",
    "                )\n",
    "\n",
    "            # Check if the columns exist in the existing CSV, if not, create them after the existing columns\n",
    "            for column in columns_to_append:\n",
    "                if column not in existing_df.columns:\n",
    "                    existing_df[column] = pd.NA  # Create the column with missing values\n",
    "\n",
    "            # Ensure the new columns are placed after the existing columns\n",
    "            existing_columns = existing_df.columns.tolist()\n",
    "            new_columns = [\n",
    "                column for column in columns_to_append if column not in existing_columns\n",
    "            ]\n",
    "            existing_df = existing_df[existing_columns + new_columns]\n",
    "\n",
    "            # Update the row with the new data from last_row\n",
    "            for column, value in last_row.items():\n",
    "                existing_df.at[row_index[0], column] = value\n",
    "\n",
    "            # Save the updated DataFrame back to the CSV\n",
    "            existing_df.to_csv(filename, index=False)\n",
    "\n",
    "            time.sleep(6)  # Sleep to avoid making too many requests in a short time\n",
    "\n",
    "    def extract_keeper_table(self, team_type, header_offset):\n",
    "        \"\"\"\n",
    "        Extracts a specific keeper statistics table for the given team.\n",
    "        - team_type: \"home\" or \"away\".\n",
    "        - header_offset: Number of header columns to skip.\n",
    "        \"\"\"\n",
    "        # Get the team ID based on the team type (home or away)\n",
    "        team_id = self.teams_data[team_type][\"id\"]\n",
    "\n",
    "        # Construct the CSS selector for the specific table\n",
    "        keeper_table_selector = f\"#keeper_stats_{team_id}\"\n",
    "\n",
    "        # Select the table element using the constructed selector\n",
    "        table = self.soup.select_one(keeper_table_selector)\n",
    "\n",
    "        # Check if the table exists\n",
    "        if not table:\n",
    "            raise Exception(f\"Keeper table not found for team {team_type}.\")\n",
    "\n",
    "        # Extract headers from the table, skipping the specified number of columns\n",
    "        headers = [th.text.strip() for th in table.find(\"thead\").find_all(\"th\")][\n",
    "            header_offset:\n",
    "        ]\n",
    "\n",
    "        # Extract rows of data from the table body\n",
    "        rows = [\n",
    "            [cell.text.strip() for cell in row.find_all([\"td\", \"th\"])]\n",
    "            for row in table.find(\"tbody\").find_all(\"tr\")\n",
    "        ]\n",
    "\n",
    "        # Create a DataFrame from the extracted rows and headers\n",
    "        df = pd.DataFrame(rows, columns=headers)\n",
    "\n",
    "        return df\n",
    "\n",
    "        # Add a delay to avoid overloading the server\n",
    "        time.sleep(6)\n",
    "\n",
    "    def process_keeper_data(self, team_type):\n",
    "        \"\"\"\n",
    "        Processes all keeper statistics tables for a specific team (home or away).\n",
    "        Combines data into a dictionary of DataFrames.\n",
    "        \"\"\"\n",
    "        # Extract data from the keeper statistics table\n",
    "        table = self.extract_keeper_table(team_type, header_offset=7)\n",
    "\n",
    "        return table\n",
    "\n",
    "    def save_keeper_tables(self, match, season):\n",
    "        \"\"\"\n",
    "        Processes and saves keeper statistics table for both home and away teams.\n",
    "        Writes the final table to a CSV file.\n",
    "        \"\"\"\n",
    "        # Extract IDs and names of the teams\n",
    "        self.extract_teams_ids()\n",
    "\n",
    "        # Process data for both home and away teams\n",
    "        for team_type in [\"home\", \"away\"]:\n",
    "            # Get the team name\n",
    "            team_name = self.teams_data[team_type][\"name\"]\n",
    "\n",
    "            # Extract and process all keeper statistics tables for the team\n",
    "            final_table = self.process_keeper_data(team_type)\n",
    "\n",
    "            # Define the new column names for the dataset\n",
    "            new_columns = [\n",
    "                f\"{team_type}_KeepersKeepers\",\n",
    "                f\"{team_type}_KeepersNationality\",\n",
    "                f\"{team_type}_KeepersAge\",\n",
    "                f\"{team_type}_KeepersMinutes\",\n",
    "                f\"{team_type}_KeepersShotsOnTargetAgainst\",\n",
    "                f\"{team_type}_KeepersGoalsAgainst\",\n",
    "                f\"{team_type}_KeepersSaved\",\n",
    "                f\"{team_type}_Keepers%Saved\",\n",
    "                f\"{team_type}_KeepersxG\",\n",
    "                f\"{team_type}_KeepersPassesLaunched\",\n",
    "                f\"{team_type}_KeepersAttemptedPassesLaunched\",\n",
    "                f\"{team_type}_Keepers%CompletedPassesLaunched\",\n",
    "                f\"{team_type}_KeepersPasses\",\n",
    "                f\"{team_type}_KeepersAttemptedPasses\",\n",
    "                f\"{team_type}_Keepers%CompletedPasses\",\n",
    "                f\"{team_type}_KeepersPassesDistance\",\n",
    "                f\"{team_type}_KeepersAttemptedKicks\",\n",
    "                f\"{team_type}_Keepers%Kicks\",\n",
    "                f\"{team_type}_KeepersKicksDistance\",\n",
    "                f\"{team_type}_KeepersCrosses\",\n",
    "                f\"{team_type}_KeepersCrossesStopped\",\n",
    "                f\"{team_type}_Keepers%CrossesStopped\",\n",
    "                f\"{team_type}_KeepersActionsOutsideArea\",\n",
    "                f\"{team_type}_KeepersDistanceActionsArea\",\n",
    "            ]\n",
    "\n",
    "            # Rename the columns of the DataFrame\n",
    "            final_table.columns = new_columns\n",
    "\n",
    "            # Convert the 'Age' column to integer by extracting the first two characters\n",
    "            final_table[f\"{team_type}_KeepersAge\"] = final_table[\n",
    "                f\"{team_type}_KeepersAge\"\n",
    "            ].apply(lambda x: int(x[:2]) if isinstance(x, str) else 0)\n",
    "\n",
    "            # Define columns to calculate the mean\n",
    "            columns_to_mean = [\n",
    "                f\"{team_type}_KeepersAge\",\n",
    "                f\"{team_type}_Keepers%Saved\",\n",
    "                f\"{team_type}_Keepers%CompletedPassesLaunched\",\n",
    "                f\"{team_type}_Keepers%CompletedPasses\",\n",
    "                f\"{team_type}_KeepersPassesDistance\",\n",
    "                f\"{team_type}_Keepers%Kicks\",\n",
    "                f\"{team_type}_KeepersKicksDistance\",\n",
    "                f\"{team_type}_Keepers%CrossesStopped\",\n",
    "                f\"{team_type}_KeepersDistanceActionsArea\",\n",
    "            ]\n",
    "\n",
    "            # Define columns to calculate the sum\n",
    "            columns_to_sum = [\n",
    "                f\"{team_type}_KeepersKeepers\",\n",
    "                f\"{team_type}_KeepersMinutes\",\n",
    "                f\"{team_type}_KeepersShotsOnTargetAgainst\",\n",
    "                f\"{team_type}_KeepersGoalsAgainst\",\n",
    "                f\"{team_type}_KeepersSaved\",\n",
    "                f\"{team_type}_KeepersxG\",\n",
    "                f\"{team_type}_KeepersPassesLaunched\",\n",
    "                f\"{team_type}_KeepersAttemptedPassesLaunched\",\n",
    "                f\"{team_type}_KeepersPasses\",\n",
    "                f\"{team_type}_KeepersAttemptedPasses\",\n",
    "                f\"{team_type}_KeepersAttemptedKicks\",\n",
    "                f\"{team_type}_KeepersCrosses\",\n",
    "                f\"{team_type}_KeepersCrossesStopped\",\n",
    "                f\"{team_type}_KeepersActionsOutsideArea\",\n",
    "            ]\n",
    "\n",
    "            # Convert the mean columns to numeric\n",
    "            for col in columns_to_mean:\n",
    "                final_table[col] = final_table[col].apply(\n",
    "                    pd.to_numeric, errors=\"coerce\"\n",
    "                )\n",
    "\n",
    "            # Convert the sum columns to numeric\n",
    "            for col in columns_to_sum:\n",
    "                final_table[col] = final_table[col].apply(\n",
    "                    pd.to_numeric, errors=\"coerce\"\n",
    "                )\n",
    "\n",
    "            # Calculate the mean and sum for specified columns\n",
    "            mean_values = final_table[columns_to_mean].mean()\n",
    "            sum_values = final_table[columns_to_sum].sum()\n",
    "\n",
    "            # Create a new row for totals with placeholder values\n",
    "            total_row = {col: \"-\" for col in final_table.columns}\n",
    "\n",
    "            # Populate the total row with mean values\n",
    "            for col, mean in mean_values.items():\n",
    "                total_row[col] = mean\n",
    "\n",
    "            # Populate the total row with sum values\n",
    "            for col, total in sum_values.items():\n",
    "                total_row[col] = total\n",
    "\n",
    "            # Add the number of rows (lines) to the first column of the total row\n",
    "            num_lines = len(final_table)\n",
    "            total_row[final_table.columns[0]] = num_lines\n",
    "\n",
    "            # Check if the 'id' column exists, if not, create it with NaN values\n",
    "            if \"id\" not in final_table.columns:\n",
    "                final_table[\"id\"] = np.nan  # Create the column with NaN values\n",
    "\n",
    "            # Add the match ID to the total row\n",
    "            total_row[\"id\"] = match\n",
    "\n",
    "            # Append the total row to the DataFrame\n",
    "            final_table.loc[len(final_table)] = total_row\n",
    "\n",
    "            # Define the columns to append to the existing CSV\n",
    "            columns_to_append = [\n",
    "                f\"{team_type}_KeepersKeepers\",\n",
    "                f\"{team_type}_KeepersMinutes\",\n",
    "                f\"{team_type}_KeepersShotsOnTargetAgainst\",\n",
    "                f\"{team_type}_KeepersGoalsAgainst\",\n",
    "                f\"{team_type}_KeepersSaved\",\n",
    "                f\"{team_type}_Keepers%Saved\",\n",
    "                f\"{team_type}_KeepersxG\",\n",
    "                f\"{team_type}_KeepersPassesLaunched\",\n",
    "                f\"{team_type}_KeepersAttemptedPassesLaunched\",\n",
    "                f\"{team_type}_Keepers%CompletedPassesLaunched\",\n",
    "                f\"{team_type}_KeepersPasses\",\n",
    "                f\"{team_type}_KeepersAttemptedPasses\",\n",
    "                f\"{team_type}_Keepers%CompletedPasses\",\n",
    "                f\"{team_type}_KeepersPassesDistance\",\n",
    "                f\"{team_type}_KeepersAttemptedKicks\",\n",
    "                f\"{team_type}_Keepers%Kicks\",\n",
    "                f\"{team_type}_KeepersKicksDistance\",\n",
    "                f\"{team_type}_KeepersCrosses\",\n",
    "                f\"{team_type}_KeepersCrossesStopped\",\n",
    "                f\"{team_type}_Keepers%CrossesStopped\",\n",
    "                f\"{team_type}_KeepersActionsOutsideArea\",\n",
    "                f\"{team_type}_KeepersDistanceActionsArea\",\n",
    "            ]\n",
    "\n",
    "            # Extract the last row from final_table (this contains the sums and means)\n",
    "            last_row = final_table.iloc[-1][columns_to_append]\n",
    "\n",
    "            # Define the filename for the current season\n",
    "            filename = f\"matches_{season}.csv\"\n",
    "\n",
    "            # Load the existing CSV file from the parent directory\n",
    "            existing_df = pd.read_csv(filename)\n",
    "\n",
    "            # Get the ID from the last row of final_table\n",
    "            last_row_id = final_table.iloc[-1][\"id\"]\n",
    "\n",
    "            # Find the row in the existing CSV based on the ID\n",
    "            row_index = existing_df[existing_df[\"id\"] == last_row_id].index\n",
    "\n",
    "            # Check if the row exists\n",
    "            if row_index.empty:\n",
    "                raise ValueError(\n",
    "                    f\"Error: No row with ID {last_row_id} found in {filename}\"\n",
    "                )\n",
    "\n",
    "            # Check if the columns exist in the existing CSV, if not, create them after the existing columns\n",
    "            for column in columns_to_append:\n",
    "                if column not in existing_df.columns:\n",
    "                    existing_df[column] = pd.NA  # Create the column with missing values\n",
    "\n",
    "            # Ensure the new columns are placed after the existing columns\n",
    "            existing_columns = existing_df.columns.tolist()\n",
    "            new_columns = [\n",
    "                column for column in columns_to_append if column not in existing_columns\n",
    "            ]\n",
    "            existing_df = existing_df[existing_columns + new_columns]\n",
    "\n",
    "            # Update the row with the new data from last_row\n",
    "            for column, value in last_row.items():\n",
    "                existing_df.at[row_index[0], column] = value\n",
    "\n",
    "            # Save the updated DataFrame back to the CSV\n",
    "            existing_df.to_csv(filename, index=False)\n",
    "\n",
    "            time.sleep(6)  # Sleep to avoid making too many requests in a short time\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Processes multiple gameweek URLs by reading from a file of links and gameweeks.\n",
    "        For each URL, extracts and saves player and keeper statistics tables.\n",
    "        \"\"\"\n",
    "        print(f\"Starting collecting players data...\")\n",
    "\n",
    "        # Read the links and gameweeks from CSV files\n",
    "        links_df = pd.read_csv(self.links_file)\n",
    "        gameweeks_df = pd.read_csv(self.gameweeks_file)\n",
    "\n",
    "        # Extract the season from the filename\n",
    "        season_match = re.search(r\"(\\d{4})-(\\d{4})\", self.filename)\n",
    "        if season_match:\n",
    "            season = season_match.group(0)\n",
    "        else:\n",
    "            season = \"unknown_season\"  # Default value if the season cannot be extracted\n",
    "\n",
    "        # Initialize match as an integer\n",
    "        match = 1  # Start match numbering from 1\n",
    "\n",
    "        # Loop through each link and its corresponding gameweek\n",
    "        for index in range(len(links_df)):\n",
    "            link = links_df.iloc[index][\"link\"]\n",
    "            gameweek = gameweeks_df.iloc[index][\"gameweek\"]\n",
    "\n",
    "            print(f\"Processing match {index + 1}: {link}\")\n",
    "\n",
    "            # Set the current link and gameweek for the instance\n",
    "            self.link = link\n",
    "            self.gameweek = gameweek\n",
    "\n",
    "            # Extract team data for the current match\n",
    "            self.extract_teams_ids()\n",
    "\n",
    "            # Extract and save the player statistics table for the current match\n",
    "            self.save_players_tables(match, season)\n",
    "\n",
    "            # Extract and save the keeper statistics table for the current match\n",
    "            self.save_keeper_tables(match, season)\n",
    "\n",
    "            # Increment the match counter\n",
    "            match += 1\n",
    "\n",
    "            time.sleep(6)  # Sleep to avoid making too many requests in a short time\n",
    "\n",
    "        print(f\"Collecting players data process completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FootballRanking:\n",
    "    def __init__(self, input_file, output_file):\n",
    "        self.input_file = input_file\n",
    "        self.output_file = output_file\n",
    "        self.df = pd.read_csv(input_file)  # Read the CSV file\n",
    "        self.team_stats = {}  # Stores points, goals for, goals against, matches played, and card counts\n",
    "\n",
    "    def update_team_stats(self, home_team, away_team, home_goals, away_goals, \n",
    "                      home_yellow_cards, home_red_cards, home_second_yellow_cards,\n",
    "                      away_yellow_cards, away_red_cards, away_second_yellow_cards):\n",
    "        \"\"\"Update the stats for both teams after a match.\"\"\"\n",
    "        \n",
    "        # Initialize stats if they don't exist for home team\n",
    "        if home_team not in self.team_stats:\n",
    "            self.team_stats[home_team] = {\n",
    "                \"points\": 0, \"goals_for\": 0, \"goals_against\": 0, \n",
    "                \"matches_played\": 0, \"yellow_cards\": 0, \"red_cards\": 0, \n",
    "                \"second_yellow_cards\": 0\n",
    "            }\n",
    "\n",
    "        # Initialize stats if they don't exist for away team\n",
    "        if away_team not in self.team_stats:\n",
    "            self.team_stats[away_team] = {\n",
    "                \"points\": 0, \"goals_for\": 0, \"goals_against\": 0, \n",
    "                \"matches_played\": 0, \"yellow_cards\": 0, \"red_cards\": 0, \n",
    "                \"second_yellow_cards\": 0\n",
    "            }\n",
    "        \n",
    "        # Calculate points based on the match result\n",
    "        if home_goals > away_goals:  # Home team wins\n",
    "            home_points = 3\n",
    "            away_points = 0\n",
    "        elif home_goals < away_goals:  # Away team wins\n",
    "            home_points = 0\n",
    "            away_points = 3\n",
    "        else:  # Draw\n",
    "            home_points = 1\n",
    "            away_points = 1\n",
    "        \n",
    "        # Update stats for home team\n",
    "        self.team_stats[home_team][\"points\"] += home_points\n",
    "        self.team_stats[home_team][\"goals_for\"] += home_goals\n",
    "        self.team_stats[home_team][\"goals_against\"] += away_goals\n",
    "        self.team_stats[home_team][\"yellow_cards\"] += home_yellow_cards\n",
    "        self.team_stats[home_team][\"red_cards\"] += home_red_cards\n",
    "        self.team_stats[home_team][\"second_yellow_cards\"] += home_second_yellow_cards\n",
    "        self.team_stats[home_team][\"matches_played\"] += 1\n",
    "        \n",
    "        # Update stats for away team\n",
    "        self.team_stats[away_team][\"points\"] += away_points\n",
    "        self.team_stats[away_team][\"goals_for\"] += away_goals\n",
    "        self.team_stats[away_team][\"goals_against\"] += home_goals\n",
    "        self.team_stats[away_team][\"yellow_cards\"] += away_yellow_cards\n",
    "        self.team_stats[away_team][\"red_cards\"] += away_red_cards\n",
    "        self.team_stats[away_team][\"second_yellow_cards\"] += away_second_yellow_cards\n",
    "        self.team_stats[away_team][\"matches_played\"] += 1\n",
    "\n",
    "    def reorder_teams_by_new_order(self, sorted_teams, new_order):\n",
    "        \"\"\"\n",
    "        Reorders the teams in sorted_teams based on the order provided in new_order,\n",
    "        while keeping the overall ranking intact.\n",
    "        \n",
    "        Parameters:\n",
    "        - sorted_teams: List of dictionaries, where each dictionary contains team data.\n",
    "        - new_order: List of tuples with team names and their respective values (e.g., [('Team A', 0), ('Team B', 0)]).\n",
    "\n",
    "        Returns:\n",
    "        - List of dictionaries with teams ordered based on new_order while keeping the rest of the teams in their original order.\n",
    "        \"\"\"\n",
    "        # Extraer solo los nombres de los equipos de la lista de tuplas\n",
    "        new_order_teams = [team[0] for team in new_order]\n",
    "\n",
    "        # Crear un diccionario con los equipos en sorted_teams para facilitar la búsqueda\n",
    "        team_dict = {team['team']: team for team in sorted_teams}\n",
    "\n",
    "        # Filtrar los equipos que están en el nuevo orden, preservando su estructura original\n",
    "        reordered_block = [team_dict[team_name] for team_name in new_order_teams if team_name in team_dict]\n",
    "\n",
    "        # Crear una nueva lista respetando la estructura de sorted_teams\n",
    "        final_sorted_teams = []\n",
    "        inserted = False\n",
    "\n",
    "        for team in sorted_teams:\n",
    "            if team['team'] in new_order_teams and not inserted:\n",
    "                # Insertar el grupo reordenado en la posición correcta\n",
    "                final_sorted_teams.extend(reordered_block)\n",
    "                inserted = True  # Evitar insertar más de una vez\n",
    "            elif team['team'] not in new_order_teams:\n",
    "                # Mantener los equipos que no estaban en el nuevo orden\n",
    "                final_sorted_teams.append(team)\n",
    "\n",
    "        return final_sorted_teams\n",
    "\n",
    "    def check_tiebreaker_type(self, sorted_teams, current_gameweek, index):\n",
    "        # 1. Agrupar equipos por puntos\n",
    "        points_groups = {}\n",
    "        for team_stats in sorted_teams:\n",
    "            points = team_stats[\"points\"]\n",
    "            if points not in points_groups:\n",
    "                points_groups[points] = []\n",
    "            points_groups[points].append(team_stats)  # Guardar en formato {equipo: estadísticas}\n",
    "\n",
    "        # 2. Filtrar solo los grupos con más de un equipo (es decir, los empates)\n",
    "        tied_groups = {points: teams for points, teams in points_groups.items() if len(teams) > 1}\n",
    "\n",
    "        # 3. Reordenar los grupos de equipos empatados según criterios de desempate\n",
    "        for points, teams_list in tied_groups.items():\n",
    "            if len(teams_list) == 2:\n",
    "                # Desempatar entre dos equipos\n",
    "                sorted_teams = self.apply_tiebreaker_two_teams(sorted_teams, current_gameweek, index, teams_list, points)\n",
    "            elif len(teams_list) >= 3:\n",
    "                # Desempatar entre tres o más equipos\n",
    "                sorted_teams = self.apply_tiebreaker_multiple_teams(sorted_teams, current_gameweek, index, teams_list, points)\n",
    "\n",
    "        return sorted_teams\n",
    "\n",
    "    def apply_tiebreaker_two_teams(self, sorted_teams, gameweek, match_id, teams_list, points):\n",
    "        if len(teams_list) != 2:\n",
    "            raise ValueError(\"apply_tiebreaker_two_teams must receive exactly two teams.\")\n",
    "\n",
    "        team1 = teams_list[0][\"team\"]\n",
    "        team2 = teams_list[1][\"team\"]\n",
    "\n",
    "        print(f\"\\nChecking tiebreaker for teams: {team1} vs {team2} (Points: {points}. Gameweek: {gameweek}. Match id: {match_id})\")\n",
    "\n",
    "        # Buscar partidos entre team1 y team2 hasta el partido actual (match_id)\n",
    "        total_goals_team1 = 0\n",
    "        total_goals_team2 = 0\n",
    "\n",
    "        # Filtrar el CSV para obtener los partidos entre los dos equipos previos a este match_id\n",
    "        for index, row in self.df.loc[:match_id-1].iterrows():  # Iterar desde el inicio hasta el id anterior\n",
    "            home_team = row[\"home_team_name\"]\n",
    "            away_team = row[\"away_team_name\"]\n",
    "            home_goals = row[\"home_team_goals\"]\n",
    "            away_goals = row[\"away_team_goals\"]\n",
    "\n",
    "            # Verificar si el partido es entre los dos equipos\n",
    "            if (home_team == team1 and away_team == team2) or (home_team == team2 and away_team == team1):\n",
    "                print(f\"Found match: {home_team} vs {away_team} (Home goals: {home_goals}, Away goals: {away_goals})\")\n",
    "\n",
    "                if home_team == team1:  # Si team1 es el equipo local\n",
    "                    total_goals_team1 += home_goals\n",
    "                    total_goals_team2 += away_goals\n",
    "                else:  # Si team2 es el equipo local\n",
    "                    total_goals_team1 += away_goals\n",
    "                    total_goals_team2 += home_goals\n",
    "\n",
    "        # Mostrar los goles totales marcados en los enfrentamientos directos\n",
    "        print(f\"Total goals in direct encounters: {team1}: {total_goals_team1}, {team2}: {total_goals_team2}\")\n",
    "\n",
    "        # Si no están empatados en goles en enfrentamientos directos, aplicar el desempate basado en los goles marcados en enfrentamientos directos\n",
    "        if total_goals_team1 > total_goals_team2:\n",
    "            print(f\"{team1} has more goals in direct encounters. Moving {team1} up.\")\n",
    "            # Verificar si están en el orden correcto\n",
    "            rank_team1 = sorted_teams.index(next(team for team in sorted_teams if team['team'] == team1))\n",
    "            rank_team2 = sorted_teams.index(next(team for team in sorted_teams if team['team'] == team2))\n",
    "\n",
    "            if rank_team1 > rank_team2:\n",
    "                # Ajustar las posiciones\n",
    "                sorted_teams[rank_team1], sorted_teams[rank_team2] = sorted_teams[rank_team2], sorted_teams[rank_team1]\n",
    "        elif total_goals_team2 > total_goals_team1:\n",
    "            print(f\"{team2} has more goals in direct encounters. Moving {team2} up.\")\n",
    "            # Verificar si están en el orden correcto\n",
    "            rank_team1 = sorted_teams.index(next(team for team in sorted_teams if team['team'] == team1))\n",
    "            rank_team2 = sorted_teams.index(next(team for team in sorted_teams if team['team'] == team2))\n",
    "\n",
    "            if rank_team2 > rank_team1:\n",
    "                # Ajustar las posiciones\n",
    "                sorted_teams[rank_team1], sorted_teams[rank_team2] = sorted_teams[rank_team2], sorted_teams[rank_team1]\n",
    "        # Si los goles en enfrentamientos directos están empatados, aplicar el segundo criterio: diferencia de goles en todos los partidos\n",
    "        else:\n",
    "            total_goals_for_team1 = 0\n",
    "            total_goals_against_team1 = 0\n",
    "            total_goals_for_team2 = 0\n",
    "            total_goals_against_team2 = 0\n",
    "\n",
    "            # Filtrar el CSV para obtener los partidos de todos los equipos hasta el match_id\n",
    "            for index, row in self.df.loc[:match_id-1].iterrows():  # Iterar desde el inicio hasta el id anterior\n",
    "                home_team = row[\"home_team_name\"]\n",
    "                away_team = row[\"away_team_name\"]\n",
    "                home_goals = row[\"home_team_goals\"]\n",
    "                away_goals = row[\"away_team_goals\"]\n",
    "\n",
    "                # Para team1\n",
    "                if home_team == team1:\n",
    "                    total_goals_for_team1 += home_goals\n",
    "                    total_goals_against_team1 += away_goals\n",
    "                elif away_team == team1:\n",
    "                    total_goals_for_team1 += away_goals\n",
    "                    total_goals_against_team1 += home_goals\n",
    "\n",
    "                # Para team2\n",
    "                if home_team == team2:\n",
    "                    total_goals_for_team2 += home_goals\n",
    "                    total_goals_against_team2 += away_goals\n",
    "                elif away_team == team2:\n",
    "                    total_goals_for_team2 += away_goals\n",
    "                    total_goals_against_team2 += home_goals\n",
    "\n",
    "            # Calcular la diferencia de goles para cada equipo\n",
    "            diff_goals_team1 = total_goals_for_team1 - total_goals_against_team1\n",
    "            diff_goals_team2 = total_goals_for_team2 - total_goals_against_team2\n",
    "\n",
    "            print(f\"Goal difference in all encounters: {team1}: {diff_goals_team1}, {team2}: {diff_goals_team2}\")\n",
    "\n",
    "            # Aplicar el desempate basado en la diferencia de goles\n",
    "            if diff_goals_team1 > diff_goals_team2:\n",
    "                print(f\"{team1} has a better goal difference in all encounters. Moving {team1} up.\")\n",
    "                # Verificar si están en el orden correcto\n",
    "                rank_team1 = sorted_teams.index(next(team for team in sorted_teams if team['team'] == team1))\n",
    "                rank_team2 = sorted_teams.index(next(team for team in sorted_teams if team['team'] == team2))\n",
    "\n",
    "                if rank_team1 > rank_team2:\n",
    "                    # Ajustar las posiciones\n",
    "                    sorted_teams[rank_team1], sorted_teams[rank_team2] = sorted_teams[rank_team2], sorted_teams[rank_team1]\n",
    "            elif diff_goals_team2 > diff_goals_team1:\n",
    "                print(f\"{team2} has a better goal difference in all encounters. Moving {team2} up.\")\n",
    "                # Verificar si están en el orden correcto\n",
    "                rank_team1 = sorted_teams.index(next(team for team in sorted_teams if team['team'] == team1))\n",
    "                rank_team2 = sorted_teams.index(next(team for team in sorted_teams if team['team'] == team2))\n",
    "\n",
    "                if rank_team2 > rank_team1:\n",
    "                    # Ajustar las posiciones\n",
    "                    sorted_teams[rank_team1], sorted_teams[rank_team2] = sorted_teams[rank_team2], sorted_teams[rank_team1]\n",
    "            else:\n",
    "                # Buscar los diccionarios para team1 y team2\n",
    "                team1_data = next(team for team in sorted_teams if team[\"team\"] == team1)\n",
    "                total_goals_team1 = team1_data[\"goals_for\"]\n",
    "\n",
    "                team2_data = next(team for team in sorted_teams if team[\"team\"] == team2)\n",
    "                total_goals_team2 = team2_data[\"goals_for\"]\n",
    "                \n",
    "                if total_goals_team1 > total_goals_team2:\n",
    "                    print(f\"{team1} has scored more total goals. Keeping {team1} up.\")\n",
    "                elif total_goals_team1 < total_goals_team2:\n",
    "                    print(f\"{team2} has scored more total goals. Moving {team2} up.\")\n",
    "                    # Verificar si están en el orden correcto\n",
    "                    rank_team1 = sorted_teams.index(next(team for team in sorted_teams if team['team'] == team1))\n",
    "                    rank_team2 = sorted_teams.index(next(team for team in sorted_teams if team['team'] == team2))\n",
    "\n",
    "                    if rank_team2 > rank_team1:\n",
    "                        # Ajustar las posiciones\n",
    "                        sorted_teams[rank_team1], sorted_teams[rank_team2] = sorted_teams[rank_team2], sorted_teams[rank_team1]\n",
    "                else:\n",
    "                    # Si los goles son iguales, comparar el fairplay\n",
    "                    total_fairplay_team1 = team1_data[\"fairplay\"]\n",
    "                    total_fairplay_team2 = team2_data[\"fairplay\"]\n",
    "\n",
    "                    if total_fairplay_team1 < total_fairplay_team2:\n",
    "                        print(f\"{team1} has better fairplay (fewer penalties). Keeping {team1} up.\")\n",
    "                    elif total_fairplay_team1 > total_fairplay_team2:\n",
    "                        print(f\"{team2} has better fairplay (fewer penalties). Moving {team2} up.\")\n",
    "                        # Mover el equipo 2 hacia arriba (intercambiar posiciones)\n",
    "                        rank_team1 = sorted_teams.index(next(team for team in sorted_teams if team['team'] == team1))\n",
    "                        rank_team2 = sorted_teams.index(next(team for team in sorted_teams if team['team'] == team2))\n",
    "                        \n",
    "                        if rank_team2 > rank_team1:\n",
    "                            # Ajustar las posiciones\n",
    "                            sorted_teams[rank_team1], sorted_teams[rank_team2] = sorted_teams[rank_team2], sorted_teams[rank_team1]\n",
    "                    else:\n",
    "                        # Si aún están empatados, comparar por orden alfabético\n",
    "                        winner = min(team1, team2)\n",
    "                        print(f\"{winner} has better alphabetical order. Moving {winner} up.\")\n",
    "                        if winner == team2:\n",
    "                            rank_team1 = sorted_teams.index(next(team for team in sorted_teams if team['team'] == team1))\n",
    "                            rank_team2 = sorted_teams.index(next(team for team in sorted_teams if team['team'] == team2))\n",
    "        \n",
    "                            # Ajustar las posiciones según el orden alfabético\n",
    "                            if rank_team1 > rank_team2:\n",
    "                                sorted_teams[rank_team1], sorted_teams[rank_team2] = sorted_teams[rank_team2], sorted_teams[rank_team1]\n",
    "\n",
    "        return sorted_teams\n",
    "\n",
    "    def apply_tiebreaker_multiple_teams(self, sorted_teams, gameweek, match_id, teams_list, points):\n",
    "        \"\"\"Apply tiebreaker logic between multiple teams, considering only their matches against each other.\"\"\"\n",
    "\n",
    "        print(\"\\n0 - Ranking before tiebreaker:\")\n",
    "        print(\", \".join([team_data[\"team\"] for team_data in sorted_teams]))\n",
    "        print(f\"\\nGroup with {points} points: {', '.join([team['team'] for team in teams_list])} at gameweek: {gameweek})\")\n",
    "\n",
    "        total_goals = {team[\"team\"]: 0 for team in teams_list}\n",
    "        total_points = {team[\"team\"]: 0 for team in teams_list}\n",
    "\n",
    "        for _, row in self.df.iterrows():\n",
    "            if row[\"id\"] <= match_id and (row[\"home_team_name\"] in [team[\"team\"] for team in teams_list]) and (row[\"away_team_name\"] in [team[\"team\"] for team in teams_list]):\n",
    "                home_team = row[\"home_team_name\"]\n",
    "                away_team = row[\"away_team_name\"]\n",
    "                home_goals = row[\"home_team_goals\"]\n",
    "                away_goals = row[\"away_team_goals\"]\n",
    "\n",
    "                total_goals[home_team] += home_goals\n",
    "                total_goals[away_team] += away_goals\n",
    "\n",
    "                if home_goals > away_goals:\n",
    "                    total_points[home_team] += 3\n",
    "                elif home_goals < away_goals:\n",
    "                    total_points[away_team] += 3\n",
    "                else:\n",
    "                    total_points[home_team] += 1\n",
    "                    total_points[away_team] += 1\n",
    "\n",
    "        points_sorted_teams = sorted(total_points.items(), key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        sorted_teams = self.reorder_teams_by_new_order(sorted_teams, points_sorted_teams)\n",
    "\n",
    "        print(\"\\n1 - Ranking after points between teams:\")\n",
    "        print(\", \".join([team_data[\"team\"] for team_data in sorted_teams]))\n",
    "\n",
    "        points_groups = {}\n",
    "        for team, pts in points_sorted_teams:\n",
    "            if pts not in points_groups:\n",
    "                points_groups[pts] = []\n",
    "            points_groups[pts].append(team)\n",
    "\n",
    "        filtered_points_groups = {pts: teams for pts, teams in points_groups.items() if len(teams) >= 2}\n",
    "\n",
    "        for pts, teams in sorted(filtered_points_groups.items(), reverse=True):\n",
    "            if len(teams) == 2:\n",
    "                team1_name, team2_name = teams\n",
    "                \n",
    "                team1_data = next(team for team in sorted_teams if team[\"team\"] == team1_name)\n",
    "                team2_data = next(team for team in sorted_teams if team[\"team\"] == team2_name)\n",
    "\n",
    "                teams_list_for_tiebreaker = [team1_data, team2_data]\n",
    "                \n",
    "                sorted_teams = self.apply_tiebreaker_two_teams(sorted_teams, gameweek, match_id, teams_list_for_tiebreaker, points)\n",
    "            else:\n",
    "                for points, teams_in_group in points_groups.items():\n",
    "                    print(f\"\\nGroup with {pts} points between teams: {', '.join(teams_in_group)} at gameweek: {gameweek}):\")\n",
    "                    \n",
    "                    if len(teams_in_group) == 2:\n",
    "                        team1_name, team2_name = teams_in_group\n",
    "                        \n",
    "                        team1_data = next(team for team in sorted_teams if team[\"team\"] == team1_name)\n",
    "                        team2_data = next(team for team in sorted_teams if team[\"team\"] == team2_name)\n",
    "\n",
    "                        teams_list_for_tiebreaker = [team1_data, team2_data]\n",
    "                        \n",
    "                        sorted_teams = self.apply_tiebreaker_two_teams(sorted_teams, gameweek, match_id, teams_list_for_tiebreaker, points)\n",
    "                    elif len(teams_in_group) > 2:\n",
    "                        total_goal_difference = {team: total_goals[team] - sum([total_goals[other_team] for other_team in teams_in_group if other_team != team]) for team in teams_in_group}\n",
    "\n",
    "                        sorted_teams_by_goal_difference = sorted(total_goal_difference.items(), key=lambda x: x[1], reverse=True)\n",
    "                        \n",
    "                        sorted_teams = self.reorder_teams_by_new_order(sorted_teams, sorted_teams_by_goal_difference)\n",
    "\n",
    "                        print(\"\\n2 - Ranking after difference goals between teams:\")\n",
    "                        print(\", \".join([team_data[\"team\"] for team_data in sorted_teams]))\n",
    "\n",
    "                        tied_teams = {}\n",
    "                        current_tie_group = []\n",
    "                        last_goal_diff = sorted_teams_by_goal_difference[0][1]\n",
    "\n",
    "                        for team, goal_diff in sorted_teams_by_goal_difference:\n",
    "                            if goal_diff == last_goal_diff:\n",
    "                                current_tie_group.append(team)\n",
    "                            else:\n",
    "                                if len(current_tie_group) >= 2:\n",
    "                                    tied_teams[len(current_tie_group)] = current_tie_group\n",
    "                                current_tie_group = [team]\n",
    "                                last_goal_diff = goal_diff\n",
    "\n",
    "                        if len(current_tie_group) >= 2:\n",
    "                            tied_teams[len(current_tie_group)] = current_tie_group\n",
    "\n",
    "                        for tie_size, tie_group in tied_teams.items():\n",
    "                            print(f\"\\nGroup with {goal_diff} goals difference between teams: {tie_group} at gameweek: {gameweek}):\")\n",
    "                            if tie_size == 2:\n",
    "                                team1_name, team2_name = tie_group\n",
    "                                \n",
    "                                team1_data = next(team for team in sorted_teams if team[\"team\"] == team1_name)\n",
    "                                team2_data = next(team for team in sorted_teams if team[\"team\"] == team2_name)\n",
    "\n",
    "                                teams_list_for_tiebreaker = [team1_data, team2_data]\n",
    "                                \n",
    "                                sorted_teams = self.apply_tiebreaker_two_teams(sorted_teams, gameweek, match_id, teams_list_for_tiebreaker, points)\n",
    "                            elif tie_size >= 3:\n",
    "                                goal_difference_total = {team: 0 for team in tie_group}\n",
    "\n",
    "                                for _, row in self.df.iterrows():\n",
    "                                    if row[\"id\"] <= match_id and ((row[\"home_team_name\"] in tie_group) or (row[\"away_team_name\"] in tie_group)):\n",
    "                                        home_team = row[\"home_team_name\"]\n",
    "                                        away_team = row[\"away_team_name\"]\n",
    "                                        home_goals = row[\"home_team_goals\"]\n",
    "                                        away_goals = row[\"away_team_goals\"]\n",
    "\n",
    "                                        if home_team in tie_group:\n",
    "                                            goal_difference_total[home_team] += home_goals - away_goals\n",
    "                                        if away_team in tie_group:\n",
    "                                            goal_difference_total[away_team] += away_goals - home_goals\n",
    "\n",
    "                                goal_diff_sorted_teams = sorted(goal_difference_total.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "                                sorted_teams = self.reorder_teams_by_new_order(sorted_teams, goal_diff_sorted_teams)\n",
    "\n",
    "                                print(\"\\n3 - Ranking after difference goals global:\")\n",
    "                                print(\", \".join([team_data[\"team\"] for team_data in sorted_teams]))\n",
    "\n",
    "                                tie_group = [team for team, _ in goal_diff_sorted_teams]\n",
    "\n",
    "                                grouped_ties = {}\n",
    "                                for team, goal_diff in goal_diff_sorted_teams:\n",
    "                                    if goal_diff not in grouped_ties:\n",
    "                                        grouped_ties[goal_diff] = []\n",
    "                                    grouped_ties[goal_diff].append(team)\n",
    "\n",
    "                                grouped_ties_with_multiple_teams = {goal_diff: teams for goal_diff, teams in grouped_ties.items() if len(teams) >= 2}\n",
    "\n",
    "                                sorted_groups = sorted(grouped_ties_with_multiple_teams.items(), key=lambda x: x[0], reverse=True)\n",
    "\n",
    "                                for goal_diff, teams in sorted_groups:\n",
    "                                    print(f\"\\nGroup with {goal_diff} goals difference goals global: {teams} at gameweek: {gameweek}):\")\n",
    "                                    if len(teams) == 2:\n",
    "                                        team1_name, team2_name = teams\n",
    "                                        \n",
    "                                        team1_data = next(team for team in sorted_teams if team[\"team\"] == team1_name)\n",
    "                                        team2_data = next(team for team in sorted_teams if team[\"team\"] == team2_name)\n",
    "\n",
    "                                        teams_list_for_tiebreaker = [team1_data, team2_data]\n",
    "                                        \n",
    "                                        sorted_teams = self.apply_tiebreaker_two_teams(sorted_teams, gameweek, match_id, teams_list_for_tiebreaker, points)\n",
    "                                    elif len(teams) > 2:\n",
    "                                        goals_for_total = {team: 0 for team in teams}\n",
    "\n",
    "                                        for _, row in self.df.iterrows():\n",
    "                                            if row[\"gameweek\"] <= gameweek and ((row[\"home_team_name\"] in teams) or (row[\"away_team_name\"] in teams)):\n",
    "                                                home_team = row[\"home_team_name\"]\n",
    "                                                away_team = row[\"away_team_name\"]\n",
    "                                                home_goals = row[\"home_team_goals\"]\n",
    "                                                away_goals = row[\"away_team_goals\"]\n",
    "\n",
    "                                                if home_team in teams:\n",
    "                                                    goals_for_total[home_team] += home_goals\n",
    "                                                if away_team in teams:\n",
    "                                                    goals_for_total[away_team] += away_goals\n",
    "\n",
    "                                        global_diff_sorted_teams = sorted(goals_for_total.items(), key=lambda x: x[1], reverse=True)\n",
    "                                        \n",
    "                                        sorted_teams = self.reorder_teams_by_new_order(sorted_teams, global_diff_sorted_teams)\n",
    "                                        \n",
    "                                        print(\"\\n4 - Ranking after goals global:\")\n",
    "                                        print(\", \".join([team_data[\"team\"] for team_data in sorted_teams]))\n",
    "\n",
    "                                        grouped_ties = {}\n",
    "                                        for team_name, goals_for in global_diff_sorted_teams:\n",
    "                                            if goals_for not in grouped_ties:\n",
    "                                                grouped_ties[goals_for] = []\n",
    "                                            grouped_ties[goals_for].append((team_name, goals_for))  \n",
    "\n",
    "                                        grouped_ties_list = [teams for teams in grouped_ties.values() if len(teams) >= 2]\n",
    "\n",
    "                                        for group in grouped_ties_list:\n",
    "                                            print(f\"\\nGroup: {[team[0] for team in group]} at gameweek: {gameweek})\")\n",
    "\n",
    "                                            if len(group) == 2:\n",
    "                                                team1_name, team2_name = [team[0] for team in group]\n",
    "\n",
    "                                                team1_data = next(team for team in sorted_teams if team[\"team\"] == team1_name)\n",
    "                                                team2_data = next(team for team in sorted_teams if team[\"team\"] == team2_name)\n",
    "\n",
    "                                                teams_list_for_tiebreaker = [team1_data, team2_data]\n",
    "\n",
    "                                                sorted_teams = self.apply_tiebreaker_two_teams(sorted_teams, gameweek, match_id, teams_list_for_tiebreaker, points)\n",
    "\n",
    "                                                print(\", \".join([team_data[\"team\"] for team_data in sorted_teams]))\n",
    "\n",
    "                                            elif len(group) > 2:\n",
    "                                                teams_with_fairplay = []\n",
    "                                                for team_name, _ in group:\n",
    "                                                    team_data = next(team for team in sorted_teams if team[\"team\"] == team_name)\n",
    "                                                    fairplay = team_data[\"fairplay\"]\n",
    "                                                    teams_with_fairplay.append((team_name, fairplay))\n",
    "\n",
    "                                                teams_with_fairplay_sorted = sorted(teams_with_fairplay, key=lambda x: x[1])\n",
    "\n",
    "                                                sorted_teams_by_fairplay = [team[0] for team in teams_with_fairplay_sorted]\n",
    "\n",
    "                                                group_sorted = sorted(group, key=lambda team: sorted_teams_by_fairplay.index(team[0]))\n",
    "\n",
    "                                                sorted_teams = self.reorder_teams_by_new_order(sorted_teams, group_sorted)\n",
    "\n",
    "                                                print(\"\\n5 - Ranking after fairplay:\")\n",
    "                                                print(\", \".join([team_data[\"team\"] for team_data in sorted_teams]))\n",
    "\n",
    "        return sorted_teams\n",
    "\n",
    "    def calculate_fairplay(self, yellow_cards, red_cards, second_yellow_cards):\n",
    "        \"\"\"Calculates the fairplay score based on the card rules.\"\"\"\n",
    "        fairplay_score = yellow_cards + 3 * (red_cards - second_yellow_cards) + second_yellow_cards\n",
    "        return fairplay_score\n",
    "\n",
    "    def process_matches(self):\n",
    "        # Inicializar variables\n",
    "        current_gameweek = None\n",
    "        gameweek_data = []  # Lista para almacenar los equipos y gameweek\n",
    "\n",
    "        # Borrar el archivo CSV si ya existe antes de empezar\n",
    "        if os.path.exists(self.output_file):\n",
    "            os.remove(self.output_file)\n",
    "\n",
    "        # Iterar sobre las filas del CSV\n",
    "        for index, row in self.df.iterrows():\n",
    "            # Obtener el valor de la columna gameweek\n",
    "            gameweek = row[\"gameweek\"]\n",
    "\n",
    "            # Si es el primer gameweek o el mismo que el anterior, agregar los nombres de los equipos a gameweek_data\n",
    "            if current_gameweek is None or gameweek == current_gameweek:\n",
    "                # Llamar a la función de actualización de estadísticas para los equipos\n",
    "                self.update_team_stats(\n",
    "                    home_team=row['home_team_name'],\n",
    "                    away_team=row['away_team_name'],\n",
    "                    home_goals=row[\"home_team_goals\"],\n",
    "                    away_goals=row[\"away_team_goals\"],\n",
    "                    home_yellow_cards=row[\"home_PlayersYellowCards\"],\n",
    "                    home_red_cards=row[\"home_PlayersRedCards\"],\n",
    "                    home_second_yellow_cards=row[\"home_PlayersSecondYellowCards\"],\n",
    "                    away_yellow_cards=row[\"away_PlayersYellowCards\"],\n",
    "                    away_red_cards=row[\"away_PlayersRedCards\"],\n",
    "                    away_second_yellow_cards=row[\"away_PlayersSecondYellowCards\"]\n",
    "                )\n",
    "\n",
    "                # Obtener las estadísticas de los equipos después de la actualización\n",
    "                home_stats = self.team_stats.get(row['home_team_name'], {})\n",
    "                away_stats = self.team_stats.get(row['away_team_name'], {})\n",
    "\n",
    "                # Añadir los datos de los equipos a gameweek_data\n",
    "                gameweek_data.append({\n",
    "                    'gameweek': gameweek,\n",
    "                    'team': row['home_team_name'], \n",
    "                    'goals': row[\"home_team_goals\"],\n",
    "                    'yellow_cards': row[\"home_PlayersYellowCards\"],\n",
    "                    'red_cards': row[\"home_PlayersRedCards\"],\n",
    "                    'second_yellow_cards': row[\"home_PlayersSecondYellowCards\"],\n",
    "                    'date_of_match': row[\"date_of_match\"],\n",
    "                    \"matches_played\": home_stats.get(\"matches_played\", 0),\n",
    "                    \"points\": home_stats.get(\"points\", 0),\n",
    "                    \"goals_for\": home_stats.get(\"goals_for\", 0),\n",
    "                    \"goals_against\": home_stats.get(\"goals_against\", 0),\n",
    "                    \"goal_difference\": home_stats.get(\"goals_for\", 0) - home_stats.get(\"goals_against\", 0),\n",
    "                    \"yellow_cards\": home_stats.get(\"yellow_cards\", 0),\n",
    "                    \"red_cards\": home_stats.get(\"red_cards\", 0),\n",
    "                    \"second_yellow_cards\": home_stats.get(\"second_yellow_cards\", 0),\n",
    "                    \"fairplay\": self.calculate_fairplay(home_stats.get(\"yellow_cards\", 0), home_stats.get(\"red_cards\", 0), home_stats.get(\"second_yellow_cards\", 0)),\n",
    "                })\n",
    "\n",
    "                gameweek_data.append({\n",
    "                    'gameweek': gameweek, \n",
    "                    'team': row['away_team_name'],\n",
    "                    'goals': row[\"away_team_goals\"],\n",
    "                    'yellow_cards': row[\"away_PlayersYellowCards\"],\n",
    "                    'red_cards': row[\"away_PlayersRedCards\"],\n",
    "                    'second_yellow_cards': row[\"away_PlayersSecondYellowCards\"],\n",
    "                    'date_of_match': row[\"date_of_match\"],\n",
    "                    \"matches_played\": away_stats.get(\"matches_played\", 0),\n",
    "                    \"points\": away_stats.get(\"points\", 0),\n",
    "                    \"goals_for\": away_stats.get(\"goals_for\", 0),\n",
    "                    \"goals_against\": away_stats.get(\"goals_against\", 0),\n",
    "                    \"goal_difference\": away_stats.get(\"goals_for\", 0) - away_stats.get(\"goals_against\", 0),\n",
    "                    \"yellow_cards\": away_stats.get(\"yellow_cards\", 0),\n",
    "                    \"red_cards\": away_stats.get(\"red_cards\", 0),\n",
    "                    \"second_yellow_cards\": away_stats.get(\"second_yellow_cards\", 0),\n",
    "                    \"fairplay\": self.calculate_fairplay(away_stats.get(\"yellow_cards\", 0), away_stats.get(\"red_cards\", 0), away_stats.get(\"second_yellow_cards\", 0)),\n",
    "                })\n",
    "\n",
    "                current_gameweek = gameweek  # Actualizar el gameweek\n",
    "\n",
    "            # Si encontramos un gameweek diferente, guardar los datos del gameweek anterior y reiniciar\n",
    "            elif gameweek != current_gameweek:\n",
    "                # Añadir el índice a cada fila de gameweek_data\n",
    "                for entry in gameweek_data:\n",
    "                    entry['index'] = index  # Asignar el valor del índice a cada fila de gameweek_data\n",
    "\n",
    "                # Ordenar gameweek_data por puntos de mayor a menor\n",
    "                gameweek_data.sort(key=lambda x: x['points'], reverse=True)\n",
    "\n",
    "                # Ordenar y aplicar el desempate\n",
    "                gameweek_data = self.check_tiebreaker_type(gameweek_data, current_gameweek, index)\n",
    "\n",
    "                # Asignar el rank basado en la posición después de ordenar\n",
    "                for rank, entry in enumerate(gameweek_data, start=1):\n",
    "                    entry['rank'] = rank  # Asignar el ranko\n",
    "\n",
    "                # Guardar los datos de este gameweek en el CSV\n",
    "                gameweek_df = pd.DataFrame(gameweek_data)\n",
    "                gameweek_df.to_csv(self.output_file, mode='a', index=False, header=not os.path.exists(self.output_file))  # Añadir al archivo CSV\n",
    "                print(f\"Datos guardados para gameweek {current_gameweek}\")\n",
    "\n",
    "                # Llamar a la función de actualización de estadísticas para los equipos\n",
    "                self.update_team_stats(\n",
    "                    home_team=row['home_team_name'],\n",
    "                    away_team=row['away_team_name'],\n",
    "                    home_goals=row[\"home_team_goals\"],\n",
    "                    away_goals=row[\"away_team_goals\"],\n",
    "                    home_yellow_cards=row[\"home_PlayersYellowCards\"],\n",
    "                    home_red_cards=row[\"home_PlayersRedCards\"],\n",
    "                    home_second_yellow_cards=row[\"home_PlayersSecondYellowCards\"],\n",
    "                    away_yellow_cards=row[\"away_PlayersYellowCards\"],\n",
    "                    away_red_cards=row[\"away_PlayersRedCards\"],\n",
    "                    away_second_yellow_cards=row[\"away_PlayersSecondYellowCards\"]\n",
    "                )\n",
    "\n",
    "                # Obtener las estadísticas de los equipos después de la actualización\n",
    "                home_stats = self.team_stats.get(row['home_team_name'], {})\n",
    "                away_stats = self.team_stats.get(row['away_team_name'], {})\n",
    "\n",
    "                # Limpiar la lista y actualizar el gameweek actual\n",
    "                gameweek_data = [{\n",
    "                    'gameweek': gameweek,\n",
    "                    'team': row['home_team_name'], \n",
    "                    'goals': row[\"home_team_goals\"],\n",
    "                    'yellow_cards': row[\"home_PlayersYellowCards\"],\n",
    "                    'red_cards': row[\"home_PlayersRedCards\"],\n",
    "                    'second_yellow_cards': row[\"home_PlayersSecondYellowCards\"],\n",
    "                    'date_of_match': row[\"date_of_match\"],\n",
    "                    \"matches_played\": home_stats.get(\"matches_played\", 0),\n",
    "                    \"points\": home_stats.get(\"points\", 0),\n",
    "                    \"goals_for\": home_stats.get(\"goals_for\", 0),\n",
    "                    \"goals_against\": home_stats.get(\"goals_against\", 0),\n",
    "                    \"goal_difference\": home_stats.get(\"goals_for\", 0) - home_stats.get(\"goals_against\", 0),\n",
    "                    \"yellow_cards\": home_stats.get(\"yellow_cards\", 0),\n",
    "                    \"red_cards\": home_stats.get(\"red_cards\", 0),\n",
    "                    \"second_yellow_cards\": home_stats.get(\"second_yellow_cards\", 0),\n",
    "                    \"fairplay\": self.calculate_fairplay(home_stats.get(\"yellow_cards\", 0), home_stats.get(\"red_cards\", 0), home_stats.get(\"second_yellow_cards\", 0)),\n",
    "                }, {\n",
    "                    'gameweek': gameweek, \n",
    "                    'team': row['away_team_name'],\n",
    "                    'goals': row[\"away_team_goals\"],\n",
    "                    'yellow_cards': row[\"away_PlayersYellowCards\"],\n",
    "                    'red_cards': row[\"away_PlayersRedCards\"],\n",
    "                    'second_yellow_cards': row[\"away_PlayersSecondYellowCards\"],\n",
    "                    'date_of_match': row[\"date_of_match\"],\n",
    "                    \"matches_played\": away_stats.get(\"matches_played\", 0),\n",
    "                    \"points\": away_stats.get(\"points\", 0),\n",
    "                    \"goals_for\": away_stats.get(\"goals_for\", 0),\n",
    "                    \"goals_against\": away_stats.get(\"goals_against\", 0),\n",
    "                    \"goal_difference\": away_stats.get(\"goals_for\", 0) - away_stats.get(\"goals_against\", 0),\n",
    "                    \"yellow_cards\": away_stats.get(\"yellow_cards\", 0),\n",
    "                    \"red_cards\": away_stats.get(\"red_cards\", 0),\n",
    "                    \"second_yellow_cards\": away_stats.get(\"second_yellow_cards\", 0),\n",
    "                    \"fairplay\": self.calculate_fairplay(away_stats.get(\"yellow_cards\", 0), away_stats.get(\"red_cards\", 0), away_stats.get(\"second_yellow_cards\", 0)),\n",
    "                }]  # Empezar nueva lista con la fila actual\n",
    "\n",
    "                current_gameweek = gameweek  # Actualizar el gameweek\n",
    "\n",
    "        # Si quedan filas del último gameweek, guardarlas también\n",
    "        if gameweek_data:\n",
    "            # Añadir el índice a cada fila de gameweek_data\n",
    "            for entry in gameweek_data:\n",
    "                entry['index'] = index  # Asignar el valor del índice a cada fila de gameweek_data\n",
    "\n",
    "            # Ordenar gameweek_data por puntos de mayor a menor\n",
    "            gameweek_data.sort(key=lambda x: x['points'], reverse=True)\n",
    "\n",
    "            # Ordenar y aplicar el desempate\n",
    "            gameweek_data = self.check_tiebreaker_type(gameweek_data, current_gameweek, index)\n",
    "\n",
    "            # Asignar el rank basado en la posición después de ordenar\n",
    "            for rank, entry in enumerate(gameweek_data, start=1):\n",
    "                entry['rank'] = rank  # Asignar el rank\n",
    "\n",
    "            # Guardar las filas procesadas en un nuevo archivo CSV\n",
    "            gameweek_df = pd.DataFrame(gameweek_data)\n",
    "            gameweek_df.to_csv(self.output_file, mode='a', index=False, header=not os.path.exists(self.output_file))  # Añadir al archivo CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ranking integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatchRankUpdater:\n",
    "    def __init__(self, matches_csv, teams_rank_csv):\n",
    "        \"\"\"\n",
    "        Inicializa la clase con las rutas de los CSVs de los partidos y los rankings de los equipos.\n",
    "        \n",
    "        :param matches_csv: Ruta del archivo CSV con los partidos (home_team, away_team, date).\n",
    "        :param teams_rank_csv: Ruta del archivo CSV con los equipos y rankings (team, date, rank, points).\n",
    "        \"\"\"\n",
    "        self.matches_df = pd.read_csv(matches_csv)\n",
    "        self.teams_rank_df = pd.read_csv(teams_rank_csv)\n",
    "        self.matches_csv = matches_csv\n",
    "\n",
    "        # Asegurarse de que las fechas sean del tipo datetime\n",
    "        self.matches_df['date_of_match'] = pd.to_datetime(self.matches_df['date_of_match'])\n",
    "        self.teams_rank_df['date_of_match'] = pd.to_datetime(self.teams_rank_df['date_of_match'])\n",
    "\n",
    "    def _get_closest_stats(self, team, match_date):\n",
    "        \"\"\"\n",
    "        Encuentra el ranking y los puntos más cercanos y anteriores a la fecha del partido para un equipo dado.\n",
    "        \"\"\"\n",
    "        team_data = self.teams_rank_df[\n",
    "            (self.teams_rank_df['team'] == team) & \n",
    "            (self.teams_rank_df['date_of_match'] < match_date)\n",
    "        ]\n",
    "\n",
    "        if not team_data.empty:\n",
    "            closest_row = team_data.loc[team_data['date_of_match'].idxmax()]\n",
    "            return closest_row['rank'], closest_row['points'], closest_row['goals_for'], closest_row['goals_against'], closest_row['goal_difference']\n",
    "        \n",
    "        return 0.0, 0.0, 0.0, 0.0, 0.0\n",
    "\n",
    "    def update_and_save(self):\n",
    "        \"\"\"\n",
    "        Actualiza el DataFrame de los partidos con los rankings y puntos de los equipos\n",
    "        (home_team y away_team) y guarda el archivo CSV actualizado en el mismo archivo.\n",
    "        \"\"\"\n",
    "        home_team_ranks = []\n",
    "        away_team_ranks = []\n",
    "        home_team_points = []\n",
    "        away_team_points = []\n",
    "        home_team_goals_for = []\n",
    "        away_team_goals_for = []\n",
    "        home_team_goals_againsts = []\n",
    "        away_team_goals_against = []\n",
    "        home_team_goal_difference = []\n",
    "        away_team_goal_difference = []\n",
    "\n",
    "        # Iterar sobre las filas del DataFrame de los partidos\n",
    "        for _, match_row in self.matches_df.iterrows():\n",
    "            match_date = match_row['date_of_match']  # Ya está en formato datetime\n",
    "            home_team = match_row['home_team_name']\n",
    "            away_team = match_row['away_team_name']\n",
    "            \n",
    "            # Obtener los rankings y puntos más cercanos para el home_team y away_team\n",
    "            home_team_rank, home_team_pts, home_team_goal_for, home_team_goal_againsts, home_team_goals_difference = self._get_closest_stats(home_team, match_date)\n",
    "            away_team_rank, away_team_pts, away_team_goal_for, away_team_goal_againsts, away_team_goals_difference = self._get_closest_stats(away_team, match_date)\n",
    "            \n",
    "            # Agregar los resultados a las listas\n",
    "            home_team_ranks.append(home_team_rank)\n",
    "            away_team_ranks.append(away_team_rank)\n",
    "            home_team_points.append(home_team_pts)\n",
    "            away_team_points.append(away_team_pts)\n",
    "            home_team_goals_for.append(home_team_goal_for)\n",
    "            away_team_goals_for.append(away_team_goal_for)\n",
    "            home_team_goals_againsts.append(home_team_goal_againsts)\n",
    "            away_team_goals_against.append(away_team_goal_againsts)\n",
    "            home_team_goal_difference.append(home_team_goals_difference)\n",
    "            away_team_goal_difference.append(away_team_goals_difference)\n",
    "\n",
    "        # Añadir las columnas al DataFrame de partidos\n",
    "        self.matches_df['home_team_rank'] = home_team_ranks\n",
    "        self.matches_df['away_team_rank'] = away_team_ranks\n",
    "        self.matches_df['home_team_points'] = home_team_points\n",
    "        self.matches_df['away_team_points'] = away_team_points\n",
    "        self.matches_df['home_team_goals_for'] = home_team_goals_for\n",
    "        self.matches_df['away_team_goals_for'] = away_team_goals_for\n",
    "        self.matches_df['home_team_goals_againsts'] = home_team_goals_againsts\n",
    "        self.matches_df['away_team_goals_against'] = away_team_goals_against\n",
    "        self.matches_df['home_team_goals_difference'] = home_team_goal_difference\n",
    "        self.matches_df['away_team_goals_difference'] = away_team_goal_difference\n",
    "\n",
    "        # Guardar el CSV actualizado en el mismo archivo\n",
    "        self.matches_df.to_csv(self.matches_csv, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining time data from the match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Match_events:\n",
    "    def __init__(self, url):\n",
    "        \"\"\"\n",
    "        Initialize the extractor with the URL of the match page.\n",
    "        This sets up the URL, initializes placeholders for parsed HTML content,\n",
    "        and lists to store events for both teams.\n",
    "        \"\"\"\n",
    "        self.url = url  # URL of the match page\n",
    "        self.soup = None  # Placeholder for the parsed HTML content\n",
    "        self.events_team_a = []  # List to store events for Team A\n",
    "        self.events_team_b = []  # List to store events for Team B\n",
    "\n",
    "    def fetch_html(self):\n",
    "        \"\"\"\n",
    "        Fetch the HTML content from the given URL.\n",
    "        This method makes an HTTP GET request to the URL and parses the HTML if the request is successful.\n",
    "        \"\"\"\n",
    "        headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:131.0) Gecko/20100101 Firefox/131.0\",\n",
    "            \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8\",\n",
    "            \"Accept-Language\": \"en-US,en;q=0.5\",  # Indica el idioma preferido\n",
    "            \"Accept-Encoding\": \"gzip, deflate, br\",  # Indica que aceptas respuestas comprimidas\n",
    "            \"Connection\": \"keep-alive\",  # Mantiene la conexión abierta para mayor eficiencia\n",
    "            \"Upgrade-Insecure-Requests\": \"1\",  # Indica que el cliente prefiere HTTPS\n",
    "            \"DNT\": \"1\",  # Indica que no deseas ser rastreado (opcional)\n",
    "        }\n",
    "        response = requests.get(self.url, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            self.soup = BeautifulSoup(\n",
    "                response.text, \"html.parser\"\n",
    "            )  # Parse the HTML content\n",
    "        else:\n",
    "            raise Exception(\n",
    "                f\"Failed to fetch HTML content. Status code: {response.status_code}\"\n",
    "            )\n",
    "\n",
    "    def parse_events(self):\n",
    "        \"\"\"\n",
    "        Extract match events from the HTML content for both teams.\n",
    "        This method locates the event container in the HTML and extracts relevant data for both teams.\n",
    "        \"\"\"\n",
    "        # Ensure that the HTML content has been loaded\n",
    "        if not self.soup:\n",
    "            raise Exception(\"HTML content not loaded. Call 'fetch_html()' first.\")\n",
    "\n",
    "        # Locate the main container that holds all the events\n",
    "        events_wrap = self.soup.find(\"div\", id=\"events_wrap\")\n",
    "        if not events_wrap:\n",
    "            raise Exception(\"Event container not found in the HTML.\")\n",
    "\n",
    "        # Parse events for Team A\n",
    "        for event in events_wrap.find_all(\n",
    "            \"div\", class_=\"event a\"\n",
    "        ):  # Look for events with class 'event a'\n",
    "            minute = (\n",
    "                event.find(\"small\").text.strip() if event.find(\"small\") else None\n",
    "            )  # Get the minute of the event\n",
    "            event_icon = event.find(\"div\", class_=\"event_icon\")\n",
    "            event_type = (\n",
    "                event_icon[\"class\"][1] if event_icon else None\n",
    "            )  # Get the type of event (e.g., goal, yellow card)\n",
    "            player_tag = event.find(\"a\")\n",
    "            player = (\n",
    "                player_tag.text.strip() if player_tag else None\n",
    "            )  # Get the player involved in the event\n",
    "            team_logo = event.find(\"img\", class_=\"teamlogo\")\n",
    "            team = (\n",
    "                team_logo[\"alt\"].replace(\" Club Crest\", \"\").replace(\" \", \"_\")\n",
    "                if team_logo\n",
    "                else None\n",
    "            )  # Get the team name\n",
    "\n",
    "            # Append the extracted details to the Team A events list\n",
    "            self.events_team_a.append(\n",
    "                {\n",
    "                    \"Minute\": minute,\n",
    "                    \"EventType\": event_type,\n",
    "                    \"Player\": player,\n",
    "                    \"Team\": team,\n",
    "                }\n",
    "            )\n",
    "\n",
    "        # Parse events for Team B\n",
    "        for event in events_wrap.find_all(\n",
    "            \"div\", class_=\"event b\"\n",
    "        ):  # Look for events with class 'event b'\n",
    "            minute = (\n",
    "                event.find(\"small\").text.strip() if event.find(\"small\") else None\n",
    "            )  # Get the minute of the event\n",
    "            event_icon = event.find(\"div\", class_=\"event_icon\")\n",
    "            event_type = (\n",
    "                event_icon[\"class\"][1] if event_icon else None\n",
    "            )  # Get the type of event (e.g., goal, yellow card)\n",
    "            player_tag = event.find(\"a\")\n",
    "            player = (\n",
    "                player_tag.text.strip() if player_tag else None\n",
    "            )  # Get the player involved in the event\n",
    "            team_logo = event.find(\"img\", class_=\"teamlogo\")\n",
    "            team = (\n",
    "                team_logo[\"alt\"].replace(\" Club Crest\", \"\").replace(\" \", \"_\")\n",
    "                if team_logo\n",
    "                else None\n",
    "            )  # Get the team name\n",
    "\n",
    "            # Append the extracted details to the Team B events list\n",
    "            self.events_team_b.append(\n",
    "                {\n",
    "                    \"Minute\": minute,\n",
    "                    \"EventType\": event_type,\n",
    "                    \"Player\": player,\n",
    "                    \"Team\": team,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    def save_to_csv(self, match, gameweek):\n",
    "        \"\"\"\n",
    "        Save the extracted events for both Team A and Team B to separate CSV files.\n",
    "        This method ensures that events are saved only after they have been parsed.\n",
    "        \"\"\"\n",
    "        if not self.events_team_a:\n",
    "            raise Exception(\n",
    "                \"No events for Team A to save. Make sure to call 'parse_events()' first.\"\n",
    "            )\n",
    "        if not self.events_team_b:\n",
    "            raise Exception(\n",
    "                \"No events for Team B to save. Make sure to call 'parse_events()' first.\"\n",
    "            )\n",
    "\n",
    "        # Convert the events for Team A and Team B to DataFrames\n",
    "        events_team_a_df = pd.DataFrame(self.events_team_a)\n",
    "        events_team_b_df = pd.DataFrame(self.events_team_b)\n",
    "\n",
    "        # Get the team names for the output filenames\n",
    "        team_name_a = self.events_team_a[0][\"Team\"]\n",
    "        team_name_b = self.events_team_b[0][\"Team\"]\n",
    "\n",
    "        # Define output filenames for the CSV files\n",
    "        output_filename_a = f\"{gameweek}_{match}_{team_name_a}_events.csv\"\n",
    "        output_filename_b = f\"{gameweek}_{match}_{team_name_b}_events.csv\"\n",
    "\n",
    "        # Save the extracted events to CSV files for both teams\n",
    "        events_team_a_df.to_csv(output_filename_a, index=False)\n",
    "        events_team_b_df.to_csv(output_filename_b, index=False)\n",
    "\n",
    "    def run(self, links_file, gameweeks_file):\n",
    "        \"\"\"\n",
    "        Execute the full process: fetch HTML, parse events, and save to CSV files for both teams.\n",
    "        This method orchestrates the entire extraction process by reading the necessary input files,\n",
    "        fetching the HTML content, parsing events, and saving the results to CSV files.\n",
    "        \"\"\"\n",
    "        print(f\"Starting collecting events data...\")\n",
    "\n",
    "        # Read the links and gameweeks from CSV files\n",
    "        links_df = pd.read_csv(links_file)\n",
    "        gameweeks_df = pd.read_csv(gameweeks_file)\n",
    "\n",
    "        # Initialize match as an integer\n",
    "        match = 1\n",
    "\n",
    "        # Loop through each link and its corresponding gameweek\n",
    "        for index, link in enumerate(links_df[\"link\"]):\n",
    "            gameweek = gameweeks_df.iloc[index][\"gameweek\"]\n",
    "\n",
    "            print(f\"Processing link {index + 1}: {link}\")\n",
    "\n",
    "            # Create an extractor for the current URL and gameweek\n",
    "            extractor = Match_events(link)\n",
    "\n",
    "            # Fetch the HTML content for the match page\n",
    "            extractor.fetch_html()\n",
    "\n",
    "            # Parse the events for both teams\n",
    "            extractor.parse_events()\n",
    "\n",
    "            # Save the extracted events to CSV files for both teams\n",
    "            extractor.save_to_csv(match, gameweek)\n",
    "\n",
    "            # Increment the match counter\n",
    "            match += 1\n",
    "\n",
    "            time.sleep(6)\n",
    "\n",
    "        print(f\"Collecting events data process completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining odds data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Odds_betting:\n",
    "    def __init__(self):\n",
    "        self.betting_filename = None\n",
    "        self.filename = None\n",
    "        self.betting_data = None\n",
    "        self.match_data = None\n",
    "        self.team_name_mapping = {\n",
    "            \"Leganes\": \"Leganes\",\n",
    "            \"Alaves\": \"Alaves\",\n",
    "            \"Valencia\": \"Valencia\",\n",
    "            \"Las Palmas\": \"Las_Palmas\",\n",
    "            \"Celta\": \"Celta_Vigo\",\n",
    "            \"Sociedad\": \"Real_Sociedad\",\n",
    "            \"Ath Madrid\": \"Atletico_Madrid\",\n",
    "            \"Sevilla\": \"Sevilla\",\n",
    "            \"Espanol\": \"Espanyol\",\n",
    "            \"Ath Bilbao\": \"Athletic_Club\",\n",
    "            \"Getafe\": \"Getafe\",\n",
    "            \"Barcelona\": \"Barcelona\",\n",
    "            \"Betis\": \"Real_Betis\",\n",
    "            \"La Coruna\": \"Deportivo_La_Coruna\",\n",
    "            \"Real Madrid\": \"Real_Madrid\",\n",
    "            \"Levante\": \"Levante\",\n",
    "            \"Villarreal\": \"Villarreal\",\n",
    "            \"Malaga\": \"Malaga\",\n",
    "            \"Eibar\": \"Eibar\",\n",
    "            \"Girona\": \"Girona\"\n",
    "        }\n",
    "\n",
    "    def load_data(self, betting_filename, filename):\n",
    "        self.betting_filename = betting_filename\n",
    "        self.filename = filename\n",
    "        self.betting_data = pd.read_csv(self.betting_filename)\n",
    "        self.match_data = pd.read_csv(self.filename)\n",
    "        \n",
    "        # Aseguramos que los datos fueron cargados correctamente\n",
    "        if self.betting_data is None or self.match_data is None:\n",
    "            print(\"Error: Failed to load betting data or match data.\")\n",
    "        else:\n",
    "            print(\"Data loaded successfully.\")\n",
    "\n",
    "    def rename_teams(self):\n",
    "        if self.betting_data is not None:\n",
    "            self.betting_data[\"HomeTeam\"] = self.betting_data[\"HomeTeam\"].replace(self.team_name_mapping)\n",
    "            self.betting_data[\"AwayTeam\"] = self.betting_data[\"AwayTeam\"].replace(self.team_name_mapping)\n",
    "        else:\n",
    "            print(\"Error: betting data is None.\")\n",
    "\n",
    "    def extract_odds_columns(self):\n",
    "        required_columns = [\n",
    "            \"Date\",\"HomeTeam\",\"AwayTeam\",\n",
    "            \"B365H\", \"B365D\", \"B365A\", \n",
    "            \"BWH\", \"BWD\", \"BWA\", \n",
    "            \"IWH\", \"IWD\", \"IWA\", \n",
    "            \"LBH\", \"LBD\", \"LBA\", \n",
    "            \"PSH\", \"PSD\", \"PSA\",\n",
    "            \"WHH\", \"WHD\", \"WHA\",\n",
    "            \"VCH\", \"VCD\", \"VCA\"\n",
    "        ]\n",
    "        \n",
    "        available_columns = [col for col in required_columns if col in self.betting_data.columns]\n",
    "        self.betting_data = self.betting_data[available_columns]\n",
    "\n",
    "    def compute_avg_odds(self):\n",
    "        self.betting_data[\"odd_home_avg\"] = self.betting_data[[\"B365H\", \"BWH\", \"IWH\", \"LBH\", \"PSH\", \"WHH\", \"VCH\"]].mean(axis=1, skipna=True)\n",
    "        self.betting_data[\"odd_draw_avg\"] = self.betting_data[[\"B365D\", \"BWD\", \"IWD\", \"LBD\", \"PSD\", \"WHD\", \"VCD\"]].mean(axis=1, skipna=True)\n",
    "        self.betting_data[\"odd_away_avg\"] = self.betting_data[[\"B365A\", \"BWA\", \"IWA\", \"LBA\", \"PSA\", \"WHA\", \"VCA\"]].mean(axis=1, skipna=True)\n",
    "        \n",
    "    def compute_probabilities(self):\n",
    "        if self.betting_data[\"odd_home_avg\"].isnull().any() or self.betting_data[\"odd_draw_avg\"].isnull().any() or self.betting_data[\"odd_away_avg\"].isnull().any():\n",
    "            print(\"Warning: Some odds are missing or NaN.\")\n",
    "\n",
    "        self.betting_data[\"prob_home_avg\"] = 1 / self.betting_data[\"odd_home_avg\"]\n",
    "        self.betting_data[\"prob_draw_avg\"] = 1 / self.betting_data[\"odd_draw_avg\"]\n",
    "        self.betting_data[\"prob_away_avg\"] = 1 / self.betting_data[\"odd_away_avg\"]\n",
    "\n",
    "        total_prob = self.betting_data[\"prob_home_avg\"] + self.betting_data[\"prob_draw_avg\"] + self.betting_data[\"prob_away_avg\"]\n",
    "\n",
    "        self.betting_data[\"prob_home_avg\"] /= total_prob\n",
    "        self.betting_data[\"prob_draw_avg\"] /= total_prob\n",
    "        self.betting_data[\"prob_away_avg\"] /= total_prob\n",
    "\n",
    "    def merge_with_match_data(self):\n",
    "        if self.betting_data is not None and self.match_data is not None:\n",
    "            merged = self.match_data.merge(\n",
    "                self.betting_data[[\"HomeTeam\", \"AwayTeam\", \"Date\", \"prob_home_avg\", \"prob_draw_avg\", \"prob_away_avg\"]],\n",
    "                how=\"left\",\n",
    "                left_on=[\"home_team_name\", \"away_team_name\"],\n",
    "                right_on=[\"HomeTeam\", \"AwayTeam\"]\n",
    "            )\n",
    "\n",
    "            merged.drop(columns=[\"HomeTeam\", \"AwayTeam\", \"Date\"], inplace=True)\n",
    "\n",
    "            self.match_data = merged\n",
    "\n",
    "        else:\n",
    "            print(\"❌ Error: betting_data or match_data is None.\")\n",
    "\n",
    "    def save_updated_data(self, filename):\n",
    "        file_path = filename\n",
    "\n",
    "        if self.match_data is not None:\n",
    "            self.match_data.to_csv(file_path, index=False)\n",
    "            print(f\"Data with probabilities saved to {file_path}\")\n",
    "        else:\n",
    "            print(\"Error: match_data is None. Cannot save data.\")\n",
    "\n",
    "    def process_odds(self, betting_filename, filename):\n",
    "        self.load_data(betting_filename, filename)\n",
    "        self.rename_teams()\n",
    "        self.extract_odds_columns()\n",
    "        self.compute_avg_odds()\n",
    "        self.compute_probabilities()\n",
    "        self.merge_with_match_data()\n",
    "        self.save_updated_data(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_full_process(season, test_size, betting_filename):\n",
    "    \"\"\"\n",
    "    Runs the full data extraction process for a given league URL.\n",
    "    It involves extracting match data, player statistics, and match events.\n",
    "    \"\"\"\n",
    "    # Define the league URL\n",
    "    league_url = f\"https://fbref.com/es/comps/12/{season}/horario/Marcadores-y-partidos-de-{season}-La-Liga\"\n",
    "    # Define the filename for the current season\n",
    "    filename = f\"matches_{season}.csv\"\n",
    "\n",
    "    # First class: Extract match data from the league URL\n",
    "    # Create an instance of Match_data and run the extraction process\n",
    "    #Match_data_extractor = Match_data(league_url, test_size)\n",
    "    #Match_data_extractor.run()\n",
    "\n",
    "    # Second class: Extract player data for each match\n",
    "    # Load the existing CSV file from the parent directory\n",
    "    data = pd.read_csv(filename)\n",
    "    # Define file paths for temporary CSV files containing links and gameweeks\n",
    "    links_file = \"links_temp.csv\"\n",
    "    gameweeks_file = \"gameweeks_temp.csv\"\n",
    "    # Save only the 'link' column from the match data to the links file\n",
    "    data[[\"link\"]].to_csv(links_file, index=False)\n",
    "    # Save only the 'gameweek' column from the match data to the gameweeks file\n",
    "    data[[\"gameweek\"]].to_csv(gameweeks_file, index=False)\n",
    "    # Create an instance of the Players_data class with the file paths\n",
    "    #Players_data_extractor = Players_data(filename, links_file, gameweeks_file)\n",
    "    #Players_data_extractor.run()\n",
    "\n",
    "    # Third class: rankings \n",
    "    output_file = f\"rankings_{season}.csv\"\n",
    "    #ranking = FootballRanking(filename, output_file)\n",
    "    #ranking.process_matches()\n",
    "    #updater = MatchRankUpdater(filename, output_file)\n",
    "    #updater.update_and_save()\n",
    "\n",
    "    # Fourth class: Extract match events data\n",
    "    # Create an instance of Match_events and run the extraction process             Quitar los parentesis del run\n",
    "    # Match_events_extractor = Match_events(league_url)\n",
    "    # Match_events_extractor.run(links_file, filename)\n",
    "\n",
    "    # Fith class: Extract betting odds data\n",
    "    # Create an instance of the BettingOdds class and run the extraction process\n",
    "    odds_processor = Odds_betting()\n",
    "    odds_processor.process_odds(betting_filename, filename)\n",
    "\n",
    "    # Clean up by removing the temporary CSV files after the process is complete\n",
    "    os.remove(links_file)\n",
    "    os.remove(gameweeks_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully.\n",
      "Data with probabilities saved to matches_2017-2018.csv\n"
     ]
    }
   ],
   "source": [
    "# Define the league URL and test size\n",
    "season = \"2017-2018\"\n",
    "test_size = 999\n",
    "betting_filename = \"SP1.csv\"\n",
    "\n",
    "# Run process\n",
    "run_full_process(season, test_size, betting_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "api-python-bet-project-c88tlEpI-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
